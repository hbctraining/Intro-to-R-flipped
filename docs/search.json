[
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html",
    "href": "lessons/01_introR-R-and-RStudio.html",
    "title": "Introduction to R and RStudio",
    "section": "",
    "text": "Approximate time: 45 minutes"
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#learning-objectives",
    "href": "lessons/01_introR-R-and-RStudio.html#learning-objectives",
    "title": "Introduction to R and RStudio",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDescribe what R and RStudio are.\nInteract with R using RStudio.\nFamiliarize various components of RStudio.\nEmploy variables in R."
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#what-is-r",
    "href": "lessons/01_introR-R-and-RStudio.html#what-is-r",
    "title": "Introduction to R and RStudio",
    "section": "What is R?",
    "text": "What is R?\nThe common misconception is that R is a programming language but in fact it is much more than that. Think of R as an environment for statistical computing and graphics, which brings together a number of features to provide powerful functionality.\nThe R environment combines:\n\nEffective handling of big data\nCollection of integrated tools\nGraphical facilities\nSimple and effective programming language"
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#why-use-r",
    "href": "lessons/01_introR-R-and-RStudio.html#why-use-r",
    "title": "Introduction to R and RStudio",
    "section": "Why use R?",
    "text": "Why use R?\n\nR is a powerful, extensible environment. It has a wide range of statistics and general data analysis and visualization capabilities.\n\nData handling, wrangling, and storage\nWide array of statistical methods and graphical techniques available\nEasy to install on any platform and use (and it’s free!)\nOpen source with a large and growing community of peers\n\n\nExamples of R used in the media and science\n\n“At the BBC data team, we have developed an R package and an R cookbook to make the process of creating publication-ready graphics in our in-house style…” - BBC Visual and Data Journalism cookbook for R graphics\n“R package of data and code behind the stories and interactives at FiveThirtyEight.com, a data-driven journalism website founded by Nate Silver (initially began as a polling aggregation site, but now covers politics, sports, science and pop culture) and owned by ESPN…” - fivethirtyeight Package\nSingle Cell RNA-seq Data analysis with Seurat"
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#what-is-rstudio",
    "href": "lessons/01_introR-R-and-RStudio.html#what-is-rstudio",
    "title": "Introduction to R and RStudio",
    "section": "What is RStudio?",
    "text": "What is RStudio?\nRStudio is freely available open-source Integrated Development Environment (IDE). RStudio provides an environment with many features to make using R easier and is a great alternative to working on R in the terminal.\n\n\nGraphical user interface, not just a command prompt\nGreat learning tool\nFree for academic use\nPlatform agnostic\nOpen source"
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#creating-a-new-project-directory-in-rstudio",
    "href": "lessons/01_introR-R-and-RStudio.html#creating-a-new-project-directory-in-rstudio",
    "title": "Introduction to R and RStudio",
    "section": "Creating a new project directory in RStudio",
    "text": "Creating a new project directory in RStudio\nLet’s create a new project directory for our “Introduction to R” lesson today.\n\nOpen RStudio\nGo to the File menu and select New Project.\nIn the New Project window, choose New Directory. Then, choose New Project. Name your new directory Intro-to-R and then “Create the project as subdirectory of:” the Desktop (or location of your choice).\nClick on Create Project.\n\n\n\nAfter your project is completed, if the project does not automatically open in RStudio, then go to the File menu, select Open Project, and choose Intro-to-R.Rproj.\nWhen RStudio opens, you will see three panels in the window.\nGo to the File menu and select New File, and select R Script.\nGo to the File menu and select Save As..., type Intro-to-R.R and select Save\n\n\n\n\nThe RStudio interface should now look like the screenshot below.\n\n\n\nRStudio interface\n\n\n\nWhat is a project in RStudio?\nIt is simply a directory that contains everything related your analyses for a specific project. RStudio projects are useful when you are working on context- specific analyses and you wish to keep them separate. When creating a project in RStudio you associate it with a working directory of your choice (either an existing one, or a new one). A . RProj file is created within that directory and that keeps track of your command history and variables in the environment. The . RProj file can be used to open the project in its current state but at a later date.\nWhen a project is (re) opened within RStudio the following actions are taken:\n\nA new R session (process) is started\nThe .RData file in the project’s main directory is loaded, populating the environment with any objects that were present when the project was closed.\nThe .Rhistory file in the project’s main directory is loaded into the RStudio History pane (and used for Console Up/Down arrow command history).\nThe current working directory is set to the project directory.\nPreviously edited source documents are restored into editor tabs\nOther RStudio settings (e.g. active tabs, splitter positions, etc.) are restored to where they were the last time the project was closed.\n\nInformation adapted from RStudio Support Site"
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#rstudio-interface",
    "href": "lessons/01_introR-R-and-RStudio.html#rstudio-interface",
    "title": "Introduction to R and RStudio",
    "section": "RStudio Interface",
    "text": "RStudio Interface\nThe RStudio interface has four main panels:\n\nConsole: where you can type commands and see output. The console is all you would see if you ran R in the command line without RStudio.\nScript editor: where you can type out commands and save to file. You can also submit the commands to run in the console.\nEnvironment/History: environment shows all active objects and history keeps track of all commands run in console\nFiles/Plots/Packages/Help"
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#organizing-your-working-directory-setting-up",
    "href": "lessons/01_introR-R-and-RStudio.html#organizing-your-working-directory-setting-up",
    "title": "Introduction to R and RStudio",
    "section": "Organizing your working directory & setting up",
    "text": "Organizing your working directory & setting up\n\nViewing your working directory\nBefore we organize our working directory, let’s check to see where our current working directory is located by typing into the console:\n\ngetwd()\n\n[1] \"/Users/nos491/Desktop/Intro-to-R-flipped/lessons\"\n\n\nYour working directory should be the Intro-to-R folder constructed when you created the project. The working directory is where RStudio will automatically look for any files you bring in and where it will automatically save any files you create, unless otherwise specified.\nYou can visualize your working directory by selecting the Files tab from the Files/Plots/Packages/Help window.\n\n\n\nIf you wanted to choose a different directory to be your working directory, you could navigate to a different folder in the Files tab, then, click on the More dropdown menu which appears as a Cog and select Set As Working Directory.\n\n\n\n\n\nStructuring your working directory\nTo organize your working directory for a particular analysis, you should separate the original data (raw data) from intermediate datasets. For instance, you may want to create a data/ directory within your working directory that stores the raw data, and have a results/ directory for intermediate datasets and a figures/ directory for the plots you will generate.\n\n\n\nLet’s create these three directories within your working directory by clicking on New Folder within the Files tab.\nWhen finished, your working directory should look like:\n\n\n\n\n\nSetting up\nThis is more of a housekeeping task. We will be writing long lines of code in our script editor and want to make sure that the lines “wrap” and you don’t have to scroll back and forth to look at your long line of code.\nClick on “Code” at the top of your RStudio screen and select “Soft Wrap Long Lines” in the pull down menu."
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#interacting-with-r",
    "href": "lessons/01_introR-R-and-RStudio.html#interacting-with-r",
    "title": "Introduction to R and RStudio",
    "section": "Interacting with R",
    "text": "Interacting with R\nNow that we have our interface and directory structure set up, let’s start playing with R! There are two main ways of interacting with R in RStudio: using the console or by using script editor (plain text files that contain your code).\n\nConsole window\nThe console window (in RStudio, the bottom left panel) is the place where R is waiting for you to tell it what to do, and where it will show the results of a command. You can type commands directly into the console, but they will be forgotten when you close the session.\nLet’s test it out:\n\n3 + 5\n\n[1] 8\n\n\n\n\nScript editor\nBest practice is to enter the commands in the script editor, and save the script. You are encouraged to comment liberally to describe the commands you are running using #. This way, you have a complete record of what you did, you can easily show others how you did it and you can do it again later on if needed.\nThe Rstudio script editor allows you to ‘send’ the current line or the currently highlighted text to the R console by clicking on the Run button in the upper-right hand corner of the script editor.\nNow let’s try entering commands to the script editor and using the comments character # to add descriptions and highlighting the text to run:\n\n# Intro to R Lesson\n# Feb 16th, 2016\n\n# Interacting with R\n\n## I am adding 3 and 5. R is fun!\n3 + 5\n\n[1] 8\n\n\n\n\n\nAlternatively, you can run by simply pressing the Ctrl and Return/Enter keys at the same time as a shortcut.\n\n\n\nYou should see the command run in the console and output the result.\n\n\n\nWhat happens if we do that same command without the comment symbol #? Re-run the command after removing the # sign in the front:\n\nI am adding 3 and 5. R is fun!\n3+5\n\nNow R is trying to run that sentence as a command, and it doesn’t work. We get an error in the console\n\n\n\n\n\n\nWarning\n\n\n\nError: unexpected symbol in “I am”\n\n\nThis means that the R interpreter did not know what to do with that command\n\n\nConsole command prompt\nInterpreting the command prompt can help understand when R is ready to accept commands. Below lists the different states of the command prompt and how you can exit a command:\nConsole is ready to accept commands: &gt;.\nIf R is ready to accept commands, the R console shows a &gt; prompt.\nWhen the console receives a command (by directly typing into the console or running from the script editor (Ctrl-Enter), R will try to execute it.\nAfter running, the console will show the results and come back with a new &gt; prompt to wait for new commands.\nConsole is waiting for you to enter more data: +.\nIf R is still waiting for you to enter more data because it isn’t complete yet, the console will show a + prompt. It means that you haven’t finished entering a complete command. Often this can be due to you having not ‘closed’ a parenthesis or quotation.\nEscaping a command and getting a new prompt: esc\nIf you’re in Rstudio and you can’t figure out why your command isn’t running, you can click inside the console window and press esc to escape the command and bring back a new prompt &gt;.\n\n\nKeyboard shortcuts in RStudio\nIn addition to some of the shortcuts described earlier in this lesson, we have listed a few more that can be helpful as you work in RStudio.\n\n\n\n\n\n\n\nkey\naction\n\n\n\n\nCtrl+Enter\nRun command from script editor in console\n\n\nESC\nEscape the current command to return to the command prompt\n\n\nCtrl+1\nMove cursor from console to script editor\n\n\nCtrl+2\nMove cursor from script editor to console\n\n\nTab\nUse this key to complete a file path\n\n\nCtrl+Shift+C\nComment the block of highlighted text\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nTry highlighting only 3 + from your script editor and running it. Find a way to bring back the command prompt &gt; in the console."
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#the-r-syntax",
    "href": "lessons/01_introR-R-and-RStudio.html#the-r-syntax",
    "title": "Introduction to R and RStudio",
    "section": "The R syntax",
    "text": "The R syntax\nNow that we know how to talk with R via the script editor or the console, we want to use R for something more than adding numbers. To do this, we need to know more about the R syntax.\nThe main “parts of speech” in R (syntax) include:\n\nthe comments # and how they are used to document function and its content\nvariables and functions\nthe assignment operator &lt;-\nthe = for arguments in functions\n\nNOTE: indentation and consistency in spacing is used to improve clarity and legibility\nWe will go through each of these “parts of speech” in more detail, starting with the assignment operator."
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#assignment-operator",
    "href": "lessons/01_introR-R-and-RStudio.html#assignment-operator",
    "title": "Introduction to R and RStudio",
    "section": "Assignment operator",
    "text": "Assignment operator\nTo do useful and interesting things in R, we need to assign values to variables using the assignment operator, &lt;-. For example, we can use the assignment operator to assign the value of 3 to x by executing:\n\nx &lt;- 3\n\nThe assignment operator (&lt;-) assigns values on the right to variables on the left.\nIn RStudio, typing Alt + - (push Alt at the same time as the - key, on Mac type option + -) will write &lt;- in a single keystroke."
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#variables",
    "href": "lessons/01_introR-R-and-RStudio.html#variables",
    "title": "Introduction to R and RStudio",
    "section": "Variables",
    "text": "Variables\nA variable is a symbolic name for (or reference to) information. Variables in computer programming are analogous to “buckets”, where information can be maintained and referenced. On the outside of the bucket is a name. When referring to the bucket, we use the name of the bucket, not the data stored in the bucket.\nIn the example above, we created a variable or a ‘bucket’ called x. Inside we put a value, 3.\nLet’s create another variable called y and give it a value of 5.\n\ny &lt;- 5\n\nWhen assigning a value to an variable, R does not print anything to the console. You can force to print the value by using parentheses or by typing the variable name.\n\ny\n\n[1] 5\n\n\nYou can also view information on the variable by looking in your Environment window in the upper right-hand corner of the RStudio interface.\n\n\n\nNow we can reference these buckets by name to perform mathematical operations on the values contained within. What do you get in the console for the following operation:\n\nx + y\n\n[1] 8\n\n\nTry assigning the results of this operation to another variable called number.\n\nnumber &lt;- x + y\n\n\n\n\n\n\n\nExercises\n\n\n\n\nTry changing the value of the variable x to 5. What happens to number?\nNow try changing the value of variable y to contain the value 10. What do you need to do, to update the variable number?\n\n\n\n\nTips on variable names\nVariables can be given almost any name, such as x, current_temperature, or subject_id. However, there are some rules / suggestions you should keep in mind:\n\nMake your names explicit and not too long.\nAvoid names starting with a number (2x is not valid but x2 is)\nAvoid names of fundamental functions in R (e.g., if, else, for, see here for a complete list). In general, even if it’s allowed, it’s best to not use other function names (e.g., c, T, mean, data) as variable names. When in doubt check the help to see if the name is already in use.\nAvoid dots (.) within a variable name as in my.dataset. There are many functions in R with dots in their names for historical reasons, but because dots have a special meaning in R (for methods) and other programming languages, it’s best to avoid them.\nUse nouns for object names and verbs for function names\nKeep in mind that R is case sensitive (e.g., genome_length is different from Genome_length)\nBe consistent with the styling of your code (where you put spaces, how you name variable, etc.). In R, two popular style guides are Hadley Wickham’s style guide and Google’s."
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#interacting-with-data-in-r",
    "href": "lessons/01_introR-R-and-RStudio.html#interacting-with-data-in-r",
    "title": "Introduction to R and RStudio",
    "section": "Interacting with data in R",
    "text": "Interacting with data in R\nR is commonly used for handling big data, and so it only makes sense that we learn about R in the context of some kind of relevant data. Let’s take a few minutes to add files to the folders we created and familiarize ourselves with the data.\n\nAdding files to your working directory\nYou can access the files we need for this workshop using the links provided below. If you right click on the link, and “Save link as..”. Choose ~/Desktop/Intro-to-R/data as the destination of the file. You should now see the file appear in your working directory. We will discuss these files a bit later in the lesson.\n\nDownload the normalized counts file by right clicking on this link\nDownload metadata file using this link\nDownload the functional analysis output file using this link\n\n\nNOTE: If the files download automatically to some other location on your laptop, you can move them to the your working directory using your file explorer or finder (outside RStudio), or navigating to the files in the Files tab of the bottom right panel of RStudio\n\n\n\nThe dataset\nIn this example dataset, we have collected whole brain samples from 12 mice and want to evaluate expression differences between them. The expression data represents normalized count data obtained from RNA-sequencing of the 12 brain samples. This data is stored in a comma separated values (CSV) file as a 2-dimensional matrix, with each row corresponding to a gene and each column corresponding to a sample.\n\n\n\n\n\nThe metadata\nWe have another file in which we identify information about the data or metadata. Our metadata is also stored in a CSV file. In this file, each row corresponds to a sample and each column contains some information about each sample.\nThe first column contains the row names, and note that these are identical to the column names in our expression data file above (albeit, in a slightly different order). The next few columns contain information about our samples that allow us to categorize them. For example, the second column contains genotype information for each sample. Each sample is classified in one of two categories: Wt (wild type) or KO (knockout). What types of categories do you observe in the remaining columns?\n\n\n\nR is particularly good at handling this type of categorical data. Rather than simply storing this information as text, the data is represented in a specific data structure which allows the user to sort and manipulate the data in a quick and efficient manner. We will discuss this in more detail as we go through the different lessons in R!\n\n\nThe functional analysis results\nWe will be using the results of the functional analysis to learn about packages/functions from the Tidyverse suite of integrated packages. These packages are designed to work together to make common data science operations like data wrangling, tidying, reading/writing, parsing, and visualizing, more user-friendly."
  },
  {
    "objectID": "lessons/01_introR-R-and-RStudio.html#best-practices",
    "href": "lessons/01_introR-R-and-RStudio.html#best-practices",
    "title": "Introduction to R and RStudio",
    "section": "Best practices",
    "text": "Best practices\nBefore we move on to more complex concepts and getting familiar with the language, we want to point out a few things about best practices when working with R which will help you stay organized in the long run:\n\nCode and workflow are more reproducible if we can document everything that we do. Our end goal is not just to “do stuff”, but to do it in a way that anyone can easily and exactly replicate our workflow and results. All code should be written in the script editor and saved to file, rather than working in the console.\nThe R console should be mainly used to inspect objects, test a function or get help.\nUse # signs to comment. Comment liberally in your R scripts. This will help future you and other collaborators know what each line of code (or code block) was meant to do. Anything to the right of a # is ignored by R. A shortcut for this is Ctrl+Shift+C if you want to comment an entire chunk of text."
  },
  {
    "objectID": "lessons/13_exporting_data_and_plots.html",
    "href": "lessons/13_exporting_data_and_plots.html",
    "title": "Saving data and plots to file",
    "section": "",
    "text": "Approximate time: 30 minutes",
    "crumbs": [
      "Day 3 Self-learning",
      "Saving data and plots to file"
    ]
  },
  {
    "objectID": "lessons/13_exporting_data_and_plots.html#learning-objectives",
    "href": "lessons/13_exporting_data_and_plots.html#learning-objectives",
    "title": "Saving data and plots to file",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDescribe how to export data tables and plots for use outside of the R environment.",
    "crumbs": [
      "Day 3 Self-learning",
      "Saving data and plots to file"
    ]
  },
  {
    "objectID": "lessons/13_exporting_data_and_plots.html#writing-data-to-file",
    "href": "lessons/13_exporting_data_and_plots.html#writing-data-to-file",
    "title": "Saving data and plots to file",
    "section": "Writing data to file",
    "text": "Writing data to file\nEverything we have done so far has only modified the data in R; the files have remained unchanged. Whenever we want to save our datasets to file, we need to use a write function in R.\nTo write our matrix to file in comma separated format (.csv), we can use the write.csv function. There are two required arguments: the variable name of the data structure you are exporting, and the path and filename that you are exporting to. By default the delimiter or column separator is set, and columns will be separated by a comma:\n\n# Save a data frame to file\nwrite.csv(sub_meta, file=\"data/subset_meta.csv\")\n\nOftentimes the output is not exactly what you might want. You can modify the output using the arguments for the function. We can explore the arguments using the ?. This can help elucidate what each of the arguments can adjust the output.\n\n?write.csv\n\nSimilar to reading in data, there are a wide variety of functions available allowing you to export data in specific formats. Another commonly used function is write.table, which allows you to specify the delimiter or separator you wish to use. This function is commonly used to create tab-delimited files.\n\n\n\n\n\n\nNote\n\n\n\nSometimes when writing a data frame using row names to file with write.table(), the column names will align starting with the row names column. To avoid this, you can include the argument col.names = NA when writing to file to ensure all of the column names line up with the correct column values.\n\n\nWriting a vector of values to file requires a different function than the functions available for writing dataframes. You can use write() to save a vector of values to file. For example:\n\n# Save a vector to file\nwrite(glengths, file=\"data/genome_lengths.txt\")\n\nIf we wanted the vector to be output to a single column instead of five, we could explore the arguments:\n\n?write\n\nNote, the ncolumns argument that it defaults to five columns unless specified, so to get a single column:\n\n# Save a vector to file as a single column\nwrite(glengths, file=\"data/genome_lengths.txt\", ncolumns = 1)",
    "crumbs": [
      "Day 3 Self-learning",
      "Saving data and plots to file"
    ]
  },
  {
    "objectID": "lessons/13_exporting_data_and_plots.html#exporting-figures-to-file",
    "href": "lessons/13_exporting_data_and_plots.html#exporting-figures-to-file",
    "title": "Saving data and plots to file",
    "section": "Exporting figures to file",
    "text": "Exporting figures to file\nThere are two ways in which figures and plots can be output to a file (rather than simply displaying on screen).\n\nThe first (and easiest) is to export directly from the RStudio ‘Plots’ panel, by clicking on Export when the image is plotted. This will give you the option of png or pdf and selecting the directory to which you wish to save it to. It will also give you options to dictate the size and resolution of the output image.\nThe second option is to use R functions and have the write to file hard-coded in to your script. This would allow you to run the script from start to finish and automate the process (not requiring human point-and-click actions to save). In R’s terminology, output is directed to a particular output device and that dictates the output format that will be produced. If we wanted to save our scatterplot to a pdf file format we can use a function called ggsave within ggplot2 to help us.\n\n\nggplot(new_metadata) +\n  geom_point(aes(x = age_in_days, y= samplemeans, color = genotype,\n            shape=celltype), size=rel(3.0))\nggsave(\"figures/scatterplot.pdf\")\n\nYou can specify the file format you would like it to print to with the device argument. However, ggsave will try to guess your preferred format from the extension that you provide in your file name.\nBy default, ggsave will save the last image that you rendered. If you want to specify the plot to save you can store your image in an object and use the plot argument inside of ggsave to save that specific image.\n\n\nClick here to see how to save an image in base R\n\nA device must be created or “opened” in order to receive graphical output and, for devices that create a file on disk, the device must also be closed in order to complete the output. If we wanted to print our scatterplot to a pdf file format, we would need to initialize a plot using a function which specifies the graphical format you intend on creating i.e.pdf(), png(), tiff() etc. Within the function you will need to specify a name for your image, and the with and height (optional). This will open up the device that you wish to write to:\n\n## Open device for writing\npdf(\"figures/scatterplot.pdf\")\n\nIf you wish to modify the size and resolution of the image you will need to add in the appropriate parameters as arguments to the function when you initialize. Then we plot the image to the device, using the ggplot scatterplot that we just created.\n\n## Make a plot which will be written to the open device, in this case the temp file created by pdf()/png()\nggplot(new_metadata) +\n  geom_point(aes(x = age_in_days, y= samplemeans, color = genotype,\n            shape=celltype), size=rel(3.0)) \n\n\n\n\n\n\n\n\nFinally, close the “device”, or file, using the dev.off() function. There are also bmp, tiff, and jpeg functions, though the jpeg function has proven less stable than the others.\n\n## Closing the device is essential to save the temporary file created by pdf()/png()\ndev.off()\n\npdf \n  3 \n\n\n\n\n\nYou will not be able to open and look at your file using standard methods (Adobe Acrobat or Preview etc.) until you execute the dev.off() function.\n\n\nIn the case of pdf(), if you had made additional plots before closing the device, they will all be stored in the same file with each plot usually getting its own page, unless otherwise specified.",
    "crumbs": [
      "Day 3 Self-learning",
      "Saving data and plots to file"
    ]
  },
  {
    "objectID": "lessons/Day3_activities.html",
    "href": "lessons/Day3_activities.html",
    "title": "Day 3 Activities",
    "section": "",
    "text": "Download the animals.csv, by right-clicking on the link and “Save Link As…” to place the file into the data directory.\nRead the .csv file into your environment and assign it to a variable called animals. Be sure to check that your row names are the different animals.\nCheck to make sure that animals is a dataframe.\nHow many rows are in the animals dataframe? How many columns?\n\n\n\n\n\nExtract the speed value of 40 km/h from the animals dataframe.\nReturn the rows with animals that are the color Tan.\nReturn the rows with animals that have speed greater than 50 km/h and output only the color column. Keep the output as a data frame.\n\nChange the color of “Grey” to “Gray”.\nCreate a list called animals_list in which the first element contains the speed column of the animals dataframe and the second element contains the color column of the animals dataframe.\nGive each element of your list the appropriate name (i.e speed and color).\n\n\n\n\n\nIn your environment you should have a dataframe called proj_summary which contains quality metric information for an RNA-seq dataset. We have obtained batch information for the control samples in this dataset. Copy and paste the code below to create a dataframe of control samples with the associated batch information:\n\n\nctrl_samples &lt;- data.frame(row.names = c(\"sample3\", \"sample10\", \"sample8\", \"sample4\", \"sample15\"), \n                           date = c(\"01/13/2018\", \"03/15/2018\", \"01/13/2018\", \"09/20/2018\",\"03/15/2018\"))\n\n\nHow many of the ctrl_samples are also in the proj_summary dataframe? Use the %in% operator to compare sample names.\nKeep only the rows in proj_summary which correspond to those in ctrl_samples. Do this with the %in% operator. Save it to a variable called proj_summary_ctrl.\nWe would like to add in the batch information for the samples in proj_summary_ctrl. Find the rows that match in ctrl_samples.\nUse cbind() to add a column called batch to the proj_summary_ctrl dataframe. Assign this new dataframe back to proj_summary_ctrl.\n\n\n\n\n\nSubset proj_summary to keep only the “high” and “low” samples based on the treament column. Save the new dataframe to a variable called proj_summary_noctl.\nFurther, subset the dataframe to remove the non-numeric columns “Quality_format”, and “treatment”. Try to do this using the map_lgl() function in addition to is.numeric(). Save the new dataframe back to proj_summary_noctl.",
    "crumbs": [
      "Day 3",
      "Day 3 Activities"
    ]
  },
  {
    "objectID": "lessons/Day3_activities.html#reading-in-and-inspecting-data",
    "href": "lessons/Day3_activities.html#reading-in-and-inspecting-data",
    "title": "Day 3 Activities",
    "section": "",
    "text": "Download the animals.csv, by right-clicking on the link and “Save Link As…” to place the file into the data directory.\nRead the .csv file into your environment and assign it to a variable called animals. Be sure to check that your row names are the different animals.\nCheck to make sure that animals is a dataframe.\nHow many rows are in the animals dataframe? How many columns?",
    "crumbs": [
      "Day 3",
      "Day 3 Activities"
    ]
  },
  {
    "objectID": "lessons/Day3_activities.html#data-wrangling",
    "href": "lessons/Day3_activities.html#data-wrangling",
    "title": "Day 3 Activities",
    "section": "",
    "text": "Extract the speed value of 40 km/h from the animals dataframe.\nReturn the rows with animals that are the color Tan.\nReturn the rows with animals that have speed greater than 50 km/h and output only the color column. Keep the output as a data frame.\n\nChange the color of “Grey” to “Gray”.\nCreate a list called animals_list in which the first element contains the speed column of the animals dataframe and the second element contains the color column of the animals dataframe.\nGive each element of your list the appropriate name (i.e speed and color).",
    "crumbs": [
      "Day 3",
      "Day 3 Activities"
    ]
  },
  {
    "objectID": "lessons/Day3_activities.html#the-in-operator-reordering-and-matching",
    "href": "lessons/Day3_activities.html#the-in-operator-reordering-and-matching",
    "title": "Day 3 Activities",
    "section": "",
    "text": "In your environment you should have a dataframe called proj_summary which contains quality metric information for an RNA-seq dataset. We have obtained batch information for the control samples in this dataset. Copy and paste the code below to create a dataframe of control samples with the associated batch information:\n\n\nctrl_samples &lt;- data.frame(row.names = c(\"sample3\", \"sample10\", \"sample8\", \"sample4\", \"sample15\"), \n                           date = c(\"01/13/2018\", \"03/15/2018\", \"01/13/2018\", \"09/20/2018\",\"03/15/2018\"))\n\n\nHow many of the ctrl_samples are also in the proj_summary dataframe? Use the %in% operator to compare sample names.\nKeep only the rows in proj_summary which correspond to those in ctrl_samples. Do this with the %in% operator. Save it to a variable called proj_summary_ctrl.\nWe would like to add in the batch information for the samples in proj_summary_ctrl. Find the rows that match in ctrl_samples.\nUse cbind() to add a column called batch to the proj_summary_ctrl dataframe. Assign this new dataframe back to proj_summary_ctrl.",
    "crumbs": [
      "Day 3",
      "Day 3 Activities"
    ]
  },
  {
    "objectID": "lessons/Day3_activities.html#bonus-using-map_lgl",
    "href": "lessons/Day3_activities.html#bonus-using-map_lgl",
    "title": "Day 3 Activities",
    "section": "",
    "text": "Subset proj_summary to keep only the “high” and “low” samples based on the treament column. Save the new dataframe to a variable called proj_summary_noctl.\nFurther, subset the dataframe to remove the non-numeric columns “Quality_format”, and “treatment”. Try to do this using the map_lgl() function in addition to is.numeric(). Save the new dataframe back to proj_summary_noctl.",
    "crumbs": [
      "Day 3",
      "Day 3 Activities"
    ]
  },
  {
    "objectID": "lessons/11b_Custom_Functions_ggplot2.html",
    "href": "lessons/11b_Custom_Functions_ggplot2.html",
    "title": "Custom functions for consistent plots",
    "section": "",
    "text": "Approximate time: 20 minutes",
    "crumbs": [
      "Day 3 Self-learning",
      "Custom functions for consistent plots"
    ]
  },
  {
    "objectID": "lessons/11b_Custom_Functions_ggplot2.html#learning-objectives",
    "href": "lessons/11b_Custom_Functions_ggplot2.html#learning-objectives",
    "title": "Custom functions for consistent plots",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nApply the custom function to generate consistent plots.",
    "crumbs": [
      "Day 3 Self-learning",
      "Custom functions for consistent plots"
    ]
  },
  {
    "objectID": "lessons/11b_Custom_Functions_ggplot2.html#consistent-formatting-using-custom-functions",
    "href": "lessons/11b_Custom_Functions_ggplot2.html#consistent-formatting-using-custom-functions",
    "title": "Custom functions for consistent plots",
    "section": "Consistent formatting using custom functions",
    "text": "Consistent formatting using custom functions\nWhen publishing, it is helpful to ensure all plots have similar formatting. To do this we can create a custom function with our preferences for the theme. Remember the structure of a function is:\n\nname_of_function &lt;- function(arguments) {\n    statements or code that does something\n}\n\nNow, let’s suppose we always wanted our theme to include the following:\n\ntheme_bw() +\ntheme(axis.title=element_text(size=rel(1.5))) +\ntheme(plot.title=element_text(size=rel(1.5), hjust=0.5))\n\n\n\n\n\n\n\nNote\n\n\n\nYou can also combine multiple arguments within the same theme() function:\n\ntheme_bw() +\ntheme(axis.title=element_text(size=rel(1.5)), plot.title=element_text(size=rel(1.5), hjust=0.5))\n\n\n\nIf there is nothing that we want to change when we run this, then we do not need to specify any arguments. Creating the function is simple; we can just put the code inside the {}:\n\npersonal_theme &lt;- function(){\n  theme_bw() +\n  theme(axis.title=element_text(size=rel(1.5))) +\n  theme(plot.title=element_text(size=rel(1.5), hjust=0.5))\n}\n\nNow to run our personal theme with any plot, we can use this function in place of the lines of theme() code:\n\nggplot(new_metadata) +\n  geom_point(aes(x=age_in_days, y=samplemeans, color=genotype, shape=celltype), size=rel(3.0)) +\n  xlab(\"Age (days)\") +\n  ylab(\"Mean expression\") +\n  ggtitle(\"Expression with Age\") +\n  personal_theme()",
    "crumbs": [
      "Day 3 Self-learning",
      "Custom functions for consistent plots"
    ]
  },
  {
    "objectID": "lessons/answer_keys/Day4_activities_answer_key.html",
    "href": "lessons/answer_keys/Day4_activities_answer_key.html",
    "title": "Day 4 Activities",
    "section": "",
    "text": "Exercises\n\nlibrary(tidyverse)\nanimals &lt;- read.csv(\"../data/animals.csv\", row.names=1)\n\n\nChange the animals data frame to a tibble called animals_tb. Save the row names to a column called animal_names before turning it into a tibble.\n\n\n\nanimals_tb &lt;- animals %&gt;%\n        rownames_to_column(var = \"animal_names\") %&gt;%\n        as_tibble()\nanimals_tb\n\n# A tibble: 6 × 3\n  animal_names speed color\n  &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;\n1 Elephant      40   Gray \n2 Cheetah      120   Tan  \n3 Tortoise       0.1 Green\n4 Hare          48   Grey \n5 Lion          80   Tan  \n6 PolarBear     30   White\n\n\n\nUse ggplot2 to plot the animal names (x-axis) versus the speed of the animal (y-axis) in animals_tb using a scatterplot. Customize the plot to display as shown below.\n\n\n\nggplot(animals_tb) +\n        geom_point(aes(x = animal_names, y = speed), color = \"purple\") +\n        theme_bw() +\n        ggtitle(\"Speed Comparisons Between Animals\") + \n        ylab(\"Speed (km/h)\") +\n        xlab(\"Animal\") +\n        theme(plot.title=element_text(hjust=0.5))\n\n\n\n\n\n\n\n\n\nWe decide that our plot would look better with the animal names ordered from slowest to fastest. Using the animals_tb tibble, reorder the animals on the x-axis to start with the slowest animal on the left-hand side of the plot to the fastest animal on the right-hand side of the plot by completing the following steps:\n\na. Use the arrange() function to order the rows by speed from slowest to fastest. Then use the pull() function to extract the animal_names column as a vector of character values. Save the new variable as names_ordered_by_speed.\n\nnames_ordered_by_speed &lt;- animals_tb %&gt;% arrange(speed) %&gt;% pull(animal_names)\nnames_ordered_by_speed\n\n[1] \"Tortoise\"  \"PolarBear\" \"Elephant\"  \"Hare\"      \"Lion\"      \"Cheetah\"  \n\n\nb. Turn the animal_names column of animals_tb into a factor and specify the levels as names_ordered_by_speed from slowest to fastest (output in part a). Note: this step is crucial, because ggplot2 uses factor as plotting order, instead of the order we observe in data frame.\n\nanimals_tb$animal_names &lt;- factor(animals_tb$animal_names, \n                                  levels = names_ordered_by_speed)\nanimals_tb$animal_names\n\n[1] Elephant  Cheetah   Tortoise  Hare      Lion      PolarBear\nLevels: Tortoise PolarBear Elephant Hare Lion Cheetah\n\n\nc. Re-plot the scatterplot with the animal names in order from slowest to fastest.\n\n\nggplot(animals_tb) +\n        geom_point(aes(x = animal_names, y = speed), color = \"purple\") +\n        theme_bw() +\n        ggtitle(\"Speed Comparisons Between Animals\") + \n        ylab(\"Speed (km/h)\") +\n        xlab(\"Animal\") +\n        theme(plot.title=element_text(hjust=0.5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are interested in exploring other ways to reorder a variable in ggplot2, refer to this post.\n\n\n\nSave the plot as a PDF called animals_by_speed_scatterplot.pdf to the results folder.\n\n\nggplot(animals_tb) +\n        geom_point(aes(x = animal_names, y = speed), color = \"purple\") +\n        theme_bw() +\n        ggtitle(\"Speed Comparisons Between Animals\") + \n        ylab(\"Speed (km/h)\") +\n        xlab(\"Animal\") +\n        theme(plot.title=element_text(hjust=0.5))\n\n\n\n\n\n\n\nggsave(\"../figures/animals_by_speed_scatterplot.pdf\")\n\n\nUse the functions from the dplyr package to perform the following tasks:\n\na. Extract the rows of animals_tb tibble with color of gray or tan, order the rows based from slowest to fastest speed, and save to a variable called animals_gray_tan.\n\n\nanimals_gray_tan &lt;- animals_tb %&gt;% \n        filter(color == \"Gray\" | color == \"Tan\") %&gt;%\n        arrange(speed)\nanimals_gray_tan\n\n# A tibble: 3 × 3\n  animal_names speed color\n  &lt;fct&gt;        &lt;dbl&gt; &lt;chr&gt;\n1 Elephant        40 Gray \n2 Lion            80 Tan  \n3 Cheetah        120 Tan  \n\n\nb. Save animals_gray_tan as a comma-separated value file called animals_tb_ordered.csv to the results folder.\n\nwrite.csv(animals_gray_tan,\n          file = \"../results/animals_tb_ordered.csv\",\n          quote = FALSE)"
  },
  {
    "objectID": "lessons/answer_keys/Day2_activities_answer_key.html",
    "href": "lessons/answer_keys/Day2_activities_answer_key.html",
    "title": "Day 2 Activities",
    "section": "",
    "text": "Exercises\n\nCustom Functions - Let’s create a function temp_conv(), which converts the temperature in Fahrenheit (input) to the temperature in Kelvin (output). Let’s perform a two-step calculation: first convert from Fahrenheit to Celsius, and then convert from Celsius to Kelvin.\n\nThe formula for celsius to farenheight: temp_c = (temp_f - 32) * 5 / 9\nThe formula for celsius to kelvin: temp_k = temp_c + 273.15\nTest your function. If your input is 70, the result of temp_conv(70) should be 294.2611.\n\n\n\ntemp_conv &lt;- function(temp_f) {\n  temp_c = (temp_f - 32) * 5 / 9\n  temp_k = temp_c + 273.15\n  return (temp_k)\n}\n\n\nNesting Functions - Now we want to round the temperature in Kelvin (output of temp_conv()) to a single decimal place.\n\nUse the round() function with the newly-created temp_conv() function to achieve this in one line of code.\nIf your input is 70, the output should now be 294.3.\n\n\n\nround(temp_conv(70), digits = 1)\n\n[1] 294.3"
  },
  {
    "objectID": "lessons/Day4_activities.html",
    "href": "lessons/Day4_activities.html",
    "title": "Day 4 Activities",
    "section": "",
    "text": "Exercises\n\nChange the animals data frame to a tibble called animals_tb. Save the row names to a column called animal_names before turning it into a tibble.\n\n\n\nUse ggplot2 to plot the animal names (x-axis) versus the speed of the animal (y-axis) in animals_tb using a scatterplot. Customize the plot to display as shown below.\n\n\n\nWe decide that our plot would look better with the animal names ordered from slowest to fastest. Using the animals_tb tibble, reorder the animals on the x-axis to start with the slowest animal on the left-hand side of the plot to the fastest animal on the right-hand side of the plot by completing the following steps:\na. Use the arrange() function to order the rows by speed from slowest to fastest. Then use the pull() function to extract the animal_names column as a vector of character values. Save the new variable as names_ordered_by_speed.\nb. Turn the animal_names column of animals_tb into a factor and specify the levels as names_ordered_by_speed from slowest to fastest (output in part a). Note: this step is crucial, because ggplot2 uses factor as plotting order, instead of the order we observe in data frame.\nc. Re-plot the scatterplot with the animal names in order from slowest to fastest.\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are interested in exploring other ways to reorder a variable in ggplot2, refer to this post.\n\n\n\nSave the plot as a PDF called animals_by_speed_scatterplot.pdf to the results folder.\nUse the functions from the dplyr package to perform the following tasks:\n\na. Extract the rows of animals_tb tibble with color of gray or tan, order the rows based from slowest to fastest speed, and save to a variable called animals_gray_tan.\n\nb. Save animals_gray_tan as a comma-separated value file called animals_tb_ordered.csv to the results folder.",
    "crumbs": [
      "Day 4",
      "Day 4 Activities"
    ]
  },
  {
    "objectID": "lessons/05_introR-data-wrangling.html",
    "href": "lessons/05_introR-data-wrangling.html",
    "title": "Data subsetting with base R: vectors and factors",
    "section": "",
    "text": "Approximate time: 60 min",
    "crumbs": [
      "Day 2",
      "Data subsetting with base R: vectors and factors"
    ]
  },
  {
    "objectID": "lessons/05_introR-data-wrangling.html#learning-objectives",
    "href": "lessons/05_introR-data-wrangling.html#learning-objectives",
    "title": "Data subsetting with base R: vectors and factors",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDemonstrate how to subset vectors and factors\nExplain the use of logical operators when subsetting vectors and factors\nDemonstrate how to relevel factors in a desired order",
    "crumbs": [
      "Day 2",
      "Data subsetting with base R: vectors and factors"
    ]
  },
  {
    "objectID": "lessons/05_introR-data-wrangling.html#selecting-data-using-indices-and-sequences",
    "href": "lessons/05_introR-data-wrangling.html#selecting-data-using-indices-and-sequences",
    "title": "Data subsetting with base R: vectors and factors",
    "section": "Selecting data using indices and sequences",
    "text": "Selecting data using indices and sequences\nWhen analyzing data, we often want to partition the data so that we are only working with selected columns or rows. A data frame or data matrix is simply a collection of vectors combined together. So let’s begin with vectors and how to access different elements, and then extend those concepts to dataframes.\n\nVectors\n\nSelecting using indices\nIf we want to extract one or several values from a vector, we must provide one or several indices using square brackets [ ] syntax. The index represents the element number within a vector (or the compartment number, if you think of the bucket analogy). R indices start at 1. Programming languages like Fortran, MATLAB, and R start counting at 1, because that’s what human beings typically do. Languages in the C family (including C++, Java, Perl, and Python) count from 0 because that’s simpler for computers to do.\nLet’s start by creating a vector called age:\n\nage &lt;- c(15, 22, 45, 52, 73, 81)\n\n\nSuppose we only wanted the fifth value of this vector, we would use the following syntax:\n\nage[5]\n\n[1] 73\n\n\nIf we wanted all values except the fifth value of this vector, we would use the following:\n\nage[-5]\n\n[1] 15 22 45 52 81\n\n\nIf we wanted to select more than one element we would still use the square bracket syntax, but rather than using a single value we would pass in a vector of several index values:\n\nage[c(3,5,6)]   ## nested\n\n[1] 45 73 81\n\n# OR\n\n## create a vector first then select\nidx &lt;- c(3,5,6) # create vector of the elements of interest\nage[idx]\n\n[1] 45 73 81\n\n\nTo select a sequence of continuous values from a vector, we would use : which is a special function that creates numeric vectors of integer in increasing or decreasing order. Let’s select the first four values from age:\n\nage[1:4]\n\n[1] 15 22 45 52\n\n\nAlternatively, if you wanted the reverse could try 4:1 for instance, and see what is returned.\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate a vector called alphabets with the following letters, C, D, X, L, F.\nUse the associated indices along with [ ] to do the following:\n\nOnly display C, D and F\nDisplay all except X\nDisplay the letters in the opposite order (F, L, X, D, C)\n\n\n\n\n\n\nSelecting using indices with logical operators\nWe can also use indices with logical operators. Logical operators include greater than (&gt;), less than (&lt;), and equal to (==). A full list of logical operators in R is displayed below:\n\n\n\nOperator\nDescription\n\n\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n==\nequal to\n\n\n!=\nnot equal to\n\n\n&\nand\n\n\n|\nor\n\n\n\nWe can use logical expressions to determine whether a particular condition is true or false. For example, let’s use our age vector:\n\nage\n\n[1] 15 22 45 52 73 81\n\n\nIf we wanted to know if each element in our age vector is greater than 50, we could write the following expression:\n\nage &gt; 50\n\n[1] FALSE FALSE FALSE  TRUE  TRUE  TRUE\n\n\nReturned is a vector of logical values the same length as age with TRUE and FALSE values indicating whether each element in the vector is greater than 50.\nWe can use these logical vectors to select only the elements in a vector with TRUE values at the same position or index as in the logical vector.\nSelect all values in the age vector over 50 or age less than 18:\n\nage &gt; 50 | age &lt; 18\n\n[1]  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n\nage[age &gt; 50 | age &lt; 18]  ## nested\n\n[1] 15 52 73 81\n\n# OR\n\n## create a vector first then select\nidx &lt;- age &gt; 50 | age &lt; 18\nage[idx]\n\n[1] 15 52 73 81\n\n\n\nIndexing with logical operators using the which() function\nWhile logical expressions will return a vector of TRUE and FALSE values of the same length, we could use the which() function to output the indices where the values are TRUE. Indexing with either method generates the same results, and personal preference determines which method you choose to use. For example:\n\nwhich(age &gt; 50 | age &lt; 18)\n\n[1] 1 4 5 6\n\nage[which(age &gt; 50 | age &lt; 18)]  ## nested\n\n[1] 15 52 73 81\n\n# OR\n\n## create a vector first then select\nidx_num &lt;- which(age &gt; 50 | age &lt; 18)\nage[idx_num]\n\n[1] 15 52 73 81\n\n\nNotice that we get the same results regardless of whether or not we use the which(). Also note that while which() works the same as the logical expressions for indexing, it can be used for multiple other operations, where it is not interchangeable with logical expressions.\n\n\n\n\nFactors\nSince factors are special vectors, the same rules for selecting values using indices apply. The elements of the expression factor created previously had the following categories or levels: low, medium, and high.\nLet’s extract the values of the factor with high expression, and let’s using nesting here:\n\nexpression[expression == \"high\"]    ## This will only return those elements in the factor equal to \"high\"\n\n[1] \"high\" \"high\" \"high\"\n\n\n\n\n\n\n\n\nNesting note:\n\n\n\nThe piece of code above was more efficient with nesting; we used a single step instead of two steps as shown below:\n\nStep1 (no nesting): idx &lt;- expression == \"high\"\nStep2 (no nesting): expression[idx]\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nExtract only those elements in samplegroup that are not KO (nesting the logical operation is optional).\n\n\n\n\nReleveling factors\nWe have briefly talked about factors, but this data type only becomes more intuitive once you’ve had a chance to work with it. Let’s take a slight detour and learn about how to relevel categories within a factor.\nTo view the integer assignments under the hood you can use str():\n\nexpression\n\n[1] \"low\"    \"high\"   \"medium\" \"high\"   \"low\"    \"medium\" \"high\"  \n\nstr(expression)\n\n chr [1:7] \"low\" \"high\" \"medium\" \"high\" \"low\" \"medium\" \"high\"\n\n\nThe categories are referred to as “factor levels”. As we learned earlier, the levels in the expression factor were assigned integers alphabetically, with high=1, low=2, medium=3. However, it makes more sense for us if low=1, medium=2 and high=3, i.e. it makes sense for us to “relevel” the categories in this factor.\nTo relevel the categories, you can add the levels argument to the factor() function, and give it a vector with the categories listed in the required order:\n\nexpression &lt;- factor(expression, levels=c(\"low\", \"medium\", \"high\"))     # you can re-factor a factor \n\nstr(expression)\n\n Factor w/ 3 levels \"low\",\"medium\",..: 1 3 2 3 1 2 3\n\n\nNow we have a releveled factor with low as the lowest or first category, medium as the second and high as the third. This is reflected in the way they are listed in the output of str(), as well as in the numbering of which category is where in the factor.\n\n\n\n\n\n\nNote\n\n\n\nReleveling becomes necessary when you need a specific category in a factor to be the “base” category, i.e. category that is equal to 1. One example would be if you need the “control” to be the “base” in a given RNA-seq experiment.\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nUse the samplegroup factor we created in a previous lesson, and relevel it such that KO is the first level followed by CTL and OE.",
    "crumbs": [
      "Day 2",
      "Data subsetting with base R: vectors and factors"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html",
    "href": "lessons/15_tidyverse.html",
    "title": "Tidyverse data wrangling",
    "section": "",
    "text": "Approximate time: 75 minutes",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html#learning-objectives",
    "href": "lessons/15_tidyverse.html#learning-objectives",
    "title": "Tidyverse data wrangling",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nPerform basic data wrangling with functions in the Tidyverse package.",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html#tidyverse-basics",
    "href": "lessons/15_tidyverse.html#tidyverse-basics",
    "title": "Tidyverse data wrangling",
    "section": "Tidyverse basics",
    "text": "Tidyverse basics\nThe Tidyverse suite of packages introduces users to a set of data structures, functions and operators to make working with data more intuitive, but is slightly different from the way we do things in base R. Two important new concepts we will focus on are pipes and tibbles.\nBefore we get started with pipes or tibbles, let’s load the library:\n\nlibrary(tidyverse)\n\n\nPipes\nStringing together commands in R can be quite daunting. Also, trying to understand code that has many nested functions can be confusing.\nTo make R code more human readable, the Tidyverse tools use the pipe, %&gt;%, which was acquired from the magrittr package and is now part of the dplyr package that is installed automatically with Tidyverse. The pipe allows the output of a previous command to be used as input to another command instead of using nested functions.\n\n\n\n\n\n\nNote\n\n\n\nShortcut to write the pipe is shift + command + M\n\n\nAn example of using the pipe to run multiple commands:\n\n## A single command\nsqrt(83)\n\n[1] 9.110434\n\n## Base R method of running more than one command\nround(sqrt(83), digits = 2)\n\n[1] 9.11\n\n## Running more than one command with piping\nsqrt(83) %&gt;% round(digits = 2)\n\n[1] 9.11\n\n\nThe pipe represents a much easier way of writing and deciphering R code, and so we will be taking advantage of it, when possible, as we work through the remaining lesson.\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate a vector of random numbers using the code below:\n\n\nrandom_numbers &lt;- c(81, 90, 65, 43, 71, 29)\n\n\nUse the pipe (%&gt;%) to perform two steps in a single line:\n\nTake the mean of random_numbers using the mean() function.\nRound the output to three digits using the round() function.\n\n\n\n\n\n\nTibbles\nA core component of the tidyverse is the tibble. Tibbles are a modern rework of the standard data.frame, with some internal improvements to make code more reliable. They are data frames, but do not follow all of the same rules. For example, tibbles can have numbers/symbols for column names, which is not normally allowed in base R.\nImportant: tidyverse is very opinionated about row names. These packages insist that all column data (e.g. data.frame) be treated equally, and that special designation of a column as rownames should be deprecated. Tibble provides simple utility functions to handle rownames: rownames_to_column() and column_to_rownames().\nTibbles can be created directly using the tibble() function or data frames can be converted into tibbles using as_tibble(name_of_df).\n\n\n\n\n\n\nNote\n\n\n\nThe function as_tibble() will ignore row names, so if a column representing the row names is needed, then the function rownames_to_column(name_of_df) should be run prior to turning the data.frame into a tibble. Also, as_tibble() will not coerce character vectors to factors by default.",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html#experimental-data",
    "href": "lessons/15_tidyverse.html#experimental-data",
    "title": "Tidyverse data wrangling",
    "section": "Experimental data",
    "text": "Experimental data\nWe’re going to explore the Tidyverse suite of tools to wrangle our data to prepare it for visualization. You should have downloaded the file called gprofiler_results_Mov10oe.tsv into your R project’s data folder earlier.\n\n\n\n\n\n\nNote\n\n\n\nIf you do not have the gprofiler_results_Mov10oe.tsv file in your data folder, you can right click and download it into the data folder using this link.\n\n\nThe dataset:\n\nRepresents the functional analysis results, including the biological processes, functions, pathways, or conditions that are over-represented in a given list of genes.\nOur gene list was generated by differential gene expression analysis and the genes represent differences between control mice and mice over-expressing a gene involved in RNA splicing.\n\nThe functional analysis that we will focus on involves gene ontology (GO) terms, which:\n\ndescribe the roles of genes and gene products\norganized into three controlled vocabularies/ontologies (domains):\n\nbiological processes (BP)\ncellular components (CC)\nmolecular functions (MF)",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html#analysis-goal-and-workflow",
    "href": "lessons/15_tidyverse.html#analysis-goal-and-workflow",
    "title": "Tidyverse data wrangling",
    "section": "Analysis goal and workflow",
    "text": "Analysis goal and workflow\nGoal: Visually compare the most significant biological processes (BP) based on the number of associated differentially expressed genes (gene ratios) and significance values by creating the following plot:\n\nTo wrangle our data in preparation for the plotting, we are going to use the Tidyverse suite of tools to wrangle and visualize our data through several steps:\n\nRead in the functional analysis results\nExtract only the GO biological processes (BP) of interest\nSelect only the columns needed for visualization\nOrder by significance (p-adjusted values)\nRename columns to be more intuitive\nCreate additional metrics for plotting (e.g. gene ratios)\nPlot results",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html#tidyverse-tools",
    "href": "lessons/15_tidyverse.html#tidyverse-tools",
    "title": "Tidyverse data wrangling",
    "section": "Tidyverse tools",
    "text": "Tidyverse tools\nWhile all of the tools in the Tidyverse suite are deserving of being explored in more depth, we are going to investigate more deeply the reading (readr), wrangling (dplyr), and plotting (ggplot2) tools.",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html#read-in-the-functional-analysis-results",
    "href": "lessons/15_tidyverse.html#read-in-the-functional-analysis-results",
    "title": "Tidyverse data wrangling",
    "section": "1. Read in the functional analysis results",
    "text": "1. Read in the functional analysis results\nWhile the base R packages have perfectly fine methods for reading in data, the readr and readxl Tidyverse packages offer additional methods for reading in data. Let’s read in our tab-delimited functional analysis results using read_delim():\n\n# Read in the functional analysis results\nfunctional_GO_results &lt;- read_delim(file = \"data/gprofiler_results_Mov10oe.txt\", delim = \"\\t\" )\n\n# Take a look at the results\nfunctional_GO_results\n\n# A tibble: 3,644 × 14\n   query.number significant p.value term.size query.size overlap.size recall\n          &lt;dbl&gt; &lt;lgl&gt;         &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n 1            1 TRUE        0.00434       111       5850           52  0.009\n 2            1 TRUE        0.0033        110       5850           52  0.009\n 3            1 TRUE        0.0297         39       5850           21  0.004\n 4            1 TRUE        0.0193         70       5850           34  0.006\n 5            1 TRUE        0.0148         26       5850           16  0.003\n 6            1 TRUE        0.0187         22       5850           14  0.002\n 7            1 TRUE        0.0226         48       5850           25  0.004\n 8            1 TRUE        0.0491         17       5850           11  0.002\n 9            1 TRUE        0.00798       164       5850           71  0.012\n10            1 TRUE        0.0439         19       5850           12  0.002\n# ℹ 3,634 more rows\n# ℹ 7 more variables: precision &lt;dbl&gt;, term.id &lt;chr&gt;, domain &lt;chr&gt;,\n#   subgraph.number &lt;dbl&gt;, term.name &lt;chr&gt;, relative.depth &lt;dbl&gt;,\n#   intersection &lt;chr&gt;\n\n\n\n\nClick here to see how to do this in base R\n\n\n# Read in the functional analysis results\nfunctional_GO_results &lt;- read.delim(file = \"data/gprofiler_results_Mov10oe.tsv\", sep = \"\\t\" )\n# Take a look at the results\nfunctional_GO_results\n\n\nNotice that the results were automatically read in as a tibble and the output gives the number of rows, columns and the data type for each of the columns.\n\n\n\n\n\n\nNote\n\n\n\nA large number of tidyverse functions will work with both tibbles and dataframes, and the data structure of the output will be identical to the input. However, there are some functions that will return a tibble (without row names), whether or not a tibble or dataframe is provided.",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html#extract-only-the-go-biological-processes-bp-of-interest",
    "href": "lessons/15_tidyverse.html#extract-only-the-go-biological-processes-bp-of-interest",
    "title": "Tidyverse data wrangling",
    "section": "2. Extract only the GO biological processes (BP) of interest",
    "text": "2. Extract only the GO biological processes (BP) of interest\nNow that we have our data, we will need to wrangle it into a format ready for plotting. For all of our data wrangling steps we will be using tools from the dplyr package, which is a swiss-army knife for data wrangling of data frames.\nTo extract the biological processes of interest, we only want those rows where the domain is equal to BP, which we can do using the filter() function.\nTo filter rows of a data frame/tibble based on values in different columns, we give a logical expression as input to the filter() function to return those rows for which the expression is TRUE.\nNow let’s return only those rows that have a domain of BP:\n\n# Return only GO biological processes\nbp_oe &lt;- functional_GO_results %&gt;%\n  filter(domain == \"BP\")\n  \nbp_oe\n\n# A tibble: 1,102 × 14\n   query.number significant p.value term.size query.size overlap.size recall\n          &lt;dbl&gt; &lt;lgl&gt;         &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n 1            1 TRUE        0.00434       111       5850           52  0.009\n 2            1 TRUE        0.0033        110       5850           52  0.009\n 3            1 TRUE        0.0297         39       5850           21  0.004\n 4            1 TRUE        0.0193         70       5850           34  0.006\n 5            1 TRUE        0.0148         26       5850           16  0.003\n 6            1 TRUE        0.0187         22       5850           14  0.002\n 7            1 TRUE        0.0226         48       5850           25  0.004\n 8            1 TRUE        0.0491         17       5850           11  0.002\n 9            1 TRUE        0.00798       164       5850           71  0.012\n10            1 TRUE        0.0439         19       5850           12  0.002\n# ℹ 1,092 more rows\n# ℹ 7 more variables: precision &lt;dbl&gt;, term.id &lt;chr&gt;, domain &lt;chr&gt;,\n#   subgraph.number &lt;dbl&gt;, term.name &lt;chr&gt;, relative.depth &lt;dbl&gt;,\n#   intersection &lt;chr&gt;\n\n\n\n\nClick here to see how to do this in base R\n\n\n# Return only GO biological processes\nidx &lt;- functional_GO_results$domain == \"BP\"\nbp_oe2 &lt;- functional_GO_results[idx,]\nView(bp_oe)\n\n\nNow we have returned only those rows with a domain of BP. How have the dimensions of our results changed?\n\n\n\n\n\n\nExercises\n\n\n\nWe would like to perform an additional round of filtering to only keep the most specific GO terms.\n\nFor bp_oe, use the filter() function to only keep those rows where the relative.depth is greater than 4.\nSave output to overwrite our bp_oe variable.",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html#select-only-the-columns-needed-for-visualization",
    "href": "lessons/15_tidyverse.html#select-only-the-columns-needed-for-visualization",
    "title": "Tidyverse data wrangling",
    "section": "3. Select only the columns needed for visualization",
    "text": "3. Select only the columns needed for visualization\nFor visualization purposes, we are only interested in the columns related to the GO terms, the significance of the terms, and information about the number of genes associated with the terms.\nTo extract columns from a data frame/tibble we can use the select() function. In contrast to base R, we do not need to put the column names in quotes for selection.\n\n# Selecting columns to keep\nbp_oe &lt;- bp_oe %&gt;%\n  select(term.id, term.name, p.value, query.size, term.size, overlap.size, intersection)\n\nbp_oe\n\n# A tibble: 1,102 × 7\n   term.id    term.name   p.value query.size term.size overlap.size intersection\n   &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;       \n 1 GO:0032606 type I int… 0.00434       5850       111           52 rnf216,polr…\n 2 GO:0032479 regulation… 0.0033        5850       110           52 rnf216,polr…\n 3 GO:0032480 negative r… 0.0297        5850        39           21 rnf216,otud…\n 4 GO:0032481 positive r… 0.0193        5850        70           34 polr3b,polr…\n 5 GO:0010644 cell commu… 0.0148        5850        26           16 pkp2,prkaca…\n 6 GO:0086064 cell commu… 0.0187        5850        22           14 pkp2,prkaca…\n 7 GO:0035904 aorta deve… 0.0226        5850        48           25 plxnd1,ap2b…\n 8 GO:0034199 activation… 0.0491        5850        17           11 prkar2b,prk…\n 9 GO:0050852 T cell rec… 0.00798       5850       164           71 psmb1,psmc4…\n10 GO:0046653 tetrahydro… 0.0439        5850        19           12 mthfd1,mthf…\n# ℹ 1,092 more rows\n\n\n\n\nClick here to see how to do this in base R\n\n\n# Selecting columns to keep\nbp_oe &lt;- bp_oe[, c(\"term.id\", \"term.name\", \"p.value\", \"query.size\", \"term.size\", \"overlap.size\", \"intersection\")]\nView(bp_oe)\n\n\nThe select() function also allows for negative selection. So we could have alternately removed columns with negative selection. Note that we need to put the column names inside of the combine (c()) function with a - preceding it for this functionality.\n\n# DO NOT RUN\n# Selecting columns to remove\nbp_oe &lt;- bp_oe %&gt;%\n    select(-c(query.number, significant, recall, precision, \n              subgraph.number, relative.depth, domain))\n\n\n\nClick here to see how to do this in base R\n\n\n# DO NOT RUN\n# Selecting columns to remove\nidx &lt;- !(colnames(bp_oe) %in% c(\"query.number\", \"significant\", \"recall\", \"precision\", \"subgraph.number\", \"relative.depth\", \"domain\"))\nbp_oe &lt;- bp_oe[, idx]",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html#order-go-processes-by-significance-adjusted-p-values",
    "href": "lessons/15_tidyverse.html#order-go-processes-by-significance-adjusted-p-values",
    "title": "Tidyverse data wrangling",
    "section": "4. Order GO processes by significance (adjusted p-values)",
    "text": "4. Order GO processes by significance (adjusted p-values)\nNow that we have only the rows and columns of interest, let’s arrange these by significance, which is denoted by the adjusted p-value.\nLet’s sort the rows by adjusted p-value with the arrange() function.\n\n# Order by adjusted p-value ascending\nbp_oe &lt;- bp_oe %&gt;%\n  arrange(p.value)\n\n\n\nClick here to see how to do this in base R\n\n\n# Order by adjusted p-value ascending\nidx &lt;- order(bp_oe$p.value)\nbp_oe &lt;- bp_oe[idx,]\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you wanted to arrange in descending order, then you could have run the following instead:\n\n# DO NOT RUN\n# Order by adjusted p-value descending\nbp_oe &lt;- bp_oe %&gt;%\n  arrange(desc(p.value))\n\n\n\nClick here to see how to do this in base R\n\n\n# DO NOT RUN\n# Order by adjusted p-value descending\nidx &lt;- order(bp_oe$p.value, decreasing = TRUE)\nbp_oe &lt;- bp_oe[idx,]\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nOrdering variables in ggplot2 is a bit different. This post introduces a few ways of ordering variables in a plot.",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html#rename-columns-to-be-more-intuitive",
    "href": "lessons/15_tidyverse.html#rename-columns-to-be-more-intuitive",
    "title": "Tidyverse data wrangling",
    "section": "5. Rename columns to be more intuitive",
    "text": "5. Rename columns to be more intuitive\nWhile not necessary for our visualization, renaming columns more intuitively can help with our understanding of the data using the rename() function. The syntax is new_name = old_name.\nLet’s rename the term.id and term.name columns.\n\n# Provide better names for columns\nbp_oe &lt;- bp_oe %&gt;% \n  dplyr::rename(GO_id = term.id, \n                GO_term = term.name)\n\nhead(bp_oe)\n\n# A tibble: 6 × 7\n  GO_id      GO_term      p.value query.size term.size overlap.size intersection\n  &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;       \n1 GO:0044260 cellular m… 1.56e-75       5850      8276         3171 dpm1,scyl3,…\n2 GO:0034641 cellular n… 3.51e-66       5850      6428         2535 dpm1,gclc,n…\n3 GO:0010467 gene expre… 6.71e-66       5850      5257         2142 gclc,nfya,b…\n4 GO:0006807 nitrogen c… 2.85e-64       5850      6866         2671 dpm1,gclc,n…\n5 GO:0044237 cellular m… 3.27e-64       5850     10105         3695 dpm1,scyl3,…\n6 GO:0090304 nucleic ac… 1.18e-61       5850      5103         2073 gclc,nfya,d…\n\n\n\n\nClick here to see how to do this in base R\n\n\n# Provide better names for columns\ncolnames(bp_oe)[colnames(bp_oe) == \"term.id\"] &lt;- \"GO_id\"\ncolnames(bp_oe)[colnames(bp_oe) == \"term.name\"] &lt;- \"GO_term\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the case of two packages with identical function names, you can use :: with the package name before and the function name after (e.g stats::filter()) to ensure that the correct function is implemented. The :: can also be used to bring in a function from a library without loading it first.\nIn the example above, we wanted to use the rename() function specifically from the dplyr package, and not any of the other packages (or base R) which may have the rename() function.\n\n\n\n\n\n\n\n\nExercises\n\n\n\nRename the intersection column to genes to reflect the fact that these are the DE genes associated with the GO process.",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html#create-additional-metrics-for-plotting-e.g.-gene-ratios",
    "href": "lessons/15_tidyverse.html#create-additional-metrics-for-plotting-e.g.-gene-ratios",
    "title": "Tidyverse data wrangling",
    "section": "6. Create additional metrics for plotting (e.g. gene ratios)",
    "text": "6. Create additional metrics for plotting (e.g. gene ratios)\nFinally, before we plot our data, we need to create a couple of additional metrics. The mutate() function enables you to create a new column from an existing column.\nLet’s generate gene ratios to reflect the number of DE genes associated with each GO process relative to the total number of DE genes.\n\n# Create gene ratio column based on other columns in dataset\nbp_oe &lt;- bp_oe %&gt;%\n  mutate(gene_ratio = overlap.size / query.size)\nhead(bp_oe)\n\n# A tibble: 6 × 8\n  GO_id      GO_term      p.value query.size term.size overlap.size intersection\n  &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;       \n1 GO:0044260 cellular m… 1.56e-75       5850      8276         3171 dpm1,scyl3,…\n2 GO:0034641 cellular n… 3.51e-66       5850      6428         2535 dpm1,gclc,n…\n3 GO:0010467 gene expre… 6.71e-66       5850      5257         2142 gclc,nfya,b…\n4 GO:0006807 nitrogen c… 2.85e-64       5850      6866         2671 dpm1,gclc,n…\n5 GO:0044237 cellular m… 3.27e-64       5850     10105         3695 dpm1,scyl3,…\n6 GO:0090304 nucleic ac… 1.18e-61       5850      5103         2073 gclc,nfya,d…\n# ℹ 1 more variable: gene_ratio &lt;dbl&gt;\n\n\n\n\nClick here to see how to do this in base R\n\n\n# Create gene ratio column based on other columns in dataset\nbp_oe &lt;- cbind(bp_oe, gene_ratio = bp_oe$overlap.size / bp_oe$query.size)\n\n\n\n\n\n\n\n\nExercises\n\n\n\nCreate a column in bp_oe called term_percent to determine the percent of DE genes associated with the GO term relative to the total number of genes associated with the GO term (overlap.size / term.size)\n\n\nOur final data for plotting should look like the table below:",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/15_tidyverse.html#next-steps",
    "href": "lessons/15_tidyverse.html#next-steps",
    "title": "Tidyverse data wrangling",
    "section": "Next steps",
    "text": "Next steps\nNow that we have our results ready for plotting, we can use the ggplot2 package to plot our results. If you are interested, you can follow this lesson and dive into how to use ggplot2 to create the plots with this dataset.\n\nAdditional resources\n\nR for Data Science\nteach the tidyverse\ntidy style guide",
    "crumbs": [
      "Day 3 Self-learning",
      "Tidyverse data wrangling"
    ]
  },
  {
    "objectID": "lessons/homework/Intro_to_R_key.html",
    "href": "lessons/homework/Intro_to_R_key.html",
    "title": "Homework answer key - Introduction to R practice",
    "section": "",
    "text": "We are performing RNA-Seq on cancer samples being treated with three different types of treatment (A, B, and P). You have 12 samples total, with 4 replicates per treatment. Write the R code you would use to construct your metadata table as described below.\n\nCreate the vectors/factors for each column (Hint: you can type out each vector/factor, or if you want the process go faster try exploring the rep() function).\n\n\n\nsex &lt;- c(\"M\", \"F\",...) # saved vectors/factors as variables and used c() or rep() function to create\n\n - Put them together into a dataframe called `meta`.\n \n\nmeta &lt;- data.frame(sex, stage, treatment, myc) # used data.frame() to create the table\n\n - Use the `rownames()` function to assign row names to the dataframe (Hint: you can type out the row names as a vector, or if you want the process go faster try exploring the `paste()` function).\n \n\nrownames(meta) &lt;- c(\"sample1\", \"sample2\",... , \"sample12\") # or use:\n\nrownames(meta) &lt;- paste(\"sample12\", 1:12, sep=\"\")\n\n Your finished metadata table should have information for the variables `sex`, `stage`, `treatment`, and `myc` levels: \n\n | |sex | stage | treatment | myc |\n |:--:|:--: | :--:  | :------:  | :--: |\n |sample1|  M   |I  |A  |2343|\n |sample2|  F   |II |A  |457|\n |sample3   |M  |II |A  |4593|\n |sample4   |F  |I  |A  |9035|\n |sample5|  M   |II |B  |3450|\n |sample6|  F|  II| B|  3524|\n |sample7|  M|  I|  B|  958|\n |sample8|  F|  II| B|  1053|\n |sample9|  M|  II| P|  8674|\n |sample10  |F| I   |P  |3424|\n |sample11| M   |II |P  |463|\n |sample12| F|  II| P|  5105|"
  },
  {
    "objectID": "lessons/homework/Intro_to_R_key.html#creating-vectorsfactors-and-dataframes",
    "href": "lessons/homework/Intro_to_R_key.html#creating-vectorsfactors-and-dataframes",
    "title": "Homework answer key - Introduction to R practice",
    "section": "",
    "text": "We are performing RNA-Seq on cancer samples being treated with three different types of treatment (A, B, and P). You have 12 samples total, with 4 replicates per treatment. Write the R code you would use to construct your metadata table as described below.\n\nCreate the vectors/factors for each column (Hint: you can type out each vector/factor, or if you want the process go faster try exploring the rep() function).\n\n\n\nsex &lt;- c(\"M\", \"F\",...) # saved vectors/factors as variables and used c() or rep() function to create\n\n - Put them together into a dataframe called `meta`.\n \n\nmeta &lt;- data.frame(sex, stage, treatment, myc) # used data.frame() to create the table\n\n - Use the `rownames()` function to assign row names to the dataframe (Hint: you can type out the row names as a vector, or if you want the process go faster try exploring the `paste()` function).\n \n\nrownames(meta) &lt;- c(\"sample1\", \"sample2\",... , \"sample12\") # or use:\n\nrownames(meta) &lt;- paste(\"sample12\", 1:12, sep=\"\")\n\n Your finished metadata table should have information for the variables `sex`, `stage`, `treatment`, and `myc` levels: \n\n | |sex | stage | treatment | myc |\n |:--:|:--: | :--:  | :------:  | :--: |\n |sample1|  M   |I  |A  |2343|\n |sample2|  F   |II |A  |457|\n |sample3   |M  |II |A  |4593|\n |sample4   |F  |I  |A  |9035|\n |sample5|  M   |II |B  |3450|\n |sample6|  F|  II| B|  3524|\n |sample7|  M|  I|  B|  958|\n |sample8|  F|  II| B|  1053|\n |sample9|  M|  II| P|  8674|\n |sample10  |F| I   |P  |3424|\n |sample11| M   |II |P  |463|\n |sample12| F|  II| P|  5105|"
  },
  {
    "objectID": "lessons/homework/Intro_to_R_key.html#subsetting-vectorsfactors-and-dataframes",
    "href": "lessons/homework/Intro_to_R_key.html#subsetting-vectorsfactors-and-dataframes",
    "title": "Homework answer key - Introduction to R practice",
    "section": "Subsetting vectors/factors and dataframes",
    "text": "Subsetting vectors/factors and dataframes\n\nUsing the meta data frame from question #1, write out the R code you would use to perform the following operations (questions DO NOT build upon each other):\n\nreturn only the treatment and sex columns using []:\n\n\n\nmeta[ , c(1,3)]\n\n - return the `treatment` values for samples 5, 7, 9, and 10 using `[]`:\n      \n\nmeta[c(5,7,9,10), 3]\n\n - use `filter()` to return all data for those samples receiving treatment `P`:\n      \n\nfilter(meta, treatment == \"P\")\n\n - use `filter()`/`select()` to return only the `stage` and `treatment` data for those samples with `myc` &gt; 5000:\n      \n\nfilter(meta, myc &gt; 5000) %&gt;% select(stage, treatment)\n\n - remove the `treatment` column from the dataset using `[]`:\n      \n\nmeta[, -3]\n\n - remove samples 7, 8 and 9 from the dataset using `[]`:\n      \n\nmeta[-7:-9, ]\n\n - keep only samples 1-6 using `[]`:\n      \n\nmeta [1:6, ]\n\n - add a column called `pre_treatment` to the beginning of the dataframe with the values T, F, F, F, T, T, F, T, F, F, T, T (Hint: use `cbind()`): \n      \n\npre_treatment &lt;- c(T, F, F, F, T, T, F, T, F, F, T, T)\n\ncbind(pre_treatment, meta)\n\n - change the names of the columns to: \"A\", \"B\", \"C\", \"D\":\n      \n\ncolnames(meta) &lt;- c(\"A\", \"B\", \"C\", \"D\")"
  },
  {
    "objectID": "lessons/homework/Intro_to_R_key.html#extracting-components-from-lists",
    "href": "lessons/homework/Intro_to_R_key.html#extracting-components-from-lists",
    "title": "Homework answer key - Introduction to R practice",
    "section": "Extracting components from lists",
    "text": "Extracting components from lists\n\nCreate a new list, list_hw with three components, the glengths vector, the dataframe df, and number value. Use this list to answer the questions below . list_hw has the following structure (NOTE: the components of this list are not currently named):\n   [[1]]\n   [1]   4.6  3000.0 50000.0 \n\n   [[2]]\n          species  glengths \n     1    ecoli    4.6\n     2    human    3000.0\n     3    corn     50000.0\n\n   [[3]]\n   [1] 8\n\nWrite out the R code you would use to perform the following operations (questions DO NOT build upon each other): - return the second component of the list:\n\nlist_hw[[2]]\n\n\nreturn 50000.0 from the first component of the list:\n\n\nlist_hw[[1]][3]\n\n\nreturn the value human from the second component:\n\n\nlist_hw[[2]][2, 1]\n\n\ngive the components of the list the following names: “genome_lengths”, “genomes”, “record”:\n\n\nnames(list_hw) &lt;- c(\"genome_lengths\",\"genomes\",\"record\")\n\nlist_hw$record"
  },
  {
    "objectID": "lessons/homework/Intro_to_R_key.html#creating-figures-with-ggplot2",
    "href": "lessons/homework/Intro_to_R_key.html#creating-figures-with-ggplot2",
    "title": "Homework answer key - Introduction to R practice",
    "section": "Creating figures with ggplot2",
    "text": "Creating figures with ggplot2\n\n\n\nplot_image\n\n\n\nCreate the same plot as above using ggplot2 using the provided metadata and counts datasets. The metadata table describes an experiment that you have setup for RNA-seq analysis, while the associated count matrix gives the normalized counts for each sample for every gene. Download the count matrix and metadata using the links provided.\nFollow the instructions below to build your plot. Write the code you used and provide the final image.\n\nRead in the metadata file using: meta &lt;- read.delim(\"Mov10_full_meta.txt\", sep=\"\\t\", row.names=1)\nRead in the count matrix file using: data &lt;- read.delim(\"normalized_counts.txt\", sep=\"\\t\", row.names=1)\nCreate a vector called expression that contains the normalized count values from the row in data that corresponds to the MOV10 gene.\n\n\n\nexpression &lt;- data[\"MOV10\", ]\n\n - Check the class of this expression vector. `data.frame`\n \n Then, will need to convert this to a numeric vector using `as.numeric(expression)`\n  \n\nclass(expression)\n\nexpression &lt;- as.numeric(expression)\n\nclass(expression)\n\n - Bind that vector to your metadata data frame (`meta`) and call the new data frame `df`. \n  \n\ndf &lt;- cbind(meta, expression) #or\n\ndf &lt;- data.frame(meta, expression)\n\n - Create a ggplot by constructing the plot line by line:\n \n      - Initialize a  ggplot with your `df` as input.\n\n      - Add the `geom_jitter()` geometric object with the required aesthetics\n\n      - Color the points based on `sampletype`\n\n      - Add the `theme_bw()` layer \n\n      - Add the title \"Expression of MOV10\" to the plot\n\n      - Change the x-axis label to be blank\n\n      - Change the y-axis label to \"Normalized counts\"\n\n      - Using `theme()` change the following properties of the plot:\n\n           - Remove the legend (Hint: use ?theme help and scroll down to legend.position)\n\n           - Change the plot title size to 1.5x the default and center align\n\n           - Change the axis title to 1.5x the default size\n\n           - Change the size of the axis text only on the y-axis to 1.25x the default size\n           \n           - Rotate the x-axis text to 45 degrees using `axis.text.x=element_text(angle=45, hjust=1)`\n       \n\nggplot(df) +\n  geom_jitter(aes(x= sampletype, y= expression, color = sampletype)) +\n  theme_bw() +\n  ggtitle(\"Expression of MOV10\") +\n  xlab(NULL) +\n  ylab(\"Normalized counts\") +\n  theme(legend.position = \"none\",\n        plot.title=element_text(hjust=0.5, size=rel(1.5)),\n        axis.text=element_text(size=rel(1.25)),\n        axis.title=element_text(size=rel(1.5)),\n        axis.text.x=element_text(angle=45, hjust=1))\n\n ![plot_image](MOV10_homework_ggplot.png)"
  },
  {
    "objectID": "lessons/09_reordering-to-match-datasets.html",
    "href": "lessons/09_reordering-to-match-datasets.html",
    "title": "Advanced R, reordering to match datasets",
    "section": "",
    "text": "Approximate time: 45 min",
    "crumbs": [
      "Day 2 Self-learning",
      "Advanced R, reordering to match datasets"
    ]
  },
  {
    "objectID": "lessons/09_reordering-to-match-datasets.html#learning-objectives",
    "href": "lessons/09_reordering-to-match-datasets.html#learning-objectives",
    "title": "Advanced R, reordering to match datasets",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nImplement manual reordering of vectors and data frames\nUtilize the match() function to reorder vectors and data frames so that unique identifiers are in the same order",
    "crumbs": [
      "Day 2 Self-learning",
      "Advanced R, reordering to match datasets"
    ]
  },
  {
    "objectID": "lessons/09_reordering-to-match-datasets.html#reordering-data-to-match",
    "href": "lessons/09_reordering-to-match-datasets.html#reordering-data-to-match",
    "title": "Advanced R, reordering to match datasets",
    "section": "Reordering data to match",
    "text": "Reordering data to match\nIn the previous lesson, we learned how to determine whether the same data is present in two datasets, in addition to, whether it is in the same order. In this lesson, we will explore how to reorder the data such that the datasets are matching.",
    "crumbs": [
      "Day 2 Self-learning",
      "Advanced R, reordering to match datasets"
    ]
  },
  {
    "objectID": "lessons/09_reordering-to-match-datasets.html#manual-reordering-of-data-using-indices",
    "href": "lessons/09_reordering-to-match-datasets.html#manual-reordering-of-data-using-indices",
    "title": "Advanced R, reordering to match datasets",
    "section": "Manual reordering of data using indices",
    "text": "Manual reordering of data using indices\nIndexing [ ] can be used to extract values from a dataset as we saw earlier, but we can also use it to rearrange our data values.\n\nteaching_team &lt;- c(\"Jihe\", \"Mary\", \"Meeta\", \"Radhika\", \"Will\", \"Emma\", \n                   \"Heather\", \"Elizabeth\", \"Noor\", \"Upen\")\n\n\nRemember that we can return values in a vector by specifying it’s position or index:\n\n# Extracting values from a vector\nteaching_team[c(2, 4)] \n\n[1] \"Mary\"    \"Radhika\"\n\n\nAlso, note that we haven’t changed the teaching_team variable. The only way to change the teaching_team variable would be to re-assign/overwrite it.\n\nteaching_team\n\n [1] \"Jihe\"      \"Mary\"      \"Meeta\"     \"Radhika\"   \"Will\"      \"Emma\"     \n [7] \"Heather\"   \"Elizabeth\" \"Noor\"      \"Upen\"     \n\n\nWe can also extract the values and reorder them:\n\n# Extracting values and reordering them\nteaching_team[c(4, 2)] \n\n[1] \"Radhika\" \"Mary\"   \n\n\nSimilarly, we can extract all of the values and reorder them:\n\n# Extracting all values and reordering them\nteaching_team[c(5, 4, 10, 6, 9, 2, 8, 1, 7, 3)]\n\n [1] \"Will\"      \"Radhika\"   \"Upen\"      \"Emma\"      \"Noor\"      \"Mary\"     \n [7] \"Elizabeth\" \"Jihe\"      \"Heather\"   \"Meeta\"    \n\n\nIf we want to save our results, we need to assign to a variable:\n\n# Saving the results to a variable\nreorder_teach &lt;- teaching_team[c(5, 4, 10, 6, 9, 2, 8, 1, 7, 3)] \n\n\n\n\n\n\n\nExercises\n\n\n\n\nNow that we know how to reorder using indices, let’s try to use it to reorder the contents of one vector to match the contents of another. Let’s create the vectors first and second as detailed below:\n\n\n\nfirst &lt;- c(\"A\",\"B\",\"C\",\"D\",\"E\")\nsecond &lt;- c(\"B\",\"D\",\"E\",\"A\",\"C\")  # same letters but different order\n\nHow would you reorder the second vector to match first?\n\n\nIf we had large datasets, it would be difficult to reorder them by searching for the indices of the matching elements, and it would be quite easy to make a typo or mistake. To help with matching datasets, there is a function called match().",
    "crumbs": [
      "Day 2 Self-learning",
      "Advanced R, reordering to match datasets"
    ]
  },
  {
    "objectID": "lessons/09_reordering-to-match-datasets.html#the-match-function",
    "href": "lessons/09_reordering-to-match-datasets.html#the-match-function",
    "title": "Advanced R, reordering to match datasets",
    "section": "The match function",
    "text": "The match function\nWe can use the match() function to match the values in two vectors. We’ll be using it to evaluate which values are present in both vectors, and how to reorder the elements to make the values match.\nmatch() takes 2 arguments. The first argument is a vector of values in the order you want, while the second argument is the vector of values to be reordered such that it will match the first:\n\na vector of values in the order you want\na vector of values to be reordered\n\nThe function returns the position of the matches (indices) with respect to the second vector, which can be used to re-order it so that it matches the order in the first vector. Let’s use match() on the first and second vectors we created.\n\nmatch(first, second)\n\n[1] 4 1 5 2 3\n\n\nThe output is the indices for how to reorder the second vector to match the first. These indices match the indices that we derived manually before.\nNow, we can just use the indices to reorder the elements of the second vector to be in the same positions as the matching elements in the first vector:\n\n# Saving indices for how to reorder `second` to match `first`\nreorder_idx &lt;- match(first,second) \n\nThen, we can use those indices to reorder the second vector similar to how we ordered with the manually derived indices.\n\n# Reordering the second vector to match the order of the first vector\nsecond[reorder_idx]\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\"\n\n\nIf the output looks good, we can save the reordered vector to a new variable.\n\n# Reordering and saving the output to a variable\nsecond_reordered &lt;- second[reorder_idx]  \n\n\nNow that we know how match() works, let’s change vector second so that only a subset are retained:\n\nfirst &lt;- c(\"A\",\"B\",\"C\",\"D\",\"E\")\nsecond &lt;- c(\"D\",\"B\",\"A\")  # remove values\n\n\nAnd try to match() again:\n\nmatch(first,second)\n\n[1]  3  2 NA  1 NA\n\n\nWe see that the match() function takes every element in the first vector and finds the position of that element in the second vector, and if that element is not present, will return a missing value of NA. The value NA represents missing data for any data type within R. In this case, we can see that the match() function output represents the value at position 3 as first, which is A, then position 2 is next, which is B, the value coming next is supposed to be C, but it is not present in the second vector, so NA is returned, so on and so forth.\n\n\n\n\n\n\nNote\n\n\n\nFor values that don’t match by default return an NA value. You can specify what values you would have it assigned using nomatch argument. Also, if there is more than one matching value found only the first is reported.\n\n\nIf we rearrange second using these indices, then we should see that all the values present in both vectors are in the same positions and NAs are present for any missing values.\n\nsecond[match(first, second)]\n\n[1] \"A\" \"B\" NA  \"D\" NA \n\n\n\nReordering genomic data using match() function\nWhile the input to the match() function is always going to be to vectors, often we need to use these vectors to reorder the rows or columns of a data frame to match the rows or columns of another dataframe.\nLet’s explore how to do this with our use case featuring RNA-seq data. To perform differential gene expression analysis, we have a data frame with the expression data or counts for every sample and another data frame with the information about to which condition each sample belongs. For the tools doing the analysis, the samples in the counts data, which are the column names, need to be the same and in the same order as the samples in the metadata data frame, which are the rownames.\nWe can take a look at these samples in each dataset by using the rownames() and colnames() functions.\n\n# Check row names of the metadata\nrownames(metadata)\n\n [1] \"sample1\"  \"sample2\"  \"sample3\"  \"sample4\"  \"sample5\"  \"sample6\" \n [7] \"sample7\"  \"sample8\"  \"sample9\"  \"sample10\" \"sample11\" \"sample12\"\n\n# Check the column names of the counts data\ncolnames(rpkm_data)\n\n [1] \"sample2\"  \"sample5\"  \"sample7\"  \"sample8\"  \"sample9\"  \"sample4\" \n [7] \"sample6\"  \"sample12\" \"sample3\"  \"sample11\" \"sample10\" \"sample1\" \n\n\nWe see the row names of the metadata are in a nice order starting at sample1 and ending at sample12, while the column names of the counts data look to be the same samples, but are randomly ordered.\nWe will use the match function to match the row names of our metadata with the column names of our counts data, so these will be the arguments for match().\n\nThe rownames of the metadata is the vector in the order that we want, so this will be the first argument\nThe column names of the count or rpkm data is the vector to be reordered, and will be the second argument.\n\nWe will save these indices for how to reorder the column names, to a variable called genomic idx.\n\ngenomic_idx &lt;- match(rownames(metadata), colnames(rpkm_data))\ngenomic_idx\n\n [1] 12  1  9  6  2  7  3  4  5 11 10  8\n\n\nNow we can create a new counts data frame in which the columns are re-ordered based on the match() indices. Remember that to reorder the rows or columns in a data frame we give the name of the data frame followed by square brackets, and then the indices for how to reorder the rows or columns.\n\n# Reorder the counts data frame to have the sample names in the same order as the metadata data frame\nrpkm_ordered  &lt;- rpkm_data[ , genomic_idx]\n\nOur genomic_idx represents how to reorder the columns of our count data such that the column names would be in the same order as the row names of our metadata. Therefore, genomic_idx was used in the columns position.\nCheck and see what happened by clicking on the rpkm_ordered in the Environment window or using the View() function.\n\n# View the reordered counts\nView(rpkm_ordered)\n\nWe can see the sample names are now in a nice order from sample 1 to 12, just like the metadata. One thing to note is that you would never want to rearrange just the column names without the rest of the column because that would dissociate the sample name from it’s values.\nYou can also verify that column names of this new data matrix matches the metadata row names by using the all function:\n\nall(rownames(metadata) == colnames(rpkm_ordered))\n\n[1] TRUE\n\n\nNow that our samples are ordered the same in our metadata and counts data, if these were raw counts (not RPKM) we could proceed to perform differential expression analysis with this dataset.\n\n\n\n\n\n\nExercises\n\n\n\n\nAfter talking with your collaborator, it becomes clear that sample2 and sample9 were actually from a different mouse background than the other samples and should not be part of our analysis. Create a new variable called subset_rpkm that has these columns removed from the rpkm_ordered data frame.\nUse the match() function to subset the metadata data frame so that the row names of the metadata data frame match the column names of the subset_rpkm data frame.",
    "crumbs": [
      "Day 2 Self-learning",
      "Advanced R, reordering to match datasets"
    ]
  },
  {
    "objectID": "lessons/12_boxplot_exercise.html",
    "href": "lessons/12_boxplot_exercise.html",
    "title": "Plotting and data visualization in R",
    "section": "",
    "text": "Approximate time: 60 minutes",
    "crumbs": [
      "Day 3 Self-learning",
      "Plotting and data visualization in R"
    ]
  },
  {
    "objectID": "lessons/12_boxplot_exercise.html#learning-objectives",
    "href": "lessons/12_boxplot_exercise.html#learning-objectives",
    "title": "Plotting and data visualization in R",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nGenerate the box plot using ggplot2",
    "crumbs": [
      "Day 3 Self-learning",
      "Plotting and data visualization in R"
    ]
  },
  {
    "objectID": "lessons/12_boxplot_exercise.html#generating-a-boxplot-with-ggplot2",
    "href": "lessons/12_boxplot_exercise.html#generating-a-boxplot-with-ggplot2",
    "title": "Plotting and data visualization in R",
    "section": "Generating a Boxplot with ggplot2",
    "text": "Generating a Boxplot with ggplot2\nA boxplot provides a graphical view of the distribution of data based on a five number summary:\n\nThe top and bottom of the box represent the (1) first and (2) third quartiles (25th and 75th percentiles, respectively).\nThe line inside the box represents the (3) median (50th percentile).\nThe whiskers extending above and below the box represent the (4) maximum, and (5) minimum of a data set.\nThe whiskers of the plot reach the minimum and maximum values that are not outliers.\n\n\n\n\n\n\n\nNote\n\n\n\nIn this case, outliers are determined using the interquartile range (IQR), which is defined as: Q3 - Q1. Any values that exceeds 1.5 x IQR below Q1 or above Q3 are considered outliers and are represented as points above or below the whiskers.\n\n\n\n1. Boxplot!\nGenerate a boxplot using the data in the new_metadata dataframe. Create a ggplot2 code chunk with the following instructions:\n\nUse the geom_boxplot() layer to plot the differences in sample means between the Wt and KO genotypes.\nUse the fill aesthetic to look at differences in sample means between the celltypes within each genotype.\nAdd a title to your plot.\nAdd labels, ‘Genotype’ for the x-axis and ‘Mean expression’ for the y-axis.\nMake the following theme() changes:\n\nUse the theme_bw() function to make the background white.\nChange the size of your axes labels to 1.25x larger than the default.\nChange the size of your plot title to 1.5x larger than default.\nCenter the plot title.\n\n\nAfter running the above code the boxplot should look something like that provided below.\n\n\n\n\n\n2. Changing the order of genotype on the Boxplot\nLet’s say you wanted to have the “Wt” boxplots displayed first on the left side, and “KO” on the right. How might you go about doing this?\nTo do this, your first question should be - How does ggplot2 determine what to place where on the X-axis? * The order of the genotype on the X axis is in alphabetical order. * To change it, you need to make sure that the genotype column is a factor * And, the factor levels for that column are in the order you want on the X-axis\n\nFactor the new_metadata$genotype column without creating any extra variables/objects and change the levels to c(\"Wt\", \"KO\")\nRe-run the boxplot code chunk you created for the “Boxplot!” exercise above.\n\n\n\n3. Changing default colors\nYou can color the boxplot differently by using some specific layers:\n\nAdd a new layer scale_color_manual(values=c(\"purple\",\"orange\")).\n\nDo you observe a change?\n\nReplace scale_color_manual(values=c(\"purple\",\"orange\")) with scale_fill_manual(values=c(\"purple\",\"orange\")).\n\nDo you observe a change?\nIn the scatterplot we drew in class, add a new layer scale_color_manual(values=c(\"purple\",\"orange\")), do you observe a difference?\nWhat do you think is the difference between scale_color_manual() and scale_fill_manual()?\n\nBack in your boxplot code, change the colors in the scale_fill_manual() layer to be your 2 favorite colors.\n\nAre there any colors that you tried that did not work?\n\n\nWe have a separate lesson about using color palettes from the package RColorBrewer, if you are interested.\nYou are not restricted to using colors by writing them out as character vectors. You have the choice of a lot of colors in R, and you can do so by using their hexadecimal code. For example, “#FF0000” would be red and “#00FF00” would be green similarly, “#FFFFFF” would be white and “#000000” would be black. Click here for more information about color palettes in R or you can use this helpful cheatsheet that lists many popular colors in R.\nOPTIONAL Exercise:\n\nFind the hexadecimal code for your 2 favourite colors (from exercise 3 above) and replace the color names with the hexadecimal codes within the ggplot2 code chunk.",
    "crumbs": [
      "Day 3 Self-learning",
      "Plotting and data visualization in R"
    ]
  },
  {
    "objectID": "lessons/14_finding_help.html",
    "href": "lessons/14_finding_help.html",
    "title": "Troubleshooting and finding help",
    "section": "",
    "text": "Approximate time: 30 min",
    "crumbs": [
      "Day 3 Self-learning",
      "Troubleshooting and finding help"
    ]
  },
  {
    "objectID": "lessons/14_finding_help.html#learning-objectives",
    "href": "lessons/14_finding_help.html#learning-objectives",
    "title": "Troubleshooting and finding help",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nIdentify different R-specific external sources to help with troubleshooting errors and obtaining more information about functions and packages.",
    "crumbs": [
      "Day 3 Self-learning",
      "Troubleshooting and finding help"
    ]
  },
  {
    "objectID": "lessons/14_finding_help.html#asking-for-help",
    "href": "lessons/14_finding_help.html#asking-for-help",
    "title": "Troubleshooting and finding help",
    "section": "Asking for help",
    "text": "Asking for help\nThe key to getting help from someone is for them to grasp your problem rapidly. You should make it as easy as possible to pinpoint where the issue might be.\n\nTry to use the correct words to describe your problem. For instance, a package is not the same thing as a library. Most people will understand what you meant, but others have really strong feelings about the difference in meaning. The key point is that it can make things confusing for people trying to help you. Be as precise as possible when describing your problem.\nAlways include the output of sessionInfo() as it provides critical information about your platform, the versions of R and the packages that you are using, and other information that can be very helpful to understand your problem.\n\n\nsessionInfo()  #This time it is not interchangeable with search()\n\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sonoma 14.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.1    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.4.1       htmltools_0.5.9   otel_0.2.0        rstudioapi_0.17.1\n [9] yaml_2.3.12       rmarkdown_2.30    knitr_1.51        jsonlite_2.0.0   \n[13] xfun_0.55         digest_0.6.39     rlang_1.1.7       evaluate_1.0.5   \n\n\n\nIf possible, reproduce the problem using a very small data.frame instead of your 50,000 rows and 10,000 columns one, provide the small one with the description of your problem. When appropriate, try to generalize what you are doing so even people who are not in your field can understand the question.\n\nTo share an object with someone else, you can provide either the raw file (i.e., your CSV file) with your script up to the point of the error (and after removing everything that is not relevant to your issue). Alternatively, in particular if your questions is not related to a data.frame, you can save any other R data structure that you have in your environment to a file:\n\n\n\n# DO NOT RUN THIS!\n\nsave(iris, file=\"/tmp/iris.RData\")\n\nThe content of this .RData file is not human readable and cannot be posted directly on stackoverflow. It can, however, be emailed to someone who can read it with this command:\n\n# DO NOT RUN THIS!\n\nload(file=\"~/Downloads/iris.RData\")\n\n\nWhere to ask for help?\n\nGoogle is often your best friend for finding answers to specific questions regarding R.\n\nCryptic error messages are very common in R - it is very likely that someone else has encountered this problem already! Start by googling the error message. However, this doesn’t always work because often, package developers rely on the error catching provided by R. You end up with general error messages that might not be very helpful to diagnose a problem (e.g. “subscript out of bounds”).\n\nStackoverflow: Search using the [r] tag. Most questions have already been answered, but the challenge is to use the right words in the search to find the answers: http://stackoverflow.com/questions/tagged/r. If your question hasn’t been answered before and is well crafted, chances are you will get an answer in less than 5 min.\nYour friendly colleagues: if you know someone with more experience than you, they might be able and willing to help you.\nAI tools: You can submit your line of code and the resulting error to ChatGPT or other tools and ask it to interpret the error for you, or ask ChatGPT to write R code to accomplish the task you are struggling with and see where your solutions differ. Importantly, if you use any code written by AI, make sure you review the generated code line by line to check that it works and that you understand what it is doing!\nThe R-help: it is read by a lot of people (including most of the R core team), a lot of people post to it, but the tone can be pretty dry, and it is not always very welcoming to new users. If your question is valid, you are likely to get an answer very fast but don’t expect that it will come with smiley faces. Also, here more than everywhere else, be sure to use correct vocabulary (otherwise you might get an answer pointing to the misuse of your words rather than answering your question). You will also have more success if your question is about a base function rather than a specific package.\nThe Bioconductor support site. This is very useful and if you tag your post, there is a high likelihood of getting an answer from the developer.\nIf your question is about a specific package, see if there is a mailing list for it. Usually it’s included in the DESCRIPTION file of the package that can be accessed using packageDescription(\"name-of-package\"). You may also want to try to email the author of the package directly.\nThere are also some topic-specific mailing lists (GIS, phylogenetics, etc…), the complete list is here.\n\n\n\nMore resources\n\nThe Posting Guide for the R mailing lists.\nHow to ask for R help useful guidelines\nThe Introduction to R can also be dense for people with little programming experience but it is a good place to understand the underpinnings of the R language.\nThe R FAQ is dense and technical but it is full of useful information.\n\n\n\n\n\n\n\nExercises\n\n\n\n\nRun the following code chunks and fix all of the errors. (Note: The code chunks are independent from one another.)\n\n\n# Create vector of work days\nwork_days &lt;- c(Monday, Tuesday, Wednesday, Thursday, Friday)\n\n\n# Create a function to round the output of the sum function\nround_the_sum &lt;- function(x){\n        return(round(sum(x))\n}\n\n\n# Create a function to add together three numbers\nadd_numbers &lt;- function(x,y,z){\n        sum(x,y,z)\n}\n\nadd_numbers(5,9)\n\n\nYou try to install a package and you get the following error message:\n\n\n\n\n\n\n\nWarning\n\n\n\nError: package or namespace load failed for ‘Seurat’ in loadNamespace(j &lt;- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]): there is no package called ‘multtest’\n\n\nWhat would you do to remedy the error?\n\nYou would like to ask for help on an online forum. To do this you want the users of the forum to reproduce your problem, so you want to provide them as much relevant information and data as possible.\n\nYou want to provide them with the list of packages that you currently have loaded, the version of R, your OS and package versions. Use the appropriate function(s) to obtain this information.\nYou want to also provide a small data frame that reproduces the error (if working with a large data frame, you’ll need to subset it down to something small). For this exercise use the data frame df, and save it as an RData object called df.RData.\nWhat code should the people looking at your help request should use to read in df.RData?",
    "crumbs": [
      "Day 3 Self-learning",
      "Troubleshooting and finding help"
    ]
  },
  {
    "objectID": "lessons/04_introR_packages.html",
    "href": "lessons/04_introR_packages.html",
    "title": "Packages and libraries",
    "section": "",
    "text": "Approximate time: 25 min",
    "crumbs": [
      "Day 2 Self-learning",
      "Packages and libraries"
    ]
  },
  {
    "objectID": "lessons/04_introR_packages.html#learning-objectives",
    "href": "lessons/04_introR_packages.html#learning-objectives",
    "title": "Packages and libraries",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nExplain different ways to install external R packages\nDemonstrate how to load a library and how to find functions specific to a package",
    "crumbs": [
      "Day 2 Self-learning",
      "Packages and libraries"
    ]
  },
  {
    "objectID": "lessons/04_introR_packages.html#packages-and-libraries",
    "href": "lessons/04_introR_packages.html#packages-and-libraries",
    "title": "Packages and libraries",
    "section": "Packages and Libraries",
    "text": "Packages and Libraries\nPackages are collections of R functions, data, and compiled code in a well-defined format, created to add specific functionality. There are 10,000+ user contributed packages and growing.\nThere are a set of standard (or base) packages which are considered part of the R source code and automatically available as part of your R installation. Base packages contain the basic functions that allow R to work, and enable standard statistical and graphical functions on datasets; for example, all of the functions that we have been using so far in our examples.\nThe directories in R where the packages are stored are called the libraries. The terms package and library are sometimes used synonymously and there has been discussion amongst the community to resolve this. It is somewhat counter-intuitive to load a package using the library() function and so you can see how confusion can arise.\nYou can check what libraries are loaded in your current R session by typing into the console:\n\nsessionInfo() #Print version information about R, the OS and attached or loaded packages\n\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sonoma 14.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.1    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.4.1       htmltools_0.5.9   otel_0.2.0        rstudioapi_0.17.1\n [9] yaml_2.3.12       rmarkdown_2.30    knitr_1.51        jsonlite_2.0.0   \n[13] xfun_0.55         digest_0.6.39     rlang_1.1.7       evaluate_1.0.5   \n\n# OR\n\nsearch() #Gives a list of attached packages\n\n[1] \".GlobalEnv\"        \"package:stats\"     \"package:graphics\" \n[4] \"package:grDevices\" \"package:utils\"     \"package:datasets\" \n[7] \"package:methods\"   \"Autoloads\"         \"package:base\"     \n\n\nPreviously we have introduced you to functions from the standard base packages. However, the more you work with R, you will come to realize that there is a cornucopia of R packages that offer a wide variety of functionality. To use additional packages will require installation. Many packages can be installed from the CRAN or Bioconductor repositories.\n\n\n\n\n\n\nHelpful tips for package installations\n\n\n\n\nPackage names are case sensitive!\nAt any point (especially if you’ve used R/Bioconductor in the past), in the console R may ask you if you want to “update any old packages by asking Update all/some/none? [a/s/n]:”. If you see this, type “a” at the prompt and hit Enter to update any old packages. Updating packages can sometimes take awhile to run. If you are short on time, you can choose “n” and proceed. Without updating, you run the risk of conflicts between your old packages and the ones from your updated R version later down the road.\nIf you see a message in your console along the lines of “binary version available but the source version is later”, followed by a question, “Do you want to install from sources the package which needs compilation? y/n”, type n for no, and hit enter.\n\n\n\n\nPackage installation from CRAN\nCRAN is a repository where the latest downloads of R (and legacy versions) are found in addition to source code for thousands of different user contributed R packages.\n\n\n\nPackages for R can be installed from the CRAN package repository using the install.packages function. This function will download the source code from on the CRAN mirrors and install the package (and any dependencies) locally on your computer.\nAn example is given below for the ggplot2 package that will be required for some plots we will create later on. Run this code to install ggplot2.\n\ninstall.packages(\"ggplot2\")\n\n\nThe downloaded binary packages are in\n    /var/folders/qb/pppkhh997tl5mc721j34g6qh0000gn/T//RtmpP3mO1f/downloaded_packages\n\n\n\n\nPackage installation from Bioconductor\nAlternatively, packages can also be installed from Bioconductor, another repository of packages which provides tools for the analysis and comprehension of high-throughput genomic data. These packages includes (but is not limited to) tools for performing statistical analysis, annotation packages, and accessing public datasets.\n\n\n\nThere are many packages that are available in CRAN and Bioconductor, but there are also packages that are specific to one repository. Generally, you can find out this information with a Google search or by trial and error.\nTo install from Bioconductor, you will first need to install BiocManager. This only needs to be done once ever for your R installation.\n\n# DO NOT RUN THIS!\ninstall.packages(\"BiocManager\")\n\nNow you can use the install() function from the BiocManager package to install a package by providing the name in quotations.\nHere we have the code to install ggplot2, through Bioconductor:\n\n# DO NOT RUN THIS!\nBiocManager::install(\"ggplot2\")\n\n\n\n\n\n\n\nNote\n\n\n\nThe code above may not be familiar to you - it is essentially using a new operator, a double colon :: to execute a function from a particular package. This is the syntax: package::function_name().\n\n\n\n\nPackage installation from source\nFinally, R packages can also be installed from source. This is useful when you do not have an internet connection (and have the source files locally), since the other two methods are retrieving the source files from remote sites.\nTo install from source, we use the same install.packages function but we have additional arguments that provide specifications to change from defaults:\n\n# DO NOT RUN THIS!\ninstall.packages(\"~/Downloads/ggplot2_1.0.1.tar.gz\", type=\"source\", repos=NULL)\n\n\n\nLoading libraries\nOnce you have the package installed, you can load the library into your R session for use. Any of the functions that are specific to that package will be available for you to use by simply calling the function as you would for any of the base functions. Note that quotations are not required here.\n\nlibrary(ggplot2)\n\nYou can also check what is loaded in your current environment by using sessionInfo() or search() and you should see your package listed as:\n\nother attached packages:\n[1] ggplot2_2.0.0\n\nIn this case there are several other packages that were also loaded along with ggplot2.\nWe only need to install a package once on our computer. However, to use the package, we need to load the library every time we start a new R/RStudio environment. You can think of this as installing a bulb versus turning on the light.\n\n\n\nAnalogy and image credit to Dianne Cook of Monash University.\n\n\nFinding functions specific to a package\nThis is your first time using ggplot2, how do you know where to start and what functions are available to you? One way to do this, is by using the Package tab in RStudio. If you click on the tab, you will see listed all packages that you have installed. For those libraries that you have loaded, you will see a blue checkmark in the box next to it. Scroll down to ggplot2 in your list:\n\n\n\nIf your library is successfully loaded you will see the box checked, as in the screenshot above. Now, if you click on ggplot2 RStudio will open up the help pages and you can scroll through.\nAn alternative is to find the help manual online, which can be less technical and sometimes easier to follow. For example, this website is much more comprehensive for ggplot2 and is the result of a Google search. Many of the Bioconductor packages also have very helpful vignettes that include comprehensive tutorials with mock data that you can work with.\nIf you can’t find what you are looking for, you can use the rdocumention.org website that search through the help files across all packages available.\n\n\n\n\n\n\nExercises\n\n\n\n\nThe ggplot2 package is part of the tidyverse suite of integrated packages which was designed to work together to make common data science operations more user-friendly. We will be using the tidyverse suite in later lessons, and so let’s install it. NOTE: This suite of packages is only available in CRAN.",
    "crumbs": [
      "Day 2 Self-learning",
      "Packages and libraries"
    ]
  },
  {
    "objectID": "lessons/06_reading_and_data_inspection.html",
    "href": "lessons/06_reading_and_data_inspection.html",
    "title": "Reading in and inspecting data",
    "section": "",
    "text": "Demonstrate how to read existing data into R\nUtilize base R functions to inspect data structures",
    "crumbs": [
      "Day 1 Self-learning:",
      "Reading in and inspecting data"
    ]
  },
  {
    "objectID": "lessons/06_reading_and_data_inspection.html#learning-objectives",
    "href": "lessons/06_reading_and_data_inspection.html#learning-objectives",
    "title": "Reading in and inspecting data",
    "section": "",
    "text": "Demonstrate how to read existing data into R\nUtilize base R functions to inspect data structures",
    "crumbs": [
      "Day 1 Self-learning:",
      "Reading in and inspecting data"
    ]
  },
  {
    "objectID": "lessons/06_reading_and_data_inspection.html#reading-data-into-r",
    "href": "lessons/06_reading_and_data_inspection.html#reading-data-into-r",
    "title": "Reading in and inspecting data",
    "section": "Reading data into R",
    "text": "Reading data into R\n\nThe basics\nRegardless of the specific analysis in R we are performing, we usually need to bring data in for any analysis being done in R, so learning how to read in data is a crucial component of learning to use R.\nMany functions exist to read data in, and the function in R you use will depend on the file format being read in. Below we have a table with some examples of functions that can be used for importing some common text data types (plain text).\n\n\n\n\n\n\n\n\n\nData type\nExtension\nFunction\nPackage\n\n\n\n\nComma separated values\ncsv\nread.csv()\nutils (default)\n\n\n\n\nread_csv()\nreadr (tidyverse)\n\n\nTab separated values\ntsv\nread_tsv()\nreadr\n\n\nOther delimited formats\ntxt\nread.table()\nutils\n\n\n\n\nread_table()\nreadr\n\n\n\n\nread_delim()\nreadr\n\n\n\nFor example, if we have text file where the columns are separated by commas (comma-separated values or comma-delimited), you could use the function read.csv. However, if the data are separated by a different delimiter in a text file (e.g. “:”, “;”, ” “,”), you could use the generic read.table function and specify the delimiter (sep = \" \") as an argument in the function.\n\n\n\n\n\n\nNote\n\n\n\nThe \"\\t\" delimiter is shorthand for tab.\n\n\nIn the above table we refer to base R functions as being contained in the “utils” package. In addition to base R functions, we have also listed functions from some other packages that can be used to import data, specifically the “readr” package that installs when you install the “tidyverse” suite of packages.\nIn addition to plain text files, you can also import data from other statistical analysis packages and Excel using functions from different packages.\n\n\n\n\n\n\n\n\n\nData type\nExtension\nFunction\nPackage\n\n\n\n\nStata version 13-14\ndta\nreaddta()\nhaven\n\n\nStata version 7-12\ndta\nread.dta()\nforeign\n\n\nSPSS\nsav\nread.spss()\nforeign\n\n\nSAS\nsas7bdat\nread.sas7bdat()\nsas7bdat\n\n\nExcel\nxlsx, xls\nread_excel()\nreadxl (tidyverse)\n\n\n\nNote, that these lists are not comprehensive, and may other functions exist for importing data. Once you have been using R for a bit, maybe you will have a preference for which functions you prefer to use for which data type.\n\n\nMetadata\nWhen working with large datasets, you will very likely be working with “metadata” file which contains the information about each sample in your dataset.\n\nThe metadata is very important information and we encourage you to think about creating a document with as much metadata you can record before you bring the data into R. Here is some additional reading on metadata from the HMS Data Management Working Group.\n\n\nThe read.csv() function\nLet’s bring in the metadata file we downloaded earlier (mouse_exp_design.csv or mouse_exp_design.txt) using the read.csv function.\nFirst, check the arguments for the function using the ? to ensure that you are entering all the information appropriately:\n\n?read.csv\n\n\nThe first thing you will notice is that you’ve pulled up the documentation for read.table(), this is because that is the parent function and all the other functions are in the same family.\nThe next item on the documentation page is the function Description, which specifies that the output of this set of functions is going to be a data frame - “Reads a file in table format and creates a data frame from it, with cases corresponding to lines and variables to fields in the file.”\nIn usage, all of the arguments listed for read.table() are the default values for all of the family members unless otherwise specified for a given function. Let’s take a look at 2 examples:\n\nThe separator -\n\nin the case of read.table() it is sep = \"\" (space or tab)\nwhereas for read.csv() it is sep = \",\" (a comma).\n\nThe header - This argument refers to the column headers that may (TRUE) or may not (FALSE) exist in the plain text file you are reading in.\n\nin the case of read.table() it is header = FALSE (by default, it assumes you do not have column names)\nwhereas for read.csv() it is header = TRUE (by default, it assumes that all your columns have names listed).\n\n\nThe take-home from the “Usage” section for read.csv() is that it has one mandatory argument, the path to the file and filename in quotations; in our case that is data/mouse_exp_design.csv or data/mouse_exp_design.txt.\n\n\n\n\n\n\nThe stringsAsFactors argument\n\n\n\nNote that the read.table {utils} family of functions has an argument called stringsAsFactors, which by default is set to FALSE (you can double check this by searching the Help tab for read.table or running ?read.table in the console).\nIf stringsAsFactors = TRUE, any function in this family of functions will coerce character columns in the data you are reading in to factor columns (i.e., coerce from vector to factor) in the resulting data frame.\nIf you want to maintain the character vector data structure (e.g., for gene names), you will want to make sure that stringsAsFactors = FALSE.\n\n\n\n\nCreate a data frame by reading in the file\nAt this point, please check the extension for the mouse_exp_design file within your data folder. You will have to type it accordingly within the read.csv() function.\n\n\n\n\n\n\nNote\n\n\n\nread.csv is not fussy about extensions for plain text files, so even though the file we are reading in is a comma-separated value file, it will be read in properly even with a .txt extension.\n\n\nLet’s read in the mouse_exp_design file and create a new data frame called metadata.\n\nmetadata &lt;- read.csv(file=\"data/mouse_exp_design.csv\")\n\n# OR \n# metadata &lt;- read.csv(file=\"data/mouse_exp_design.txt\")\n\n\n\n\n\n\n\nNote\n\n\n\nRStudio supports the automatic completion of code using the Tab key. This is especially helpful for when reading in files to ensure the correct file path. The tab completion feature also provides a shortcut to listing objects, and inline help for functions. Tab completion is your friend! We encourage you to use it whenever possible.\n\n\n\n\nClick here to see how to import data using the Import Dataset button\n\nYou can also use the Import Dataset button in your Environment pane to import data. This option is not as appealing because it can lack reproducibility if not documented properly, but it can be helpful when getting started. In order to use the Import Dataset:\n\n\nLeft-click the Import Dataset button in the Environment pane\n\n\nLeft-click From Text (base…)\n\n\nNavigate to the file you would like to import and select Open\n\n\nType the name you would like the imported object to be called in the Name textbox.\n\n\nSelect the delimiter that your file is using in the Separator dropdown menu\n\n\nLeft-click Import\n\n\nThese steps are summarized in the GIF below:  Now the dataset has been imported into your environment.\n\n\n\n\n\n\nNote\n\n\n\nIf you are going to use this method, it could impact the reproducibility of your work, because the steps to do that import are not recorded anywhere. If you are going to use this method of importing data, it is STRONGLY RECOMMENDED that you copy the command that read the dataset in and is present in the console to an Rscript file. In the future, you can run that line of code from the Rscript file to recreate the data object.\n\n\n\n\nGo to your Global environment and click on the name of the data frame you just created.\n\nWhen you do this the metadata table will pop up on the top left hand corner of RStudio, right next to the R script.\n\nYou should see a subtle coloring (blue-gray) of the first row and first column, the rest of the table will have a white background. This is because your first row and first columns have different properties than the rest of the table, they are the names of the rows and columns respectively.\n\nEarlier we noted that the file we just read in had column names (first row of values) and how read.csv() deals with “headers”. In addition to column headers, read.csv() also assumes that the first column contains the row names. Not all functions in the read.table() family of functions will do this and depending on which one you use, you may have to specify an additional argument to properly assign the row names and column names.\n\n\n\n\n\n\nNote\n\n\n\nRow names and column names are really handy when subsetting data structures and they are also helpful to identify samples or genes. We almost always use them with data frames.\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\n\nInside your project’s data folder you should see a file called project-summary.txt.\nRead it in to R using read.table() with the appropriate arguments and store it as the variable proj_summary. To figure out the appropriate arguments to use with read.table(), keep the following in mind:\n\nall the columns in the input text file have column name/headers\nyou want the first column of the text file to be used as row names (hint: look up the input for the row.names = argument in read.table())\n\nDisplay the contents of proj_summary in your console",
    "crumbs": [
      "Day 1 Self-learning:",
      "Reading in and inspecting data"
    ]
  },
  {
    "objectID": "lessons/06_reading_and_data_inspection.html#inspecting-data-structures",
    "href": "lessons/06_reading_and_data_inspection.html#inspecting-data-structures",
    "title": "Reading in and inspecting data",
    "section": "Inspecting data structures",
    "text": "Inspecting data structures\nThere are a wide selection of base functions in R that are useful for inspecting your data and summarizing it. Let’s use the metadata file that we created to test out data inspection functions.\nTake a look at the dataframe by typing out the variable name metadata and pressing return; the variable contains information describing the samples in our study. Each row holds information for a single sample, and the columns contain categorical information about the sample genotype(WT or KO), celltype (typeA or typeB), and replicate number (1,2, or 3).\n\nmetadata\n\n         genotype celltype replicate\nsample1        Wt    typeA         1\nsample2        Wt    typeA         2\nsample3        Wt    typeA         3\nsample4        KO    typeA         1\nsample5        KO    typeA         2\nsample6        KO    typeA         3\nsample7        Wt    typeB         1\nsample8        Wt    typeB         2\nsample9        Wt    typeB         3\nsample10       KO    typeB         1\nsample11       KO    typeB         2\nsample12       KO    typeB         3\n\n\nSuppose we had a larger file, we might not want to display all the contents in the console. Instead we could check the top (the first 6 lines) of this data.frame using the function head():\n\nhead(metadata)\n\n        genotype celltype replicate\nsample1       Wt    typeA         1\nsample2       Wt    typeA         2\nsample3       Wt    typeA         3\nsample4       KO    typeA         1\nsample5       KO    typeA         2\nsample6       KO    typeA         3\n\n\n\nList of functions for data inspection\nWe already saw how the functions head() and str() (in the releveling section) can be useful to check the content and the structure of a data.frame. Below is a non-exhaustive list of functions to get a sense of the content/structure of data. The list has been divided into functions that work on all types of objects, some that work only on vectors/factors (1 dimensional objects), and others that work on data frames and matrices (2 dimensional objects).\nWe have some exercises below that will allow you to gain more familiarity with these. You will definitely be using some of them in the next few homework sections.\n\nAll data structures - content display:\n\nstr(): compact display of data contents (similar to what you see in the Global environment)\nclass(): displays the data type for vectors (e.g. character, numeric, etc.) and data structure for dataframes, matrices, lists\nsummary(): detailed display of the contents of a given object, including descriptive statistics, frequencies\nhead(): prints the first 6 entries (elements for 1-D objects, rows for 2-D objects)\ntail(): prints the last 6 entries (elements for 1-D objects, rows for 2-D objects)\n\nVector and factor variables:\n\nlength(): returns the number of elements in a vector or factor\n\nDataframe and matrix variables:\n\ndim(): returns dimensions of the dataset (number_of_rows, number_of_columns) [Note, row numbers will always be displayed before column numbers in R]\nnrow(): returns the number of rows in the dataset\nncol(): returns the number of columns in the dataset\nrownames(): returns the row names in the dataset\n\ncolnames(): returns the column names in the dataset\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nUse the class() function on glengths and metadata, how does the output differ between the two?\nUse the summary() function on the proj_summary dataframe, what is the median “rRNA_rate”?\nHow long is the samplegroup factor?\nWhat are the dimensions of the proj_summary dataframe?\nWhen you use the rownames() function on metadata, what is the data structure of the output?\n\n[Optional] How many elements in (how long is) the output of colnames(proj_summary)? Don’t count, but use another function to determine this.",
    "crumbs": [
      "Day 1 Self-learning:",
      "Reading in and inspecting data"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "index.html#introduction-to-r",
    "href": "index.html#introduction-to-r",
    "title": "",
    "section": "Introduction to R",
    "text": "Introduction to R\n\n\n\n\n\n\n\n\nAudience\nComputational skills required\nDuration\n\n\n\n\nBiologists\nNone\n4-session online workshop (~ 8 hours of trainer-led time)\n\n\n\n\nDescription\nThis repository has teaching materials for a hands-on Introduction to R workshop. The workshop will introduce participants to the basics of R and RStudio. R is a simple programming environment that enables the effective handling of data, while providing excellent graphical support. RStudio is a tool that provides a user-friendly environment for working with R. These materials are intended to provide both basic R programming knowledge and its application for increasing efficiency for data analysis.\nNote for Trainers: Please note that the schedule linked below assumes that learners will spend between 2-3 hours on reading through, and completing exercises from selected lessons between classes.\n\n\nLearning Objectives\n\nR syntax: Familiarize the basic syntax and the use of Rstudio.\nData types and data structures: Describe frequently-used data types and data structures in R.\nData inspection and wrangling: Demonstrate the utilization of functions and indices to inspect and subset data from various data structures.\nData visualization: Apply the ggplot2 package to create plots for data visualization.\n\n\n\nLessons\n\nWorkshop schedule (trainer-led learning) \n\n\n\nInstallation Requirements\nDownload the most recent versions of R and RStudio for the appropriate OS using the links below:\n\nR\nRStudio\n\n\n\nDataset\nAll the files used for the above lessons are linked within, but can also be accessed here.\n\n\n\nCitation\nTo cite material from this course in your publications, please use:\n\n\n\n\n\n\nImportant\n\n\n\nMeeta Mistry, Mary Piper, Jihe Liu, & Radhika Khetani. (2021, May 5). hbctraining/Intro-to-R-flipped: R workshop first release. Zenodo. https://doi.org/10.5281/zenodo.4739342. RRID:SCR_025373\n\n\nA lot of time and effort went into the preparation of these materials. Citations help us understand the needs of the community, gain recognition for our work, and attract further funding to support our teaching activities. Thank you for citing this material if it helped you in your data analysis."
  },
  {
    "objectID": "schedule/schedule.html",
    "href": "schedule/schedule.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "schedule/schedule.html#day-1",
    "href": "schedule/schedule.html#day-1",
    "title": "",
    "section": "Day 1",
    "text": "Day 1\n\n\n\nTime\nTopic\nInstructor\n\n\n\n\n10:00 - 10:30\nWorkshop Introduction\nWill\n\n\n10:30 - 11:45\nIntroduction to R and RStudio\nElizabeth\n\n\n11:45 - 12:00\nOverview of self-learning materials and homework submission\nWill\n\n\n\n\nBefore the next class:\nI. Please study the contents and work through all the code within the following lessons:\n\nR Syntax and Data Structure\n\n\nClick here for a preview of this lesson\n\nIn order to utilize R effectively, you will need to understand what types of data you can use in R and also how you can store data in “objects” or “variables”. This lesson will cover: - Assigning a value to a object - What types of information can you store in R - What are the different objects that you can use to store data in R\n\nFunctions and Arguments\n\n\nClick here for a preview of this lesson\n\nFunctions are the basic “commands” used in R to get something done. To use functions (denoted by function_name followed by “()”), one has to enter some information within the parenthesis and optionally some arguments to change the default behavior of a function. You can also create your own functions! When you want to perform a task or a series of tasks more than once, creating a custom function is the best way to go. In this lesson you will explore: - Using built-in functions - Creating your own custom functions\n\nReading in and inspecting data\n\n\nClick here for a preview of this lesson\n\nWhen using R, it is almost a certainty that you will have to bring data into the R environment. In this lesson you will learn: - Reading different types (formats) of data - Inspecting the contents and structure of the dataset once you have read it in\n\n\n\n\nComplete the exercises:\n\n\nEach lesson above contains exercises; please go through each of them.\nCopy over your solutions into the Google Form the day before the next class.\n\n\n\nQuestions?\n\nIf you get stuck due to an error while runnning code in the lesson, email us"
  },
  {
    "objectID": "schedule/schedule.html#day-2",
    "href": "schedule/schedule.html#day-2",
    "title": "",
    "section": "Day 2",
    "text": "Day 2\n\n\n\nTime\nTopic\nInstructor\n\n\n\n\n10:00 - 10:50\nQuestions about self-learning\nAll\n\n\n10:50 - 11:15\nIn-class exercises + Answer key\nElizabeth\n\n\n11:15 - 12:00\nData Wrangling: Subsetting Vectors and Factors\nWill\n\n\n\n\nBefore the next class:\nI. Please study the contents and work through all the code within the following lessons:\n\nPackages and libraries\n\n\nClick here for a preview of this lesson\n\nBase R is incredibly powerful, but it cannot do everything. R has been built to encourage community involvement in expanding functionality. Thousands of supplemental add-ons, also called “packages” have been contributed by the community. Each package comprises of several functions that enable users to perform their desired analysis. This lesson will cover: - Descriptions of package repositories - Installing a package - Loading a package - Accessing the documention for your installed packages and getting help\n\nData wrangling: data frames, matrices and lists\n\n\nClick here for a preview of this lesson\n\nIn class we covered data wrangling (extracting/subsetting) information from single-dimensional objects (vectors, factors). The next step is to learn how to wrangle data in two-dimensional objects.This lesson will cover: - Examining and extracting values from two-dimensional data structures using indices, row names, or column names - Retreiving information from lists\n\nThe %in% operator\n\n\nClick here for a preview of this lesson\n\nVery often you will have to compare two vectors to figure out if, and which, values are common between them. The %in% operator can be used for this purpose.This lesson will cover: - Implementing the %in% operator to evaluate two vectors - Distinguishing %in% from == and other logical operators - Using any() and all() functions\n\nReordering and matching\n\n\nClick here for a preview of this lesson\n\nSometimes you will want to rearrange values within a vector (row names or column names). The match() function can be very powerful for this task.This lesson will cover: - Maunually rearranging values within a vector - Implementing the match() function to automatically rearrange the values within a vector\n\nSetting up a data frame to plot (+ the map() function)\n\n\nClick here for a preview of this lesson\n\nWe will be starting with visualization in the next class. To set up for this, you need to create a new metadata data frame with information from the counts data frame. You will need to use a function over every column within the counts data frame iteratively. You could do that manually, but it is error-prone; the map() family of functions makes this more efficient.This lesson will cover: - Utilizing map_dbl() to take the average of every column in a data frame - Briefly discuss other functions within the map() family of functions - Create a new data frame for plotting\n\n\n\n\nComplete the exercises:\n\n\nEach lesson above contains exercises; please go through each of them.\nCopy over your solutions into the Google Form the day before the next class.\n\n\n\nQuestions?\n\nIf you get stuck due to an error while runnning code in the lesson, email us"
  },
  {
    "objectID": "schedule/schedule.html#day-3",
    "href": "schedule/schedule.html#day-3",
    "title": "",
    "section": "Day 3",
    "text": "Day 3\n\n\n\nTime\nTopic\nInstructor\n\n\n\n\n10:00 - 10:35\nQuestions about self-learning lessons\nAll\n\n\n10:35 - 11:15\nIn-class exercises + Answer key\nWill\n\n\n11:15 - 12:00\nPlotting with the ggplot2 package\nElizabeth\n\n\n\n\nBefore the next class:\nI. Please study the contents and work through all the code within the following lessons:\n\nUsing custom functions for consistent plots\n\n\nClick here for a preview of this lesson\n\nWhen creating your plots in ggplot2 you may want to have consistent formatting (using theme() functions) across your plots, e.g. if you are generating plots for a manuscript. This lesson will cover: - Developing a custom function for creating consistently formatted plots\n\nGenerating a boxplot with ggplot2\n\n\nClick here for a preview of this lesson\n\nPreviously, you created a scatterplot using ggplot2. However, ggplot2 can be used to create a very wide variety of plots. One of the other frequently used plots you can create with ggplot2 is a barplot.This lesson will cover: - Creating and customizing a barplot using ggplot2\n\nWriting to file and exporting plots\n\n\nClick here for a preview of this lesson\n\nNow that you have completed some analysis in R, you will need to eventually export that work out of R/RStudio. R provides lots of flexibility in what and how you export your data and plots.This lesson will cover: - Exporting your figures from R using a variety of file formats - Writing your data from R to a file\n\nFinding help\n\n\nClick here for a preview of this lesson\n\nHopefully, this course has given you the basic tools you need to be successful when using R. However, it would be impossible to cover every aspect of R and you will need to be able to troubleshoot future issues as they arise.This lesson will cover: - Suggestions for how to best ask for help - Where to look for help\n\nTidyverse\n\n\nClick here for a preview of this lesson\n\nThe Tidyverse suite of integrated packages are designed to work together to make common data science operations more user friendly. Tidyverse is becoming increasingly prevalent and it is necessary that R users are conversant in the basics of Tidyverse. We have already used two Tidyverse packages in this workshop (ggplot2 and purrr) and in this lesson we will learn some key features from a few additional packages that make up Tidyverse. This lesson will cover: - Usage of pipes for connecting together multiple commands - Tibbles for two-dimensional data storage - Data wrangling within Tidyverse\n\n\n\n\nComplete the exercises:\n\n\nEach lesson above contains exercises; please go through each of them.\nCopy over your solutions into the Google Form the day before the next class.\n\n\n\nQuestions?\n\nIf you get stuck due to an error while runnning code in the lesson, email us"
  },
  {
    "objectID": "schedule/schedule.html#day-4",
    "href": "schedule/schedule.html#day-4",
    "title": "",
    "section": "Day 4",
    "text": "Day 4\n\n\n\nTime\nTopic\nInstructor\n\n\n\n\n10:00 - 10:35\nQuestions about self-learning lessons\nAll\n\n\n10:35 - 11:15\nIn-class exercises + Answer key\nElizabeth\n\n\n11:15 - 11:25\nSaving your Posit Cloud project\nWill\n\n\n11:25 - 11:45\nDiscussion, Q & A\nAll\n\n\n11:45 - 12:00\nWrap Up\nWill\n\n\n\n\nFinal Exercises\n\nExercises\n\n\n\nAnswer Keys\n\nDay 1 homework\nDay 2 homework\nDay 3 homework\nFinal exercises"
  },
  {
    "objectID": "schedule/schedule.html#building-on-the-basic-r-knowledge",
    "href": "schedule/schedule.html#building-on-the-basic-r-knowledge",
    "title": "",
    "section": "Building on the basic R knowledge",
    "text": "Building on the basic R knowledge\n\nDGE workshop\nSingle-cell RNA-seq workshop\nRMarkdown\nFunctional analysis\nMore ggplot2\nggplot2 cookbook\nRunning R and Rstudio on O2"
  },
  {
    "objectID": "schedule/schedule.html#resources",
    "href": "schedule/schedule.html#resources",
    "title": "",
    "section": "Resources",
    "text": "Resources\n\nAll hbctraining materials"
  },
  {
    "objectID": "schedule/schedule.html#cheatsheets",
    "href": "schedule/schedule.html#cheatsheets",
    "title": "",
    "section": "Cheatsheets",
    "text": "Cheatsheets\n\nbase R cheatsheet\nRStudio cheatsheet\nggplot2 cheatsheet"
  },
  {
    "objectID": "lessons/11_ggplot2.html",
    "href": "lessons/11_ggplot2.html",
    "title": "Plotting and data visualization in R",
    "section": "",
    "text": "Approximate time: 60 minutes",
    "crumbs": [
      "Day 3",
      "Plotting and data visualization in R"
    ]
  },
  {
    "objectID": "lessons/11_ggplot2.html#learning-objectives",
    "href": "lessons/11_ggplot2.html#learning-objectives",
    "title": "Plotting and data visualization in R",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nExplain the syntax of ggplot2\nApply ggplot2 package to visualize data.",
    "crumbs": [
      "Day 3",
      "Plotting and data visualization in R"
    ]
  },
  {
    "objectID": "lessons/11_ggplot2.html#data-visualization-with-ggplot2",
    "href": "lessons/11_ggplot2.html#data-visualization-with-ggplot2",
    "title": "Plotting and data visualization in R",
    "section": "Data Visualization with ggplot2",
    "text": "Data Visualization with ggplot2\n\n\n\n\n\n\nNote\n\n\n\nFor this lesson, you will need the new_metadata data frame. If you do not have this in your environment, please download it from here to your project’s data folder by right-clicking and “save file as” or “download file as”.\nOnce you have downloaded it, load it into your environment as follows:\n\n## load the new_metadata data frame into your environment from a .RData object\nload(\"data/new_metadata.RData\")\n\nNext, let’s check if it was successfully loaded into the environment:\n\n# this data frame should have 12 rows and 5 columns\nView(new_metadata)\n\nGreat, we are now ready to move forward!\n\n\nWhen we are working with large sets of numbers it can be useful to display that information graphically to gain more insight. In this lesson we will be plotting with the popular Bioconductor package ggplot2.\nThe ggplot2 syntax takes some getting used to, but once you get it, you will find it’s extremely powerful and flexible. We will start with drawing a simple x-y scatterplot of samplemeans versus age_in_days from the new_metadata data frame. Please note that ggplot2 expects a “data frame” or “tibble” (you can find out more about tibbles in the lesson on tidyverse) as input.\n\n\n\n\n\n\nNote\n\n\n\nIf you are interested in learning about plotting with base R functions, we have a short lesson available here.\n\n\nLet’s start by loading the ggplot2 library:\n\nlibrary(ggplot2)\n\nThe ggplot() function is used to initialize the basic graph structure, then we add to it. The basic idea is that you specify different parts of the plot using additional functions one after the other and combine them into a “code chunk” using the + operator; the functions in the resulting code chunk are called layers.\nLet’s start:\n\nggplot(new_metadata) # what happens? \n\nYou get a blank plot, because you need to specify additional layers using the + operator.\nThe geom (geometric) object is the layer that specifies what kind of plot we want to draw. A plot must have at least one geom; there is no upper limit. Examples include:\n\npoints (geom_point, geom_jitter for scatter plots, dot plots, etc)\nlines (geom_line, for time series, trend lines, etc)\nboxplot (geom_boxplot, for, well, boxplots!)\n\nLet’s add a “geom” layer to our plot using the + operator, and since we want a scatter plot so we will use geom_point().\n\nggplot(new_metadata) +\n  geom_point() # note what happens here\n\nWhy do we get an error? Is the error message easy to decipher?\nWe get an error because each type of geom usually has a required set of aesthetics to be set. “Aesthetics” are set with the aes() function and can be set either nested within geom_point() (applies only to that layer) or within ggplot() (applies to the whole plot).\nThe aes() function has many different arguments, and all of those arguments take columns from the original data frame as input. It can be used to specify many plot elements including the following:\n\nposition (i.e., on the x and y axes)\ncolor (“outside” color)\nfill (“inside” color)\nshape (of points)\nlinetype\nsize\n\nTo start, we will specify x- and y-axis since geom_point requires the most basic information about a scatterplot, i.e. what you want to plot on the x and y axes. All of the other plot elements mentioned above are optional.\n\nggplot(new_metadata) +\n     geom_point(aes(x = age_in_days, y= samplemeans))\n\n\n\n\n\n\n\n\nNow that we have the required aesthetics, let’s add some extras like color to the plot. We can color the points on the plot based on the genotype column within aes(). You will notice that there are a default set of colors that will be used so we do not have to specify. Note that the legend has been conveniently plotted for us.\n\nggplot(new_metadata) +\n  geom_point(aes(x = age_in_days, y= samplemeans, color = genotype)) \n\n\n\n\n\n\n\n\nLet’s try to have both celltype and genotype represented on the plot. To do this we can assign the shape argument in aes() the celltype column, so that each celltype is plotted with a different shaped data point.\n\nggplot(new_metadata) +\n  geom_point(aes(x = age_in_days, y= samplemeans, color = genotype,\n            shape=celltype)) \n\n\n\n\n\n\n\n\nThe data points are quite small. We can adjust the size of the data points within the geom_point() layer, but it should not be within aes() since we are not mapping it to a column in the input data frame, instead we are just specifying a number.\n\nggplot(new_metadata) +\n  geom_point(aes(x = age_in_days, y= samplemeans, color = genotype,\n            shape=celltype), size=2.25) \n\n\n\n\n\n\n\n\nThe labels on the x- and y-axis are also quite small and hard to read. To change their size, we need to add an additional theme layer. The ggplot2 theme system handles non-data plot elements such as:\n\nAxis label aesthetics\nPlot background\nFacet label backround\nLegend appearance\n\nThere are built-in themes we can use (i.e. theme_bw()) that mostly change the background/foreground colours, by adding it as additional layer. Or we can adjust specific elements of the current default theme by adding the theme() layer and passing in arguments for the things we wish to change. Or we can use both.\nLet’s add a layer theme_bw().\n\nggplot(new_metadata) +\n  geom_point(aes(x = age_in_days, y= samplemeans, color = genotype,\n            shape=celltype), size=3.0) +\n  theme_bw() \n\n\n\n\n\n\n\n\nDo the axis labels or the tick labels get any larger by changing themes?\nNo, they don’t. But, we can add arguments using theme() to change the size of axis labels ourselves. Since we will be adding this layer “on top”, or after theme_bw(), any features we change will override what is set by the theme_bw() layer.\nLet’s increase the size of both the axes titles to be 1.5 times the default size. When modifying the size of text the rel() function is commonly used to specify a change relative to the default.\n\nggplot(new_metadata) +\n  geom_point(aes(x = age_in_days, y= samplemeans, color = genotype,\n            shape=celltype), size=2.25) +\n  theme_bw() +\n  theme(axis.title = element_text(size=rel(1.5)))           \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can use the example(\"geom_point\") function here to explore a multitude of different aesthetics and layers that can be added to your plot. As you scroll through the different plots, take note of how the code is modified. You can use this with any of the different geometric object layers available in ggplot2 to learn how you can easily modify your plots!\n\n\n\n\n\n\n\n\nNote\n\n\n\nRStudio provide this very useful cheatsheet for plotting using ggplot2. Different example plots are provided and the associated code (i.e which geom or theme to use in the appropriate situation.) We also encourage you to peruse through this useful online reference for working with ggplot2.\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nThe current axis label text defaults to what we gave as input to geom_point (i.e the column headers). We can change this by adding additional layers called xlab() and ylab() for the x- and y-axis, respectively. Add these layers to the current plot such that the x-axis is labeled “Age (days)” and the y-axis is labeled “Mean expression”.\nUse the ggtitle layer to add a plot title of your choice.\nAdd the following new layer to the code chunk theme(plot.title=element_text(hjust=0.5)).\n\nWhat does it change?\nHow many theme() layers can be added to a ggplot code chunk, in your estimation?",
    "crumbs": [
      "Day 3",
      "Plotting and data visualization in R"
    ]
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html",
    "href": "lessons/01a_introR-R-and-RStudio.html",
    "title": "Introduction to R and RStudio",
    "section": "",
    "text": "Approximate time: 45 minutes"
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#learning-objectives",
    "href": "lessons/01a_introR-R-and-RStudio.html#learning-objectives",
    "title": "Introduction to R and RStudio",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDescribe what R and RStudio are.\nInteract with R using RStudio.\nFamiliarize various components of RStudio.\nEmploy variables in R."
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#what-is-r",
    "href": "lessons/01a_introR-R-and-RStudio.html#what-is-r",
    "title": "Introduction to R and RStudio",
    "section": "What is R?",
    "text": "What is R?\nThe common misconception is that R is a programming language but in fact it is much more than that. Think of R as an environment for statistical computing and graphics, which brings together a number of features to provide powerful functionality.\nThe R environment combines:\n\nEffective handling of big data\nCollection of integrated tools\nGraphical facilities\nSimple and effective programming language"
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#why-use-r",
    "href": "lessons/01a_introR-R-and-RStudio.html#why-use-r",
    "title": "Introduction to R and RStudio",
    "section": "Why use R?",
    "text": "Why use R?\n\nR is a powerful, extensible environment. It has a wide range of statistics and general data analysis and visualization capabilities.\n\nData handling, wrangling, and storage\nWide array of statistical methods and graphical techniques available\nEasy to install on any platform and use (and it’s free!)\nOpen source with a large and growing community of peers\n\n\nExamples of R used in the media and science\n\n“At the BBC data team, we have developed an R package and an R cookbook to make the process of creating publication-ready graphics in our in-house style…” - BBC Visual and Data Journalism cookbook for R graphics\n“R package of data and code behind the stories and interactives at FiveThirtyEight.com, a data-driven journalism website founded by Nate Silver (initially began as a polling aggregation site, but now covers politics, sports, science and pop culture) and owned by ESPN…” - fivethirtyeight Package\nSingle Cell RNA-seq Data analysis with Seurat"
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#what-is-rstudio",
    "href": "lessons/01a_introR-R-and-RStudio.html#what-is-rstudio",
    "title": "Introduction to R and RStudio",
    "section": "What is RStudio?",
    "text": "What is RStudio?\nRStudio is freely available open-source Integrated Development Environment (IDE). RStudio provides an environment with many features to make using R easier and is a great alternative to working on R in the terminal.\n\n\nGraphical user interface, not just a command prompt\nGreat learning tool\nFree for academic use\nPlatform agnostic\nOpen source"
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#create-a-new-project-directory-in-rstudio",
    "href": "lessons/01a_introR-R-and-RStudio.html#create-a-new-project-directory-in-rstudio",
    "title": "Introduction to R and RStudio",
    "section": "Create a new project directory in RStudio",
    "text": "Create a new project directory in RStudio\nLet’s create a new project directory for our “Introduction to R” lesson today.\n\nOpen RStudio\nGo to the File menu and select New Project.\nIn the New Project window, choose New Directory. Then, choose New Project. Name your new directory Intro-to-R and then “Create the project as subdirectory of:” the Desktop (or location of your choice).\nClick on Create Project.\n\n\n\nAfter your project is completed, if the project does not automatically open in RStudio, then go to the File menu, select Open Project, and choose Intro-to-R.Rproj.\nWhen RStudio opens, you will see three panels in the window.\nGo to the File menu and select New File, and select R Script.\nGo to the File menu and select Save As..., type Intro-to-R.R and select Save\n\n\nThe RStudio interface should now look like the screenshot below.\n\n\n\nRStudio interface\n\n\n\nWhat is a project in RStudio?\nIt is simply a directory that contains everything related your analyses for a specific project. RStudio projects are useful when you are working on context- specific analyses and you wish to keep them separate. When creating a project in RStudio you associate it with a working directory of your choice (either an existing one, or a new one). A . RProj file is created within that directory and that keeps track of your command history and variables in the environment. The . RProj file can be used to open the project in its current state but at a later date.\nWhen a project is (re) opened within RStudio the following actions are taken:\n\nA new R session (process) is started\nThe .RData file in the project’s main directory is loaded, populating the environment with any objects that were present when the project was closed.\nThe .Rhistory file in the project’s main directory is loaded into the RStudio History pane (and used for Console Up/Down arrow command history).\nThe current working directory is set to the project directory.\nPreviously edited source documents are restored into editor tabs\nOther RStudio settings (e.g. active tabs, splitter positions, etc.) are restored to where they were the last time the project was closed.\n\nInformation adapted from RStudio Support Site"
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#rstudio-interface",
    "href": "lessons/01a_introR-R-and-RStudio.html#rstudio-interface",
    "title": "Introduction to R and RStudio",
    "section": "RStudio Interface",
    "text": "RStudio Interface\nThe RStudio interface has four main panels:\n\nConsole: where you can type commands and see output. The console is all you would see if you ran R in the command line without RStudio.\nScript editor: where you can type out commands and save to file. You can also submit the commands to run in the console.\nEnvironment/History: environment shows all active objects and history keeps track of all commands run in console\nFiles/Plots/Packages/Help"
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#organizing-your-working-directory-setting-up",
    "href": "lessons/01a_introR-R-and-RStudio.html#organizing-your-working-directory-setting-up",
    "title": "Introduction to R and RStudio",
    "section": "Organizing your working directory & setting up",
    "text": "Organizing your working directory & setting up\n\nViewing your working directory\nBefore we organize our working directory, let’s check to see where our current working directory is located by typing into the console:\n\ngetwd()\n\n[1] \"/Users/nos491/Desktop/Intro-to-R-flipped/lessons\"\n\n\nYour working directory should be the Intro-to-R folder constructed when you created the project. The working directory is where RStudio will automatically look for any files you bring in and where it will automatically save any files you create, unless otherwise specified.\nYou can visualize your working directory by selecting the Files tab from the Files/Plots/Packages/Help window.\n\n\n\nIf you wanted to choose a different directory to be your working directory, you could navigate to a different folder in the Files tab, then, click on the More dropdown menu which appears as a Cog and select Set As Working Directory.\n\n\n\n\n\nStructuring your working directory\nTo organize your working directory for a particular analysis, you should separate the original data (raw data) from intermediate datasets. For instance, you may want to create a data/ directory within your working directory that stores the raw data, and have a results/ directory for intermediate datasets and a figures/ directory for the plots you will generate.\n\n\n\nLet’s create these three directories within your working directory by clicking on New Folder within the Files tab.\nWhen finished, your working directory should look like:\n\n\n\n\n\nSetting up\nThis is more of a housekeeping task. We will be writing long lines of code in our script editor and want to make sure that the lines “wrap” and you don’t have to scroll back and forth to look at your long line of code.\nClick on “Code” at the top of your RStudio screen and select “Soft Wrap Long Lines” in the pull down menu."
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#interacting-with-r",
    "href": "lessons/01a_introR-R-and-RStudio.html#interacting-with-r",
    "title": "Introduction to R and RStudio",
    "section": "Interacting with R",
    "text": "Interacting with R\nNow that we have our interface and directory structure set up, let’s start playing with R! There are two main ways of interacting with R in RStudio: using the console or by using script editor (plain text files that contain your code).\n\nConsole window\nThe console window (in RStudio, the bottom left panel) is the place where R is waiting for you to tell it what to do, and where it will show the results of a command. You can type commands directly into the console, but they will be forgotten when you close the session.\nLet’s test it out:\n\n3 + 5\n\n[1] 8\n\n\n\n\nScript editor\nBest practice is to enter the commands in the script editor, and save the script. You are encouraged to comment liberally to describe the commands you are running using #. This way, you have a complete record of what you did, you can easily show others how you did it and you can do it again later on if needed.\nThe Rstudio script editor allows you to ‘send’ the current line or the currently highlighted text to the R console by clicking on the Run button in the upper-right hand corner of the script editor.\nNow let’s try entering commands to the script editor and using the comments character # to add descriptions and highlighting the text to run:\n\n# Intro to R Lesson\n# Feb 16th, 2016\n\n# Interacting with R\n\n## I am adding 3 and 5. R is fun!\n3 + 5\n\n[1] 8\n\n\n\n\n\nAlternatively, you can run by simply pressing the Ctrl and Return/Enter keys at the same time as a shortcut.\n\n\n\nYou should see the command run in the console and output the result.\n\n\n\nWhat happens if we do that same command without the comment symbol #? Re-run the command after removing the # sign in the front:\n\nI am adding 3 and 5. R is fun!\n3+5\n\nNow R is trying to run that sentence as a command, and it doesn’t work. We get an error in the console\n\n\n\n\n\n\nWarning\n\n\n\nError: unexpected symbol in “I am”\n\n\nThis means that the R interpreter did not know what to do with that command\n\n\nConsole command prompt\nInterpreting the command prompt can help understand when R is ready to accept commands. Below lists the different states of the command prompt and how you can exit a command:\nConsole is ready to accept commands: &gt;.\nIf R is ready to accept commands, the R console shows a &gt; prompt.\nWhen the console receives a command (by directly typing into the console or running from the script editor (Ctrl-Enter), R will try to execute it.\nAfter running, the console will show the results and come back with a new &gt; prompt to wait for new commands.\nConsole is waiting for you to enter more data: +.\nIf R is still waiting for you to enter more data because it isn’t complete yet, the console will show a + prompt. It means that you haven’t finished entering a complete command. Often this can be due to you having not ‘closed’ a parenthesis or quotation.\nEscaping a command and getting a new prompt: esc\nIf you’re in Rstudio and you can’t figure out why your command isn’t running, you can click inside the console window and press esc to escape the command and bring back a new prompt &gt;.\n\n\nKeyboard shortcuts in RStudio\nIn addition to some of the shortcuts described earlier in this lesson, we have listed a few more that can be helpful as you work in RStudio.\n\n\n\n\n\n\n\nkey\naction\n\n\n\n\nCtrl+Enter\nRun command from script editor in console\n\n\nESC\nEscape the current command to return to the command prompt\n\n\nCtrl+1\nMove cursor from console to script editor\n\n\nCtrl+2\nMove cursor from script editor to console\n\n\nTab\nUse this key to complete a file path\n\n\nCtrl+Shift+C\nComment the block of highlighted text\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nTry highlighting only 3 + from your script editor and running it. Find a way to bring back the command prompt &gt; in the console."
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#the-r-syntax",
    "href": "lessons/01a_introR-R-and-RStudio.html#the-r-syntax",
    "title": "Introduction to R and RStudio",
    "section": "The R syntax",
    "text": "The R syntax\nNow that we know how to talk with R via the script editor or the console, we want to use R for something more than adding numbers. To do this, we need to know more about the R syntax.\nThe main “parts of speech” in R (syntax) include:\n\nthe comments # and how they are used to document function and its content\nvariables and functions\nthe assignment operator &lt;-\nthe = for arguments in functions\n\nNOTE: indentation and consistency in spacing is used to improve clarity and legibility\nWe will go through each of these “parts of speech” in more detail, starting with the assignment operator."
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#assignment-operator",
    "href": "lessons/01a_introR-R-and-RStudio.html#assignment-operator",
    "title": "Introduction to R and RStudio",
    "section": "Assignment operator",
    "text": "Assignment operator\nTo do useful and interesting things in R, we need to assign values to variables using the assignment operator, &lt;-. For example, we can use the assignment operator to assign the value of 3 to x by executing:\n\nx &lt;- 3\n\nThe assignment operator (&lt;-) assigns values on the right to variables on the left.\nIn RStudio, typing Alt + - (push Alt at the same time as the - key, on Mac type option + -) will write &lt;- in a single keystroke."
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#variables",
    "href": "lessons/01a_introR-R-and-RStudio.html#variables",
    "title": "Introduction to R and RStudio",
    "section": "Variables",
    "text": "Variables\nA variable is a symbolic name for (or reference to) information. Variables in computer programming are analogous to “buckets”, where information can be maintained and referenced. On the outside of the bucket is a name. When referring to the bucket, we use the name of the bucket, not the data stored in the bucket.\nIn the example above, we created a variable or a ‘bucket’ called x. Inside we put a value, 3.\nLet’s create another variable called y and give it a value of 5.\n\ny &lt;- 5\n\nWhen assigning a value to an variable, R does not print anything to the console. You can force to print the value by using parentheses or by typing the variable name.\n\ny\n\n[1] 5\n\n\nYou can also view information on the variable by looking in your Environment window in the upper right-hand corner of the RStudio interface.\n\n\n\nNow we can reference these buckets by name to perform mathematical operations on the values contained within. What do you get in the console for the following operation:\n\nx + y\n\n[1] 8\n\n\nTry assigning the results of this operation to another variable called number.\n\nnumber &lt;- x + y\n\n\n\n\n\n\n\nExercises\n\n\n\n\nTry changing the value of the variable x to 5. What happens to number?\nNow try changing the value of variable y to contain the value 10. What do you need to do, to update the variable number?\n\n\n\n\nTips on variable names\nVariables can be given almost any name, such as x, current_temperature, or subject_id. However, there are some rules / suggestions you should keep in mind:\n\nMake your names explicit and not too long.\nAvoid names starting with a number (2x is not valid but x2 is)\nAvoid names of fundamental functions in R (e.g., if, else, for, see here for a complete list). In general, even if it’s allowed, it’s best to not use other function names (e.g., c, T, mean, data) as variable names. When in doubt check the help to see if the name is already in use.\nAvoid dots (.) within a variable name as in my.dataset. There are many functions in R with dots in their names for historical reasons, but because dots have a special meaning in R (for methods) and other programming languages, it’s best to avoid them.\nUse nouns for object names and verbs for function names\nKeep in mind that R is case sensitive (e.g., genome_length is different from Genome_length)\nBe consistent with the styling of your code (where you put spaces, how you name variable, etc.). In R, two popular style guides are Hadley Wickham’s style guide and Google’s."
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#interacting-with-data-in-r",
    "href": "lessons/01a_introR-R-and-RStudio.html#interacting-with-data-in-r",
    "title": "Introduction to R and RStudio",
    "section": "Interacting with data in R",
    "text": "Interacting with data in R\nR is commonly used for handling big data, and so it only makes sense that we learn about R in the context of some kind of relevant data. Let’s take a few minutes to add files to the folders we created and familiarize ourselves with the data.\n\nAdding files to your working directory\nYou can access the files we need for this workshop using the links provided below. If you right click on the link, and “Save link as..”. Choose ~/Desktop/Intro-to-R/data as the destination of the file. You should now see the file appear in your working directory. We will discuss these files a bit later in the lesson.\n\nDownload the normalized counts file by right clicking on this link\nDownload metadata file using this link\nDownload the functional analysis output file using this link\n\n\nNOTE: If the files download automatically to some other location on your laptop, you can move them to the your working directory using your file explorer or finder (outside RStudio), or navigating to the files in the Files tab of the bottom right panel of RStudio\n\n\n\nThe dataset\nIn this example dataset, we have collected whole brain samples from 12 mice and want to evaluate expression differences between them. The expression data represents normalized count data obtained from RNA-sequencing of the 12 brain samples. This data is stored in a comma separated values (CSV) file as a 2-dimensional matrix, with each row corresponding to a gene and each column corresponding to a sample.\n\n\n\n\n\nThe metadata\nWe have another file in which we identify information about the data or metadata. Our metadata is also stored in a CSV file. In this file, each row corresponds to a sample and each column contains some information about each sample.\nThe first column contains the row names, and note that these are identical to the column names in our expression data file above (albeit, in a slightly different order). The next few columns contain information about our samples that allow us to categorize them. For example, the second column contains genotype information for each sample. Each sample is classified in one of two categories: Wt (wild type) or KO (knockout). What types of categories do you observe in the remaining columns?\n\n\n\nR is particularly good at handling this type of categorical data. Rather than simply storing this information as text, the data is represented in a specific data structure which allows the user to sort and manipulate the data in a quick and efficient manner. We will discuss this in more detail as we go through the different lessons in R!\n\n\nThe functional analysis results\nWe will be using the results of the functional analysis to learn about packages/functions from the Tidyverse suite of integrated packages. These packages are designed to work together to make common data science operations like data wrangling, tidying, reading/writing, parsing, and visualizing, more user-friendly."
  },
  {
    "objectID": "lessons/01a_introR-R-and-RStudio.html#best-practices",
    "href": "lessons/01a_introR-R-and-RStudio.html#best-practices",
    "title": "Introduction to R and RStudio",
    "section": "Best practices",
    "text": "Best practices\nBefore we move on to more complex concepts and getting familiar with the language, we want to point out a few things about best practices when working with R which will help you stay organized in the long run:\n\nCode and workflow are more reproducible if we can document everything that we do. Our end goal is not just to “do stuff”, but to do it in a way that anyone can easily and exactly replicate our workflow and results. All code should be written in the script editor and saved to file, rather than working in the console.\nThe R console should be mainly used to inspect objects, test a function or get help.\nUse # signs to comment. Comment liberally in your R scripts. This will help future you and other collaborators know what each line of code (or code block) was meant to do. Anything to the right of a # is ignored by R. A shortcut for this is Ctrl+Shift+C if you want to comment an entire chunk of text."
  },
  {
    "objectID": "lessons/08_identifying-matching-elements.html",
    "href": "lessons/08_identifying-matching-elements.html",
    "title": "Advanced R, logical operators for matching",
    "section": "",
    "text": "Approximate time: 45 min",
    "crumbs": [
      "Day 2 Self-learning",
      "Advanced R, logical operators for matching"
    ]
  },
  {
    "objectID": "lessons/08_identifying-matching-elements.html#learning-objectives",
    "href": "lessons/08_identifying-matching-elements.html#learning-objectives",
    "title": "Advanced R, logical operators for matching",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDescribe the use of %in% operator.\nExplain the user case for any and all functions.",
    "crumbs": [
      "Day 2 Self-learning",
      "Advanced R, logical operators for matching"
    ]
  },
  {
    "objectID": "lessons/08_identifying-matching-elements.html#logical-operators-for-identifying-matching-elements",
    "href": "lessons/08_identifying-matching-elements.html#logical-operators-for-identifying-matching-elements",
    "title": "Advanced R, logical operators for matching",
    "section": "Logical operators for identifying matching elements",
    "text": "Logical operators for identifying matching elements\nOftentimes, we encounter different analysis tools that require multiple input datasets. It is not uncommon for these inputs to need to have the same row names, column names, or unique identifiers in the same order to perform the analysis. Therefore, knowing how to reorder datasets and determine whether the data matches is an important skill.\nIn our use case, we will be working with genomic data. We have gene expression data generated by RNA-seq, which we had downloaded previously; in addition, we have a metadata file corresponding to the RNA-seq samples. The metadata contains information about the samples present in the gene expression file, such as which sample group each sample belongs to and any batch or experimental variables present in the data.\nLet’s read in our gene expression data (RPKM matrix) that we downloaded previously:\n\nrpkm_data &lt;- read.csv(\"data/counts.rpkm.csv\")\n\nTake a look at the first few lines of the data matrix to see what’s in there.\n\nhead(rpkm_data)\n\n                     sample2    sample5  sample7   sample8   sample9   sample4\nENSMUSG00000000001 19.265000 23.7222000 2.611610 5.8495400 6.5126300 24.076700\nENSMUSG00000000003  0.000000  0.0000000 0.000000 0.0000000 0.0000000  0.000000\nENSMUSG00000000028  1.032290  0.8269540 1.134410 0.6987540 0.9251170  0.827891\nENSMUSG00000000031  0.000000  0.0000000 0.000000 0.0298449 0.0597726  0.000000\nENSMUSG00000000037  0.056033  0.0473238 0.000000 0.0685938 0.0494147  0.180883\nENSMUSG00000000049  0.258134  1.0730200 0.252342 0.2970320 0.2082800  2.191720\n                      sample6   sample12   sample3   sample11  sample10\nENSMUSG00000000001 20.8198000 26.9158000 20.889500 24.0465000 24.198100\nENSMUSG00000000003  0.0000000  0.0000000  0.000000  0.0000000  0.000000\nENSMUSG00000000028  1.1686300  0.6735630  0.892183  0.9753270  1.045920\nENSMUSG00000000031  0.0511932  0.0204382  0.000000  0.0000000  0.000000\nENSMUSG00000000037  0.1438840  0.0662324  0.146196  0.0206405  0.017004\nENSMUSG00000000049  1.6853800  0.1161970  0.421286  0.0634322  0.369550\n                      sample1\nENSMUSG00000000001 19.7848000\nENSMUSG00000000003  0.0000000\nENSMUSG00000000028  0.9377920\nENSMUSG00000000031  0.0359631\nENSMUSG00000000037  0.1514170\nENSMUSG00000000049  0.2567330\n\n\nIt looks as if the sample names (header) in our data matrix are similar to the row names of our metadata file, but it’s hard to tell since they are not in the same order. We can do a quick check of the number of columns in the count data and the rows in the metadata and at least see if the numbers match up.\n\nncol(rpkm_data)\n\n[1] 12\n\nnrow(metadata)\n\n[1] 12\n\n\nWhat we want to know is, do we have data for every sample that we have metadata?",
    "crumbs": [
      "Day 2 Self-learning",
      "Advanced R, logical operators for matching"
    ]
  },
  {
    "objectID": "lessons/08_identifying-matching-elements.html#the-in-operator",
    "href": "lessons/08_identifying-matching-elements.html#the-in-operator",
    "title": "Advanced R, logical operators for matching",
    "section": "The %in% operator",
    "text": "The %in% operator\nAlthough lacking in documentation, this operator is well-used and convenient once you get the hang of it. The operator is used with the following syntax:\n\nvector1 %in% vector2\n\nIt will take each element from vector1 as input, one at a time, and evaluate if the element is present in vector2. The two vectors do not have to be the same size.\nThis operation will return a vector containing logical values to indicate whether or not there is a match. The new vector will be of the same length as vector1. Take a look at the example below:\n\nA &lt;- c(1,3,5,7,9,11)   # odd numbers\nB &lt;- c(2,4,6,8,10,12)  # even numbers\n\n# test to see if each of the elements of A is in B  \nA %in% B\n\n[1] FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nSince vector A contains only odd numbers and vector B contains only even numbers, the operation returns a logical vector containing six FALSE, suggesting that no element in vector A is present in vector B. Let’s change a couple of numbers inside vector B to match vector A:\n\nA &lt;- c(1,3,5,7,9,11)   # odd numbers\nB &lt;- c(2,4,6,8,1,5)  # add some odd numbers in \n\n\n# test to see if each of the elements of A is in B\nA %in% B\n\n[1]  TRUE FALSE  TRUE FALSE FALSE FALSE\n\n\nThe returned logical vector denotes which elements in A are also in B - the first and third elements, which are 1 and 5.\nWe saw previously that we could use the output from a logical expression to subset data by returning only the values corresponding to TRUE. Therefore, we can use the output logical vector to subset our data, and return only those elements in A, which are also in B by returning only the TRUE values:\n\n\nintersection &lt;- A %in% B\nintersection\n\n[1]  TRUE FALSE  TRUE FALSE FALSE FALSE\n\n\n\n\nA[intersection]\n\n[1] 1 5\n\n\n\nIn these previous examples, the vectors were so small that it’s easy to check every logical value by eye; but this is not practical when we work with large datasets (e.g. a vector with 1000 logical values). Instead, we can use any function. Given a logical vector, this function will tell you whether at least one value is TRUE. It provides us a quick way to assess if any of the values contained in vector A are also in vector B:\n\nany(A %in% B)\n\n[1] TRUE\n\n\nThe all function is also useful. Given a logical vector, it will tell you whether all values are TRUE. If there is at least one FALSE value, the all function will return a FALSE. We can use this function to assess whether all elements from vector A are contained in vector B.\n\nall(A %in% B)\n\n[1] FALSE\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nUsing the A and B vectors created above, evaluate each element in B to see if there is a match in A\nSubset the B vector to only return those values that are also in A.\n\n\n\nSuppose we had two vectors containing same values. How can we check if those values are in the same order in each vector? In this case, we can use == operator to compare each element of the same position from two vectors.\nThe operator returns a logical vector indicating TRUE/FALSE at each position. Then we can use all() function to check if all values in the returned vector are TRUE. If all values are TRUE, we know that these two vectors are the same. Unlike %in% operator, == operator requires that two vectors are of equal length.\n\nA &lt;- c(10,20,30,40,50)\nB &lt;- c(50,40,30,20,10)  # same numbers but backwards \n\n# test to see if each element of A is in B\nA %in% B\n\n[1] TRUE TRUE TRUE TRUE TRUE\n\n# test to see if each element of A is in the same position in B\nA == B\n\n[1] FALSE FALSE  TRUE FALSE FALSE\n\n# use all() to check if they are a perfect match\nall(A == B)\n\n[1] FALSE\n\n\nLet’s try this on our genomic data, and see whether we have metadata information for all samples in our expression data. We’ll start by creating two vectors: one is the rownames of the metadata, and one is the colnames of the RPKM data. These are base functions in R which allow you to extract the row and column names as a vector:\n\nx &lt;- rownames(metadata)\ny &lt;- colnames(rpkm_data)\n\nNow check to see that all of x are in y:\n\nall(x %in% y)\n\n[1] TRUE\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that we can use nested functions in place of x and y and still get the same result.\n\nall(rownames(metadata) %in% colnames(rpkm_data))\n\n\n\nWe know that all samples are present, but are they in the same order?\n\nall(x == y)\n\n[1] FALSE\n\n\nNo, it looks like they need to be reordered. To reorder our genomic samples, we will learn different ways to reorder data in our next lesson.\nBut before that, let’s work on the Exercises below to consolidate concepts from this lesson.\n\n\n\n\n\n\nExercises\n\n\n\nWe have a list of 6 marker genes that we are very interested in. Our goal is to extract count data for these genes using the %in% operator from the rpkm_data data frame, instead of scrolling through rpkm_data and finding them manually.\n\nFirst, let’s create a vector called important_genes with the Ensembl IDs of the 6 genes we are interested in:\n\n\nimportant_genes &lt;- c(\"ENSMUSG00000083700\", \"ENSMUSG00000080990\", \n                     \"ENSMUSG00000065619\", \"ENSMUSG00000047945\", \n                     \"ENSMUSG00000081010\", \"ENSMUSG00000030970\")\n\n\nUse the %in% operator to determine if all of these genes are present in the row names of the rpkm_data data frame.\nExtract the rows from rpkm_data that correspond to these 6 genes using [] and the %in% operator. Double check the row names to ensure that you are extracting the correct rows.\nBonus question: Extract the rows from rpkm_data that correspond to these 6 genes using [], but without using the %in% operator.",
    "crumbs": [
      "Day 2 Self-learning",
      "Advanced R, logical operators for matching"
    ]
  },
  {
    "objectID": "lessons/10_setting_up_to_plot.html",
    "href": "lessons/10_setting_up_to_plot.html",
    "title": "Plotting and data visualization in R",
    "section": "",
    "text": "Describe the map() function for iterative tasks on data structures.",
    "crumbs": [
      "Day 2 Self-learning",
      "Plotting and data visualization in R"
    ]
  },
  {
    "objectID": "lessons/10_setting_up_to_plot.html#learning-objectives",
    "href": "lessons/10_setting_up_to_plot.html#learning-objectives",
    "title": "Plotting and data visualization in R",
    "section": "",
    "text": "Describe the map() function for iterative tasks on data structures.",
    "crumbs": [
      "Day 2 Self-learning",
      "Plotting and data visualization in R"
    ]
  },
  {
    "objectID": "lessons/10_setting_up_to_plot.html#setting-up-a-data-frame-for-visualization",
    "href": "lessons/10_setting_up_to_plot.html#setting-up-a-data-frame-for-visualization",
    "title": "Plotting and data visualization in R",
    "section": "Setting up a data frame for visualization",
    "text": "Setting up a data frame for visualization\nIn this lesson we want to make plots to evaluate the average expression in each sample and its relationship with the age of the mouse. So, to this end, we will be adding a couple of additional columns of information to the metadata data frame that we can utilize for plotting.\n\n\nCalculating average expression\nLet’s take a closer look at our counts data. Each column represents a sample in our experiment, and each sample has ~38K values corresponding to the expression of different transcripts. We want to compute the average value of expression for each sample eventually.\nTaking this one step at a time, what would we do if we just wanted the average expression for Sample 1 (across all transcripts)? We can use the R base package provided function called mean():\n\nmean(rpkm_ordered$sample1)\n\n[1] 10.2661\n\n\nThat is great, if we only wanted the average from one of the samples (one column in a data frame), but we need to get this information from all 12 samples, so all 12 columns. It would be ideal to get a vector of 12 values that we can add to the metadata data frame. What is the best way to do this?\nProgramming languages typically have a way to allow the execution of a single line of code or several lines of code multiple times, or in a “loop”. While “for loops” are available in R, there are other easier-to-use functions that can achieve this - for example, the apply() family of functions and the map() family of functions.\nThe map() family is a bit more intuitive to use than apply() and we will be using it today. However, if you are interested in learning more about theapply() family of functions we have materials available here.\nTo obtain mean values for all samples we can use the map_dbl() function which generates a numeric vector.\n\nlibrary(purrr)  # Load the purrr\n\nsamplemeans &lt;- map_dbl(rpkm_ordered, mean) \n\n\n\n\n\n\n\nThe map family of functions\n\n\n\nThe map() family of functions is available from the purrr package, which is part of the tidyverse suite of packages. More detailed information is available in the R for Data Science book. This family includes several functions, each taking a vector as input and outputting a vector of a specified type. For example, we can use these functions to execute some task/function on every element in a vector, or every column in a dataframe, or every component of a list, and so on.\n\nmap() creates a list.\nmap_lgl() creates a logical vector.\nmap_int() creates an integer vector.\nmap_dbl() creates a “double” or numeric vector.\nmap_chr() creates a character vector.\n\nThe syntax for the map() family of functions is:\n\n## DO NOT RUN\nmap(object, function_to_apply)\n\nIf you would like to practice with the map() family of functions, we have additional materials available.\n\n\n\n\nCreating a new metadata object with additional information\nBecause the input was 12 columns of information the output of map_dbl() is a named vector of length 12.\n\n# Named vectors have a name assigned to each element \n# instead of just referring to them as indices ([1], [2] and so on)\nsamplemeans\n\n  sample1   sample2   sample3   sample4   sample5   sample6   sample7   sample8 \n10.266102 10.849759  9.452517 15.833872 15.590184 15.551529 15.522219 13.808281 \n  sample9  sample10  sample11  sample12 \n14.108399 10.743292 10.778318  9.754733 \n\n# Check length of the vector before adding it to the data frame\nlength(samplemeans)\n\n[1] 12\n\n\nLet’s also create a vector with the ages of each of the mice in our data set.\n\n# Create a numeric vector with ages. Note that there are 12 elements here\nage_in_days &lt;- c(40, 32, 38, 35, 41, 32, 34, 26, 28, 28, 30, 32)        \n\nNow, we are ready to combine the metadata data frame with the two new vectors to create a new data frame with 5 columns\n\n# Add the new vector as the last column to the new_metadata dataframe\nnew_metadata &lt;- data.frame(metadata, samplemeans, age_in_days) \n\n\n# Take a look at the new_metadata object\nView(new_metadata)\n\n\n\n\n\n\n\nNote\n\n\n\nNote that we could have also combined columns using the cbind() function as shown in the code below:\n\n## DO NOT RUN\nnew_metadata &lt;- cbind(metadata, samplemeans, age_in_days)\n\nThe two functions work identically with the exception of assigning row names. For example, if we were combining columns and wanted to add in a vector of row names, we could easily do so in data.frame() with the use of the row.names argument. This argument is not available for the cbind() function.\n\n\nWe are now ready for plotting and data visualization!",
    "crumbs": [
      "Day 2 Self-learning",
      "Plotting and data visualization in R"
    ]
  },
  {
    "objectID": "lessons/16_offboarding.html",
    "href": "lessons/16_offboarding.html",
    "title": "Transferring Project from Posit Cloud",
    "section": "",
    "text": "Approximate time: 15 minutes"
  },
  {
    "objectID": "lessons/16_offboarding.html#learning-objectives",
    "href": "lessons/16_offboarding.html#learning-objectives",
    "title": "Transferring Project from Posit Cloud",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nTransfer data from the shared workspace to a local RStudio Project or personal Posit Cloud workspace"
  },
  {
    "objectID": "lessons/16_offboarding.html#transferring-rstudio-project-to-your-personal-posit-cloud-workspace",
    "href": "lessons/16_offboarding.html#transferring-rstudio-project-to-your-personal-posit-cloud-workspace",
    "title": "Transferring Project from Posit Cloud",
    "section": "Transferring RStudio Project to your personal Posit Cloud Workspace",
    "text": "Transferring RStudio Project to your personal Posit Cloud Workspace\nIn order to transfer the RStudio Project from the Harvard Chan Bioinformatics Core’s Introduction to R Workspace to your own workspace, go to the workspace page and click on the moving dolly icon.\n\nNext, select “Your Workspace” and click “OK”. You can navigate to your workspace now and see your project there. One advantage of transferring the project to your Posit Cloud workspace rather than locally is that the installed packages will remain installed following the transfer."
  },
  {
    "objectID": "lessons/16_offboarding.html#downloading-the-rstudio-project-for-local-use",
    "href": "lessons/16_offboarding.html#downloading-the-rstudio-project-for-local-use",
    "title": "Transferring Project from Posit Cloud",
    "section": "Downloading the RStudio Project for local use",
    "text": "Downloading the RStudio Project for local use\nAlternatively, you can also download the RStudio Project and open it locally in RStudio. In order to be able to open the RStudio Project locally, you will need to have both R and RStudio installed on your local computer. You can download them from the links below:\n\nR\nRStudio\n\nOne advantage to this method is that you will not be limited in your computational resources like you would be on Posit Cloud. However, the disadvantage is that the installed packages will not transfer. This is because the packages were compiled against the operating system in Posit Cloud and not your local operating system.\nIn order to download the RStudio project, click on the download icon in the workspace corresponding to the Introduction to R project.\n\nThis will prepare the download and then let you know that the project is ready to download.\nClick the “Download” button and a .zip compressed directory will be downloaded. Uncompress the directory, enter the directory and double-click on the R project file (the file with the .Rproj extension). This should open up RStudio and allow you to work on the RStudio Project locally."
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html",
    "href": "lessons/01b_introR-R-and-RStudio.html",
    "title": "Introduction to R and RStudio",
    "section": "",
    "text": "Approximate time: 45 minutes",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#learning-objectives",
    "href": "lessons/01b_introR-R-and-RStudio.html#learning-objectives",
    "title": "Introduction to R and RStudio",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDescribe what R and RStudio are.\nInteract with R using RStudio.\nFamiliarize various components of RStudio.\nEmploy variables in R.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#what-is-r",
    "href": "lessons/01b_introR-R-and-RStudio.html#what-is-r",
    "title": "Introduction to R and RStudio",
    "section": "What is R?",
    "text": "What is R?\nThe common misconception is that R is a programming language but in fact it is much more than that. Think of R as an environment for statistical computing and graphics, which brings together a number of features to provide powerful functionality.\nThe R environment combines:\n\nEffective handling of big data\nCollection of integrated tools\nGraphical facilities\nSimple and effective programming language",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#why-use-r",
    "href": "lessons/01b_introR-R-and-RStudio.html#why-use-r",
    "title": "Introduction to R and RStudio",
    "section": "Why use R?",
    "text": "Why use R?\n\nR is a powerful, extensible environment. It has a wide range of statistics and general data analysis and visualization capabilities.\n\nData handling, wrangling, and storage\nWide array of statistical methods and graphical techniques available\nEasy to install on any platform and use (and it’s free!)\nOpen source with a large and growing community of peers\n\n\nExamples of R used in the media and science\n\n“At the BBC data team, we have developed an R package and an R cookbook to make the process of creating publication-ready graphics in our in-house style…” - BBC Visual and Data Journalism cookbook for R graphics\n“R package of data and code behind the stories and interactives at FiveThirtyEight.com, a data-driven journalism website founded by Nate Silver (initially began as a polling aggregation site, but now covers politics, sports, science and pop culture) and owned by ESPN…” - fivethirtyeight Package\nSingle Cell RNA-seq Data analysis with Seurat",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#what-is-rstudio",
    "href": "lessons/01b_introR-R-and-RStudio.html#what-is-rstudio",
    "title": "Introduction to R and RStudio",
    "section": "What is RStudio?",
    "text": "What is RStudio?\nRStudio is freely available open-source Integrated Development Environment (IDE). RStudio provides an environment with many features to make using R easier and is a great alternative to working on R in the terminal.\n\n\nGraphical user interface, not just a command prompt\nGreat learning tool\nFree for academic use\nPlatform agnostic\nOpen source\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are using these materials for a locally installed version of RStudio, please use this lesson instead.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#what-is-posit-cloud",
    "href": "lessons/01b_introR-R-and-RStudio.html#what-is-posit-cloud",
    "title": "Introduction to R and RStudio",
    "section": "What is Posit Cloud?",
    "text": "What is Posit Cloud?\nPosit is the open-source data science company who manages RStudio. While many R users download Rstudio to run their analyses locally, Posit offers a service called Posit Cloud which allows users to carry out their analyses in the cloud. There are advantages to this model including:\n\nYour analyses are available from any computer in the world\nSharing Rstudio projects can be easier\n\n\nHowever, there are restrictions on the free accounts that come from Posit Cloud including:\n\nMaximum of 25 projects\n25 compute hours per month\n1GB maximum of RAM",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#why-are-we-using-posit-cloud",
    "href": "lessons/01b_introR-R-and-RStudio.html#why-are-we-using-posit-cloud",
    "title": "Introduction to R and RStudio",
    "section": "Why are we using Posit Cloud?",
    "text": "Why are we using Posit Cloud?\nGiven the restrictions on compute time and RAM, you might wonder why we are teaching you R using Posit Cloud? And the answer is that Posit Cloud offers a great environment for teaching from and all of the principles that we learn using R and RStudio on Posit Cloud will apply to your local installation of R and RStudio as well. Some of these benefits include:\n\nShared operating system for package installations\nShared versions of R and packages\nAllows instructors to take control of your RStudio environment to help troubleshoot issues\nCan pre-load data to analyze\n\nOur recommendation is for you to familiarize yourself with R and RStudio in this workshop in a common shared environment on Posit Cloud and then take these skills with you and implement them on your own analyses on a local installation of R and RStudio.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#entering-the-introduction-to-r-workspace-on-posit-cloud",
    "href": "lessons/01b_introR-R-and-RStudio.html#entering-the-introduction-to-r-workspace-on-posit-cloud",
    "title": "Introduction to R and RStudio",
    "section": "Entering the Introduction to R Workspace on Posit Cloud",
    "text": "Entering the Introduction to R Workspace on Posit Cloud\nBefore you are able to use Posit Cloud, you will need to make a free account on Posit by following this link if you have not done so already. Once you have made an account on Posit Cloud, the instructors to the workshop will have shared a link with you to join the Introduction to R workspace hosted by the Harvard Chan Bioinformatics Core. This will take you to a webpage that looks like this:\n\nOnce you hit the “Join” Button and it will take you to a webpage that looks like the one below:\n\nYou have now joined the Harvard Chan Bioinformatics Core’s Introduction to R workspace on Posit Cloud.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#overview-of-posit-cloud-workspaces",
    "href": "lessons/01b_introR-R-and-RStudio.html#overview-of-posit-cloud-workspaces",
    "title": "Introduction to R and RStudio",
    "section": "Overview of Posit Cloud Workspaces",
    "text": "Overview of Posit Cloud Workspaces\nIn the left-hand panel you should see a section called “Spaces”. Within it you should see three options:\n\nYour Workspace - This is where you can use Posit Cloud’s resources in accordance with your account’s limits. If it is the free account then it would be 25 compute hours per month and 1GB of RAM.\nIntroduction to R - This is the Harvard Chan Bioinformatics Core’s Workspace and we set the compute limits. This workspace is only to be used for the workshop and not personal use outside of the workshop.\n+ New Space - This is what you can use to create a new workspace that is tied to your personal account limits.\n\nSelect the Introduction to R workspace. This will be the workspace that we will be working within for this workshop.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#what-is-a-project-in-rstudio",
    "href": "lessons/01b_introR-R-and-RStudio.html#what-is-a-project-in-rstudio",
    "title": "Introduction to R and RStudio",
    "section": "What is a project in RStudio?",
    "text": "What is a project in RStudio?\nIt is simply a directory (or folder) that contains everything related your analyses for a specific project. RStudio projects are useful when you are working on context-specific analyses and you wish to keep them separate. When creating a project in RStudio you associate it with a working directory of your choice (either an existing one, or a new one). A . RProj file is created within that directory and that keeps track of your command history and variables in the environment. The . RProj file can be used to open the project in its current state but at a later date.\nWhen a project is (re)opened within RStudio the following actions are taken:\n\nA new R session (process) is started\nThe .RData file in the project’s main directory is loaded, populating the environment with any objects that were present when the project was closed.\nThe .Rhistory file in the project’s main directory is loaded into the RStudio History pane (and used for Console Up/Down arrow command history).\nThe current working directory is set to the project directory.\nPreviously edited source documents are restored into editor tabs\nOther RStudio settings (e.g. active tabs, splitter positions, etc.) are restored to where they were the last time the project was closed.\n\nInformation adapted from RStudio Support Site",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#starting-a-project-on-posit-cloud",
    "href": "lessons/01b_introR-R-and-RStudio.html#starting-a-project-on-posit-cloud",
    "title": "Introduction to R and RStudio",
    "section": "Starting a Project on Posit Cloud",
    "text": "Starting a Project on Posit Cloud\nWe have already begun setting up the project for you and you should see a project called “Intro-to-R” within the Introduction to R workspace:\n\n\n\n\n\n\n\nNote\n\n\n\nWe have instructions on how to create an RStudio project locally in this lesson.\n\n\n\n\n\n\n\n\nNote\n\n\n\nOnce you have opened the “Intro-to-R” on Posit Cloud for the first time, it will make a derived duplicate of the project that you are working on in our Introduction to R Workspace. In the future, you can click on either R project to come back to the point where you left off.\n\n\nThe RStudio interface should now look like this:\n\nNext, we are going to create an Rscript to keep a record of our work, but first we will implement good data management practices and create a folder to hold this script. In the bottom-right panel there should be a button that has a folder with a green plus on it and says “New Folder”, click this button:\n\n\n\n\n\n\n\nNote\n\n\n\nDepending on the size of your window, the “New Folder” button may just have the icon or the icon and the word “Folder”.\n\n\nA window should pop-up prompting you to provide a name for the folder. Type “scripts” into the text box and click “OK”:\n\nNow in the bottom-left panel, you will see a “scripts” folder.\nNext, we will create the Rscript that we will write our code in. In order to create an Rscript, click on the “File” menu option in the top-left, then “New File” and then select “R Script”.\n\nThis will create an R Script as the top panel on the left side of your RStudio window.\n\nBefore we go any further, let’s save our new R Script by following the steps listed below:\n\nClick on the “File” menu option in the top-left and find “Save As…”.\nYou will see a finder window pop-up showng you working directory. Click the “scripts” folder.\nLet’s name our R Script as “Intro-to-R.R” in the text field and click on the “Save” button\n\nNow our RStudio window should look like this:",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#rstudio-interface",
    "href": "lessons/01b_introR-R-and-RStudio.html#rstudio-interface",
    "title": "Introduction to R and RStudio",
    "section": "RStudio Interface",
    "text": "RStudio Interface\nThe RStudio interface has four main panels:\n\nConsole: This is where you can type commands and see output. The console is all you would see if you ran R in the command line without RStudio.\nScript editor: This is where you can type out commands and save to file. You can also submit the commands to run in the console.\nEnvironment/History: Environment shows all active objects and history keeps track of all commands run in console\nFiles/Plots/Packages/Help: “Files” shows a file browser and “Plots” will populate when you create a plot. “Packages” will help you manage packages from CRAN and Bioconductor. “Help” holds manuals to the functions within R.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#organizing-your-working-directory-setting-up",
    "href": "lessons/01b_introR-R-and-RStudio.html#organizing-your-working-directory-setting-up",
    "title": "Introduction to R and RStudio",
    "section": "Organizing your working directory & setting up",
    "text": "Organizing your working directory & setting up\n\nViewing your working directory\nBefore we organize our working directory, let’s check to see where our current working directory is located by typing into the console:\n\ngetwd()\n\nYour working directory should be /cloud/project. This is where our R project is being hosted. The working directory is where RStudio will automatically look for any files you bring in and where it will automatically save any files you create, unless otherwise specified.\nYou can visualize your working directory by selecting the Files tab from the Files/Plots/Packages/Help window.\n\nIf you wanted to choose a different directory to be your working directory, you could navigate to a different folder in the Files tab, then, click on the More dropdown menu which appears as a Cog and select Set As Working Directory.\n\n\n\n\n\n\n\nExercise\n\n\n\nTo organize your working directory for a particular analysis, you should separate the original data (raw data) from intermediate datasets. For instance, you may want to create a data/ directory within your working directory that stores the raw data, a scripts/ directory for your R scripts, a results/ directory for intermediate datasets and a figures/ directory for the plots you will generate.\nWe have provided you with R project containing the data/ directory and we made our scripts/ directory together. For this exercise create the results/ and figures/ directories.\nWhen finished, your working directory should look like this:\n\n\n\n\n\nSetting up\nThis is more of a housekeeping task. We will be writing long lines of code in our script editor and want to make sure that the lines “wrap” and you don’t have to scroll back and forth to look at your long line of code.\nClick on “Code” at the top of your RStudio screen and left-click “Soft Wrap Long Lines” in the pull down menu.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#interacting-with-r",
    "href": "lessons/01b_introR-R-and-RStudio.html#interacting-with-r",
    "title": "Introduction to R and RStudio",
    "section": "Interacting with R",
    "text": "Interacting with R\nNow that we have our interface and directory structure set up, let’s start playing with R! There are two main ways of interacting with R in RStudio: using the console or by using script editor (plain text files that contain your code).\n\nConsole window\nThe console window (in RStudio, the bottom left panel) is the place where R is waiting for you to tell it what to do, and where it will show the results of a command. You can type commands directly into the console, but they will be forgotten when you close the session.\nLet’s test it out:\n\n3 + 5\n\n[1] 8\n\n\n\n\nScript editor\nA better practice is to enter the commands in the script editor and save the script. You are encouraged to comment liberally to describe the commands you are running using #. This way, you have a complete record of what you did, you can easily show others how you did it and you can do it again later on if needed.\nThe Rstudio script editor allows you to ‘send’ the current line or the currently highlighted text to the R console by clicking on the Run button in the upper-right hand corner of the script editor.\nNow let’s try entering commands to the script editor and using the comments character # to add descriptions and highlighting the text to run:\n\n# Intro to R Lesson\n# June 3rd, 2025\n\n# Interacting with R\n\n## I am adding 3 and 5. R is fun!\n3 + 5\n\n[1] 8\n\n\n\n\n\nAlternatively, you can send code to the console from the script editor to be run by pressing the Ctrl and Return/Enter keys at the same time as a shortcut.\n\n\n\nYou should see the command run in the console and output the result.\n\nWhat happens if we do that same command without the comment symbol #? Re-run the command after removing the # sign in the front:\n\nI am adding 3 and 5. R is fun!\n3+5\n\nNow R is trying to run that sentence as a command, and it doesn’t work. We get an error in the console:\n\n\n\n\n\n\nWarning\n\n\n\nError: unexpected symbol in “I am”\n\n\nThis means that the R interpreter did not know what to do with that command. Reintroduce the # to re-comment the appropriate line.\n\n\nConsole command prompt\nInterpreting the command prompt can help understand when R is ready to accept commands. Below lists the different states of the command prompt and how you can exit a command:\nConsole is ready to accept commands: &gt;.\nIf R is ready to accept commands, the R console shows a &gt; prompt.\nWhen the console receives a command (by directly typing into the console or running from the script editor (Ctrl-Enter), R will try to execute it.\nAfter running, the console will show the results and come back with a new &gt; prompt to wait for new commands.\nConsole is waiting for you to enter more data: +.\nIf R is still waiting for you to enter more data because it isn’t complete yet, the console will show a + prompt. It means that you haven’t finished entering a complete command. Often this can be due to you having not ‘closed’ a parenthesis or quotation.\nEscaping a command and getting a new prompt: ESC\nIf you’re in Rstudio and you can’t figure out why your command isn’t running, you can click inside the console window and press ESC to escape the command and bring back a new prompt &gt;.\n\n\nKeyboard shortcuts in RStudio\nIn addition to some of the shortcuts described earlier in this lesson, we have listed a few more that can be helpful as you work in RStudio.\n\n\n\n\n\n\n\nkey\naction\n\n\n\n\nCtrl+Enter\nRun command from the script editor in the console\n\n\nESC\nEscape the current command to return to the command prompt\n\n\nCtrl+1\nMove cursor from console to script editor\n\n\nCtrl+2\nMove cursor from script editor to console\n\n\nTab\nUse this key to complete a file path\n\n\nCtrl+Shift+C\nComment the block of highlighted text\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTry highlighting only 3 + from your script editor and running it. Find a way to bring back the command prompt &gt; in the console.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#the-r-syntax",
    "href": "lessons/01b_introR-R-and-RStudio.html#the-r-syntax",
    "title": "Introduction to R and RStudio",
    "section": "The R syntax",
    "text": "The R syntax\nNow that we know how to talk with R via the script editor or the console, we want to use R for something more than adding numbers. To do this, we need to know more about the R syntax.\nThe main “parts of speech” in R (syntax) include:\n\nthe comments (#) and how they are used to document content\nvariables and functions\nthe assignment operator &lt;-\nthe = for arguments in functions\n\nNOTE: Indentation and consistency in spacing is used to improve clarity and legibility\nWe will go through each of these “parts of speech” in more detail, starting with the assignment operator.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#assignment-operator",
    "href": "lessons/01b_introR-R-and-RStudio.html#assignment-operator",
    "title": "Introduction to R and RStudio",
    "section": "Assignment operator",
    "text": "Assignment operator\nTo do useful and interesting things in R, we need to assign values to variables using the assignment operator, &lt;-. For example, we can use the assignment operator to assign the value of 3 to x by executing:\n\nx &lt;- 3\n\nThe assignment operator (&lt;-) assigns values on the right to variables on the left.\nIn RStudio, typing Alt + - (push Alt at the same time as the - key, on Mac type option + -) will write &lt;- in a single keystroke.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#variables",
    "href": "lessons/01b_introR-R-and-RStudio.html#variables",
    "title": "Introduction to R and RStudio",
    "section": "Variables",
    "text": "Variables\nA variable is a symbolic name for (or reference to) information. Variables in computer programming are analogous to “buckets”, where information can be maintained and referenced. On the outside of the bucket is a name. When referring to the bucket, we use the name of the bucket, not the data stored in the bucket.\nIn the example above, we created a variable or a “bucket” called x. Inside we put a value, 3.\nLet’s create another variable called y and give it a value of 5.\n\ny &lt;- 5\n\nWhen assigning a value to an variable, R does not print anything to the console. You can force it to print the value by using parentheses or by typing the variable name.\n\ny\n\n[1] 5\n\n\nYou can also view information on the variable by looking in your Environment window in the upper right-hand corner of the RStudio interface.\n\n\n\nNow we can reference these buckets by name to perform mathematical operations on the values contained within. What do you get in the console for the following operation:\n\nx + y\n\n[1] 8\n\n\nTry assigning the results of this operation to another variable called number.\n\nnumber &lt;- x + y\n\n\n\n\n\n\n\nExercises\n\n\n\nTry changing the value of the variable x to 5. What happens to number?\nNow try changing the value of variable y to contain the value 10. What do you need to do, to update the variable number?\n\n\n\nTips on variable names\nVariables can be given almost any name, such as x, current_temperature, or subject_id. However, there are some rules / suggestions you should keep in mind:\n\nMake your names explicit and not too long.\nAvoid names starting with a number (2x is not valid but x2 is)\nAvoid names of fundamental functions in R (e.g., if, else, for, see here for a complete list). In general, even if it’s allowed, it’s best to not use other function names (e.g., c, T, mean, data) as variable names. When in doubt, you can check the “Help” tab to see if the name is already in use.\nAvoid dots (.) within a variable name, as in my.dataset. There are many functions in R with dots in their names for historical reasons, but because dots have a special meaning in R (for methods) and other programming languages, it’s best to avoid them.\nUse nouns for object names and verbs for function names\nKeep in mind that R is case sensitive (e.g., genome_length is different from Genome_length)\nBe consistent with the styling of your code (where you put spaces, how you name variable, etc.). In R, two popular style guides are Hadley Wickham’s style guide and Google’s.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#interacting-with-data-in-r",
    "href": "lessons/01b_introR-R-and-RStudio.html#interacting-with-data-in-r",
    "title": "Introduction to R and RStudio",
    "section": "Interacting with data in R",
    "text": "Interacting with data in R\nR is commonly used for handling big data, and so it only makes sense that we learn about R in the context of some kind of relevant data. Let’s take a few minutes to familiarize ourselves with the data.\n\nVisualizing the provided files\nYou can access the files we need for this workshop by clicking on the data/ directory within the “Files” tab. Within here, you should find the four files that we will be working with.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you wanted to add files onto the Posit Cloud server you could do this with the “Upload” button in the “Files” tab.\n\n\n\n\n\n\n\n\nNote\n\n\n\nAdding files when working in RStudio locally is a bit different. Please reference this lesson for instructions to do this.\n\n\n\n\nThe dataset\nIn this example dataset, we have collected whole brain samples from 12 mice and want to evaluate expression differences between them. The expression data represents normalized count data obtained from RNA-sequencing of the 12 brain samples. This data is stored in a comma separated values (CSV) file as a 2-dimensional matrix, with each row corresponding to a gene and each column corresponding to a sample.\n\n\n\n\n\nThe metadata\nWe have another file in which we identify information about the data or metadata. Our metadata is also stored in a CSV file. In this file, each row corresponds to a sample and each column contains some information about each sample.\nThe first column contains the row names, and note that these are identical to the column names in our expression data file above (albeit, in a slightly different order). The next few columns contain information about our samples that allow us to categorize them. For example, the second column contains genotype information for each sample. Each sample is classified in one of two categories: Wt (wild type) or KO (knockout). What types of categories do you observe in the remaining columns?\n\n\n\nR is particularly good at handling this type of categorical data. Rather than simply storing this information as text, the data ican be represented in a specific data structure which allows the user to sort and manipulate the data in a quick and efficient manner. We will discuss this in more detail as we go through the different lessons in R!\n\n\nThe functional analysis results\nWe will be using the results from a functional analysis to learn about packages/functions from the Tidyverse suite of integrated packages. These packages are designed to work together to make common data science operations, like data wrangling, tidying, reading/writing, parsing and visualizing, more user-friendly.\n\n\nThe animals dataset\nWe will be using this toy dataset for an activity to practice our Tidyverse skills.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/01b_introR-R-and-RStudio.html#recommended-practices",
    "href": "lessons/01b_introR-R-and-RStudio.html#recommended-practices",
    "title": "Introduction to R and RStudio",
    "section": "Recommended practices",
    "text": "Recommended practices\nBefore we move on to more complex concepts and getting familiar with the language, we want to point out a few things about recommended practices when working with R, which will help you stay organized in the long run:\n\nCode and workflows are more reproducible if we can document everything that we do. Our end goal is not just to “do stuff”, but to do it in a way that anyone can easily and exactly replicate our workflow and results. All code should be written in the script editor and saved to file, rather than working in the console.\nThe R console should be mainly used to inspect objects, test a function or get help.\nUse # signs to comment. Comment liberally in your R scripts. This will help future you and other collaborators know what each line of code (or code block) was meant to do. Anything to the right of a # is ignored by R. A shortcut for this is Ctrl+Shift+C if you want to comment an entire chunk of text.",
    "crumbs": [
      "Day 1:",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "lessons/homework/Intro_to_R_hw.html",
    "href": "lessons/homework/Intro_to_R_hw.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "lessons/homework/Intro_to_R_hw.html#creating-vectorsfactors-and-dataframes",
    "href": "lessons/homework/Intro_to_R_hw.html#creating-vectorsfactors-and-dataframes",
    "title": "",
    "section": "Creating vectors/factors and dataframes",
    "text": "Creating vectors/factors and dataframes\n\nWe are performing RNA-Seq on cancer samples being treated with three different types of treatment (A, B, and P). You have 12 samples total, with 4 replicates per treatment. Write the R code you would use to construct your metadata table as described below.\n\nCreate the vectors/factors for each column (Hint: you can type out each vector/factor, or if you want the process go faster try exploring the rep() function).\nPut them together into a dataframe called meta.\nUse the rownames() function to assign row names to the dataframe (Hint: you can type out the row names as a vector, or if you want the process go faster try exploring the paste() function).\n\nYour finished metadata table should have information for the variables sex, stage, treatment, and myc levels:\n\n\n\n\nsex\nstage\ntreatment\nmyc\n\n\n\n\nsample1\nM\nI\nA\n2343\n\n\nsample2\nF\nII\nA\n457\n\n\nsample3\nM\nII\nA\n4593\n\n\nsample4\nF\nI\nA\n9035\n\n\nsample5\nM\nII\nB\n3450\n\n\nsample6\nF\nII\nB\n3524\n\n\nsample7\nM\nI\nB\n958\n\n\nsample8\nF\nII\nB\n1053\n\n\nsample9\nM\nII\nP\n8674\n\n\nsample10\nF\nI\nP\n3424\n\n\nsample11\nM\nII\nP\n463\n\n\nsample12\nF\nII\nP\n5105"
  },
  {
    "objectID": "lessons/homework/Intro_to_R_hw.html#subsetting-vectorsfactors-and-dataframes",
    "href": "lessons/homework/Intro_to_R_hw.html#subsetting-vectorsfactors-and-dataframes",
    "title": "",
    "section": "Subsetting vectors/factors and dataframes",
    "text": "Subsetting vectors/factors and dataframes\n\nUsing the meta data frame from question #1, write out the R code you would use to perform the following operations (questions DO NOT build upon each other):\n\nreturn only the treatment and sex columns using []:\nreturn the treatment values for samples 5, 7, 9, and 10 using []:\nuse filter() to return all data for those samples receiving treatment P:\nuse filter()/select()to return only the stage and treatment columns for those samples with myc &gt; 5000:\nremove the treatment column from the dataset using []:\nremove samples 7, 8 and 9 from the dataset using []:\nkeep only samples 1-6 using []:\nadd a column called pre_treatment to the beginning of the dataframe with the values T, F, F, F, T, T, F, T, F, F, T, T (Hint: use cbind()):\nchange the names of the columns to: “A”, “B”, “C”, “D”:"
  },
  {
    "objectID": "lessons/homework/Intro_to_R_hw.html#extracting-components-from-lists",
    "href": "lessons/homework/Intro_to_R_hw.html#extracting-components-from-lists",
    "title": "",
    "section": "Extracting components from lists",
    "text": "Extracting components from lists\n\nCreate a new list, list_hw with three components, the glengths vector, the dataframe df, and number value. Use this list to answer the questions below . list_hw has the following structure (NOTE: the components of this list are not currently named):\n   [[1]]\n   [1]   4.6  3000.0 50000.0 \n\n   [[2]]\n          species  glengths \n     1    ecoli    4.6\n     2    human    3000.0\n     3    corn     50000.0\n\n   [[3]]\n   [1] 8\n\nWrite out the R code you would use to perform the following operations (questions DO NOT build upon each other): - return the second component of the list: - return 50000.0 from the first component of the list: - return the value human from the second component: - give the components of the list the following names: “genome_lengths”, “genomes”, “record”:"
  },
  {
    "objectID": "lessons/homework/Intro_to_R_hw.html#creating-figures-with-ggplot2",
    "href": "lessons/homework/Intro_to_R_hw.html#creating-figures-with-ggplot2",
    "title": "",
    "section": "Creating figures with ggplot2",
    "text": "Creating figures with ggplot2\n\n\n\nplot_image\n\n\n\nCreate the same plot as above using ggplot2 using the provided metadata and counts datasets. The metadata table describes an experiment that you have setup for RNA-seq analysis, while the associated count matrix gives the normalized counts for each sample for every gene. Download the count matrix and metadata using the links provided.\nFollow the instructions below to build your plot. Write the code you used and provide the final image.\n\nRead in the metadata file using: meta &lt;- read.delim(\"Mov10_full_meta.txt\", sep=\"\\t\", row.names=1)\nRead in the count matrix file using: data &lt;- read.delim(\"normalized_counts.txt\", sep=\"\\t\", row.names=1)\nCreate a vector called expression that contains the normalized count values from the row in normalized_counts that corresponds to the MOV10 gene.\nCheck the class of this expression vector. Then, convert it to a numeric vector using as.numeric(expression)\nBind that vector to your metadata data frame (meta) and call the new data frame df.\nCreate a ggplot by constructing the plot line by line:\n\nInitialize a ggplot with your df as input.\nAdd the geom_jitter() geometric object with the required aesthetics which are x and y.\nColor the points based on sampletype\nAdd the theme_bw() layer\nAdd the title “Expression of MOV10” to the plot\nChange the x-axis label to be blank\nChange the y-axis label to “Normalized counts”\nUsing theme() change the following properties of the plot:\n\nRemove the legend (Hint: use ?theme help and scroll down to legend.position)\nChange the plot title size to 1.5x the default and center align\nChange the axis title to 1.5x the default size\nChange the size of the axis text only on the y-axis to 1.25x the default size\nRotate the x-axis text to 45 degrees using axis.text.x=element_text(angle=45, hjust=1)"
  },
  {
    "objectID": "lessons/basic_plots_in_r.html",
    "href": "lessons/basic_plots_in_r.html",
    "title": "Plotting and data visualization in R (basics)",
    "section": "",
    "text": "Approximate time: 45 minutes"
  },
  {
    "objectID": "lessons/basic_plots_in_r.html#basic-plots-in-r",
    "href": "lessons/basic_plots_in_r.html#basic-plots-in-r",
    "title": "Plotting and data visualization in R (basics)",
    "section": "Basic plots in R",
    "text": "Basic plots in R\nR has a number of built-in tools for basic graph types such as histograms, scatter plots, bar charts, boxplots and much more. Rather than going through all of different types, we will focus on plot(), a generic function for plotting x-y data.\nTo get a quick view of the different things you can do with plot, let’s use the example() function:\n\nexample(\"plot\")\n\nHere, you will find yourself having to press &lt;Return&gt; so you can scroll through the different types of graphs generated by plot. Take note of the different parameters used with each command and how that affects the aesthetics of the plot.\n\ndev.off() \n# this means \"device off\" and we will be going over what this does at the end of this section. \n# For now, it makes it so that when we draw plots they show up where they are supposed to?\n\n\nScatterplot\nFor some hands-on practice we are going to use plot to draw a scatter plot and obtain a graphical view of the relationship between two sets of continuous numeric data. From our new_metadata file we will take the samplemeans column and plot it against age_in_days, to see how mean expression changes with age.\nNow our metadata has all the information to draw a scatterplot. The base R function to do this is plot(y ~ x, data):\n\nplot(samplemeans ~ age_in_days, data=new_metadata)\n\n\n\n\n\n\n\n\nEach point represents a sample. The values on the y-axis correspond to the average expression for each sample which is dependent on the x-axis variable age_in_days. This plot is in its simplest form, we can customize many features of the plot (fonts, colors, axes, titles) through graphic options.\nFor example, let’s start by giving our plot a title and renaming the axes. We can do that by simply adding the options xlab, ylab and main as arguments to the plot() function:\n\nplot(samplemeans ~ age_in_days, data=new_metadata, main=\"Expression changes with age\", xlab=\"Age (days)\", \n    ylab=\"Mean expression\")\n\n\n\n\n\n\n\n\nWe can also change the shape of the data point using the pch option and the size of the data points using cex (specifying the amount to magnify relative to the default).\n\nplot(samplemeans ~ age_in_days, data=new_metadata, main=\"Expression changes with age\", xlab=\"Age (days)\", \n    ylab=\"Mean expression\", pch=\"*\", cex=2.0)\n\n\n\n\n\n\n\n\nWe can also add some color to the data points on the plot by adding col=\"blue\". Alternatively, you can sub in any of the default colors or you can experiment with other R packages to fiddle with better palettes.\nWe can also add color to separate the data points by information in our data frame. For example, suppose we wanted to the data points colored by celltype. We would need to specify a vector of colours and provide the factor by which we are separating samples. The first level in our factor vector (which by default is assigned alphabetically) would get assigned the first color that we list. So in this case, blue corresponds to celltype A samples and green corresponds to celltype B.\n\nplot(samplemeans ~ age_in_days, data=new_metadata, main=\"Expression changes with age\", xlab=\"Age (days)\", \n    ylab=\"Mean expression\", pch=\"*\", cex=2.0, col=c(\"blue\", \"green\")[celltype])\n\n\n\n\n\n\n\n\nThe last thing this plot needs is a figure legend describing the color scheme. It would be great if it created one for you by default, but with R base functions unfortunately it is not that easy. To draw a legend on the current plot, you need to run a new function called legend() and specify the appropriate arguments. The code to do so is provided below. Don’t worry if it seems confusing, we plan on showing you a much more intuitive way of plotting your data.\n\nplot(samplemeans ~ age_in_days, data=new_metadata, main=\"Expression changes with age\", xlab=\"Age (days)\", \n    ylab=\"Mean expression\", pch=\"*\", cex=2.0, col=c(\"blue\", \"green\")[celltype])\n\nlegend(\"topleft\", pch=\"*\", col=c(\"blue\", \"green\"), c(\"A\", \"B\"), cex=0.8,\n    title=\"Celltype\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nChange the color scheme in the scatterplot, such that it reflects the genotype of samples rather than celltype.\nUse R help to find out how to increase the size of the text on the axis labels.\n\n\n\n\n\n\n\n\n\nOther Types of Plots in Base R\n\n\n\n\n\nNOTE: we will not run these in class, but the code is provided if you are interested in exploring more on your own.\n\nBarplot\nBarplots are useful for comparing the distribution of a quantitative variable (numeric) between groups or categories. A barplot would be much more useful to compare the samplemeans (numeric variable) for each sample. We can use barplot to draw a single bar representing each sample and the height indicates the average expression level.\n\n?barplot\n# note that there is no \"data=\" argument for barplot()\n\nSimilar to the scatterplot, we can use additional arguments to specify the aesthetics that we want to change. For example, changing axis labeling and adding some color.\n\nbarplot(new_metadata$samplemeans, names.arg=c(1:12), horiz=TRUE, col=c(\"darkblue\", \"red\")[new_metadata$genotype]) \n\n\n\n\n\n\n\n\n\n\nHistogram\nIf we are interested in an overall distribution of numerical data, a histogram is what we’d want. To plot a histogram of the data use the hist command:\n\nhist(new_metadata$samplemeans)\n\n\n\n\n\n\n\n\nAgain, there are many options that we can change by modifying the default parameters. Let’s color in the bars, remove the borders and increase the number of breaks:\n\nhist(new_metadata$samplemeans, xlab=\"Mean expression level\", main=\"\", col=\"darkgrey\", border=FALSE) \n\n\n\n\n\n\n\n\n\n\nBoxplot\nUsing additional sample information from our metadata, we can use plots to compare values between different factor levels or categories. For example, we can compare the sample means across celltypes ‘typeA’ and ‘typeB’ using a boxplot.\n\n# Boxplot\nboxplot(samplemeans~celltype, data=new_metadata)"
  },
  {
    "objectID": "lessons/basic_plots_in_r.html#barplot",
    "href": "lessons/basic_plots_in_r.html#barplot",
    "title": "Plotting and data visualization in R (basics)",
    "section": "Barplot",
    "text": "Barplot\nBarplots are useful for comparing the distribution of a quantitative variable (numeric) between groups or categories. A barplot would be much more useful to compare the samplemeans (numeric variable) for each sample. We can use barplot to draw a single bar representing each sample and the height indicates the average expression level.\n\n?barplot\n# note that there is no \"data=\" argument for barplot()\n\nSimilar to the scatterplot, we can use additional arguments to specify the aesthetics that we want to change. For example, changing axis labeling and adding some color.\n\nbarplot(new_metadata$samplemeans, names.arg=c(1:12), horiz=TRUE, col=c(\"darkblue\", \"red\")[new_metadata$genotype])"
  },
  {
    "objectID": "lessons/basic_plots_in_r.html#histogram",
    "href": "lessons/basic_plots_in_r.html#histogram",
    "title": "Plotting and data visualization in R (basics)",
    "section": "Histogram",
    "text": "Histogram\nIf we are interested in an overall distribution of numerical data, a histogram is what we’d want. To plot a histogram of the data use the hist command:\n\nhist(new_metadata$samplemeans)\n\n\n\n\n\n\n\n\nAgain, there are many options that we can change by modifying the default parameters. Let’s color in the bars, remove the borders and increase the number of breaks:\n\nhist(new_metadata$samplemeans, xlab=\"Mean expression level\", main=\"\", col=\"darkgrey\", border=FALSE)"
  },
  {
    "objectID": "lessons/basic_plots_in_r.html#boxplot",
    "href": "lessons/basic_plots_in_r.html#boxplot",
    "title": "Plotting and data visualization in R (basics)",
    "section": "Boxplot",
    "text": "Boxplot\nUsing additional sample information from our metadata, we can use plots to compare values between different factor levels or categories. For example, we can compare the sample means across celltypes ‘typeA’ and ‘typeB’ using a boxplot.\n\n# Boxplot\nboxplot(samplemeans~celltype, data=new_metadata)"
  },
  {
    "objectID": "lessons/Aside_ggplot2.html",
    "href": "lessons/Aside_ggplot2.html",
    "title": "Plotting and data visualization in R",
    "section": "",
    "text": "Approximate time: 90 minutes"
  },
  {
    "objectID": "lessons/Aside_ggplot2.html#learning-objectives",
    "href": "lessons/Aside_ggplot2.html#learning-objectives",
    "title": "Plotting and data visualization in R",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nExplain the grammar of graphics syntax used by ggplot2\nDetermine how to plot different types of graphs with ggplot2 depending on the number and type of variables\nExport plots for use outside of the R environment."
  },
  {
    "objectID": "lessons/Aside_ggplot2.html#data-visualization-with-ggplot2",
    "href": "lessons/Aside_ggplot2.html#data-visualization-with-ggplot2",
    "title": "Plotting and data visualization in R",
    "section": "Data Visualization with ggplot2",
    "text": "Data Visualization with ggplot2\nWhen we are working with large sets of numbers it can be useful to display that information graphically to gain more insight. Visualization deserves an entire course of its own (there is that much to know!). In this lesson we will be plotting with the popular package ggplot2.\nMore recently, R users have moved away from base graphic options towards ggplot2 since it offers a lot more functionality as compared to the base R plotting functions. The ggplot2 syntax takes some getting used to, but once you get it, you will find it’s extremely powerful and flexible. We will start with drawing a simple X-Y scatterplot of gene_ratio versus GO_term from the bp_oe tibble. ggplot2 expects that the information being plotted is contained in a data frame or tibble (data frame-like).\nWe would typically start by loading the ggplot2 library, but it is a part of the tidyverse suite, so it was loaded in the last lesson.\n\nload(\"data/GOs_for_plotting.RData\")\n\nggplot2 syntax: To initialize the basic graph structure with this package we have to use the ggplot() function, then we add “layers” to it using the + operator. The idea is that you create a basic plot first, then additional functions are added on to build the final plot.\nLet’s start by first subsetting the bp_oe dataframe to only contain the top 30 most significant GO terms:\n\n# Load ggplot2 package\nlibrary(ggplot2)\n\n# Subset data frame\nbp_plot &lt;- bp_oe[1:30, ]\n\nNow let’s try making a plot:\n\n# What happens if we don't provide it a geom object?\nggplot(bp_plot)\n\nYou get a blank plot, because you need to specify layers using the + operator.\nOne type of layer is geometric objects. This is a mandatory layer and it specifies what type of plot you are interested in making. Examples include:\n\npoints (geom_point(), geom_jitter() for scatter plots, dot plots, etc)\nlines (geom_line(), for time series, trend lines, etc)\nboxplot (geom_boxplot(), for, well, boxplots!)\n\nFor a more exhaustive list on all possible geometric objects and when to use them check out Hadley Wickham’s RPubs or the RStudio cheatsheet.\nA plot must have at least one geom, and there can be multiple complementary geoms; there is no upper limit.\nLet’s add a geom to make a scatter plot, i.e. the geom_point() function\n\n# Provide the plot a dataset and a type of plot\nggplot(bp_plot) +\n  geom_point() \n\nYou will find that even though we have added a layer by specifying geom_point, we get an error. This is because each type of geom usually has a required set of aesthetics. Aesthetic mappings are set with the aes() function which can be nested within the geom function and can be set inside geom_point() to be specifically applied to that layer. If we supplied aesthetics within ggplot(), they will be used as defaults for every layer. Below are some examples of what is categorized as aesthetics in the ggplot2 context:\n\nposition (i.e. columns to be used for the x and y axes)\ncolor (“outside” color of the data point/bar being plotted)\nfill (“inside” color of the data point/bar being plotted)\nshape (of data points)\nlinetype\nsize (of data points)\n\nTo start, we will specify the columns for the x- and y-axis since geom_point() requires the most basic information about a scatterplot, i.e. what you want to plot on the x and y axes.\nTypically, a scatterplot is used to illustrate the relationship between two numeric variables. The x-axis represents the independent variable and the y-axis represents the dependent variable. We can test this out using two numeric columns from our bp_plot tibble:\n\n# Provide the plot a dataset, a type of plot and an aesthetics function\nggplot(bp_plot) +\n  geom_point(aes(x = overlap.size, y = p.value))\n\n\n\n\n\n\n\n\nHowever, instead of a scatterplot with numeric values on both axes, we would like to create a dotplot for visualizing the top 30 functional categories in our dataset, and how prevalent they are. Basically, we want a dotplot for visualizing functional analysis data, which plots the gene ratio values on the x-axis and the GO terms on the y-axis.\nLet’s see what happens when we add a non-numeric value to the y-axis and change the x-axis to the “gene_ratio” column:\n\nggplot(bp_plot) +\n  geom_point(aes(x = gene_ratio, y = GO_term))\n\n\n\n\n\n\n\n\nNow that we have the required aesthetics, let’s add some extras like color to the plot. Let’s say we wanted to quickly visualize significance of the GO terms in the plot, we can color the points on the plot based on p-values, by specifying the column header.\n\nggplot(bp_plot) +\n  geom_point(aes(x = gene_ratio, y = GO_term, color = p.value))\n\n\n\n\n\n\n\n\nYou will notice that there are a default set of colors that will be used so we do not have to specify which colors to use. Also, the legend has been conveniently plotted for us!\nAlternatively, we could color number of DE genes associated with each term (overlap.size).\n\nggplot(bp_plot) +\n  geom_point(aes(x = gene_ratio, y = GO_term, color = overlap.size))\n\n\n\n\n\n\n\n\nMoving forward, we are going to stick with coloring the dots based on the p.value column. Let’s explore some of the other arguments that can be specified in the geom layer.\nTo modify the size of the data points we can use the size argument. * If we add size inside aes() we could assign a numeric column to it and the size of the data points would change according to that column. * However, if we add size inside the geom_point() but outside aes() we can’t assign a column to it, instead we have to give it a numeric value. This use of size will uniformly change the size of all the data points.\n\n\n\n\n\n\nNote\n\n\n\nThis is true for several arguments, including color, shape etc. E.g. we can change all shapes to square by adding this argument to be outside the aes() function; if we put the argument inside the aes() function we could change the shape according to a (categorical) variable in our data frame or tibble.\n\n\nWe have decided that we want to change the size of all the data point to a uniform size instead of typing it to a numeric column in the input tibble. Add in the size argument by specifying a number for the size of the data point:\n\nggplot(bp_plot) +\n  geom_point(aes(x = gene_ratio, y = GO_term, , color = p.value), \n             size = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe size of the points is personal preference, and you may need to play around with the parameter to decide which size is best. That seems a bit too small, so we can try out a slightly larger size.\n\n\nAs we do that, let’s see how we can change the shape of the data point. Different shapes are available, as detailed in the RStudio ggplot2 cheatsheet. Let’s explore this parameter by changing all of the points to squares:\n\nggplot(bp_plot) +\n  geom_point(aes(x = gene_ratio, y = GO_term, , color = p.value), \n             size = 2, \n             shape = \"square\")\n\n\n\n\n\n\n\n\nNow we can start updating the plot to suit our preferences for how we want the data displayed. The labels on the x- and y-axis are also quite small and not very descriptive. To change their size and labeling, we need to add additional theme layers. The ggplot2 theme() system handles modification of non-data plot elements such as:\n\nAxis label aesthetics\nPlot background\nFacet label backround\nLegend appearance\n\nThere are built-in themes that we can use (i.e. theme_bw()) that mostly change the background/foreground colors, by adding it as additional layer. Alternatively, we can adjust specific elements of the current default theme by adding a theme() layer and passing in arguments for the things we wish to change. Or we can use both, a built-in theme layer and a custom theme layer!\nLet’s add a built-in theme layer theme_bw() first.\n\nggplot(bp_plot) +\n  geom_point(aes(x = gene_ratio, y = GO_term, , color = p.value), \n             size = 2) +\n  theme_bw()\n\n\n\n\n\n\n\n\nDo the axis labels or the tick labels get any larger by changing themes?\nNot in this case. But we can add arguments using theme() to change it ourselves. Since we are adding this layer on top (i.e later in sequence), any features we change will override what is set in the theme_bw(). Here we’ll increase the size of the axes labels to be 1.15 times the default size and the x-axis tick labels to be 1.15 times the default.\n\nggplot(bp_plot) +\n  geom_point(aes(x = gene_ratio, y = GO_term, color = p.value), \n             size = 2) +\n  theme_bw() +\n  theme(axis.text.x = element_text(size=rel(1.15)),\n        axis.title = element_text(size=rel(1.15)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen modifying the size of text we often use the rel() function to specify the size we want relative to the default. We can also provide a numeric value as we did with the data point size, but it can be cumbersome if you don’t know what the default font size is to begin with.\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can use the example(\"geom_point\") function here to explore a multitude of different aesthetics and layers that can be added to your plot. As you scroll through the different plots, take note of how the code is modified. You can use this with any of the different geom layers available in ggplot2 to learn how you can easily modify your plots!\n\n\n\n\n\n\n\n\nNote\n\n\n\nRStudio provides this very useful cheatsheet for plotting using ggplot2. Different example plots are provided and the associated code (i.e which geom or theme to use in the appropriate situation.)\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nThe current axis label text defaults to what we gave as input to geom_point (i.e the column headers). We can change this by adding additional layers called xlab() and ylab() for the x- and y-axis, respectively. Add these layers to the current plot such that:\n\nx-axis label: “Gene ratios”\ny-axis label: “Top 30 significant GO terms”\n\nAdd a ggtitle() layer to add a title to your plot.\n\nNOTE: Useful code to center your title over your plot can be done using theme(plot.title=element_text(hjust=0.5, face = \"bold\")).\n\n\n\nCustomizing data point colors\nThe plot is looking better, but it is hard to distinguish differences in significance based on the colors used. There are cheatsheets available for specifying the base R colors by name or hexadecimal code. We could specify other colors available or use pre-created color palettes from an external R package.\nTo make additional color palettes available for plotting, we can load the RColorBrewer library, which contains color palettes designed specifically for the different types of data being compared.\n\n# Install the RColorBrewer library (if you don't have it installed already)\ninstall.packages(\"RColorBrewer\")\n\n\n# Load the RColorBrewer library\nlibrary(RColorBrewer)\n\n# Check the available color palettes\ndisplay.brewer.all()\n\n\n\n\n\n\n\n\nThe output is separated into three sections based on the suggested palettes for sequential, qualitative, and diverging data.\n\nSequential palettes (top): For sequential data, with lighter colors for low values and darker colors for high values.\nQualitative palettes (middle): For categorical data, where the color does not denote differences in magnitude or value.\nDiverging palettes (bottom): For data with emphasis on mid-range values and extremes.\n\nSince our adjusted p-values are sequential, we will choose from these palettes. Let’s go with the “Yellow, orange, red” palette. We can choose how many colors from the palette to include, which may take some trial and error. We can test the colors included in a palette by using the display.brewer.pal() function, and changing if desired:\n\n# Testing the palette with six colors\ndisplay.brewer.pal(6, \"YlOrRd\")\n\n\n\n\n\n\n\n\nThe yellow might be a bit too light, and we might not need so many different colors. Let’s test with three different colors:\n\n# Testing the palette with three colors\ndisplay.brewer.pal(3, \"YlOrRd\")\n\n\n\n\n\n\n\n# Define a palette\nmypalette &lt;- brewer.pal(3, \"YlOrRd\")\n\n# how are the colors represented in the mypalette vector?\nmypalette\n\n[1] \"#FFEDA0\" \"#FEB24C\" \"#F03B20\"\n\n\nThose colors look okay, so let’s test them in our plot. We can add a color scale layer, and most often one of the following two scales will work:\n\nscale_color_manual(): for categorical data or quantiles\nscale_color_gradient() family: for continuous data.\n\nBy default, scale_color_gradient() creates a two color gradient from low to high. Since we plan to use more colors, we will use the more flexible scale_color_gradientn() function. To make the legend a bit cleaner, we will also perform a -log10 transform on the p-values (higher values means more significant).\n\nggplot(bp_plot) +\n  geom_point(aes(x = gene_ratio, y = GO_term, color = -log10(p.value)), \n             size = 2) +\n  theme_bw() +\n  theme(axis.text.x = element_text(size=rel(1.15)),\n        axis.title = element_text(size=rel(1.15))) +\n  xlab(\"Gene ratios\") +\n  ylab(\"Top 30 significant GO terms\") +\n  ggtitle(\"Dotplot of top 30 significant GO terms\") +\n  theme(plot.title = element_text(hjust=0.5, \n    face = \"bold\")) +\n  scale_color_gradientn(colors = mypalette)\n\n\n\n\n\n\n\n\nThis looks good, but we want to add better name for the legend and we want to make sure the legend title is centered and bold. To do this, we can add a name argument to scale_color_gradientn() and a new theme layer for the legend title.\n\nggplot(bp_plot) +\n  geom_point(aes(x = gene_ratio, y = GO_term, color = -log10(p.value)), \n             size = 2) +\n  theme_bw() +\n  theme(axis.text.x = element_text(size=rel(1.15)),\n        axis.title = element_text(size=rel(1.15))) +\n  xlab(\"Gene ratios\") +\n  ylab(\"Top 30 significant GO terms\") +\n  ggtitle(\"Dotplot of top 30 significant GO terms\") +\n  theme(plot.title = element_text(hjust=0.5, \n    face = \"bold\")) +\n  scale_color_gradientn(name = \"Significance \\n (-log10(padj))\", colors = mypalette) +\n  theme(legend.title = element_text(size=rel(1.15),\n    hjust=0.5, \n    face=\"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nExercises\n\nArrange bp_oe by term_percent in descending order.\nCreate a dotplot with the top 30 GO terms with highest term_percent, with term_percent as x-axis and GO_term as the y-axis.\n[Optional] Color the plot using the palette of your choice.\n\n\n\nSo far we have explored many layers that can be added to any plot with the ggplot2 package. However, we haven’t explored the different geoms available. The type of data you are plotting will determine the type of geom needed, but a nice summary of the main geoms is available on the RStudio ggplot2 cheatsheet.\nLet’s explore different geoms by creating a couple of different plots. We’ll start with a bar plot of the number of genes per category. We can start with the most basic plot by specifying the dataframe, geom, and aesthetics.\n\nggplot(bp_plot) +\n  geom_col(aes(x = GO_term, y = overlap.size))\n\n\n\n\n\n\n\n\nThis is a good base to start from, now let’s start to customize. To add color to the bars, we can use the fill argument, and if we would like to add an outline color to the bars, we can use the color argument.\n\nggplot(bp_plot) +\n  geom_col(aes(x = GO_term, y = overlap.size),\n           fill = \"royalblue\",\n           color = \"black\")\n\n\n\n\n\n\n\n\nThen we can provide our theme preferences, give the plot a title, and label our axes:\n\nggplot(bp_plot) +\n  geom_col(aes(x = GO_term, y = overlap.size),\n           fill = \"royalblue\",\n           color = \"black\") +\n  theme(axis.text.x = element_text(size=rel(1.15)),\n        axis.title = element_text(size=rel(1.15))) +\n  theme(plot.title = element_text(hjust=0.5, \n                                  face = \"bold\")) +\n  labs(title = \"DE genes per GO process\", x = NULL, y =  \"# DE genes\")\n\n\n\n\n\n\n\n\nNote that instead of using the functions xlab(), ylab(), and ggtitle(), we can provide all as arguments to the labs() function.\nNow we might be fairly happy with our plot, but the x-axis labelling needs some help. Within the theme() layer, we can change the orientiation of the x-axis labels with the angle argument and align the labels to the x-axis with the hjust argument.\n\nggplot(bp_plot) +\n  geom_col(aes(x = GO_term, y = overlap.size),\n           fill = \"royalblue\",\n           color = \"black\") +\n  theme(axis.text.x = element_text(size=rel(1.15)),\n        axis.title = element_text(size=rel(1.15))) +\n  theme(plot.title = element_text(hjust=0.5, \n                                  face = \"bold\")) +\n  labs(title = \"DE genes per GO process\", x = NULL, y =  \"# DE genes\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nThis is almost what we were looking for, but the labels are getting cut-off because the plotting area is too small. The plot.margin argument of the theme’s element_text() function can be used to alter the plotting dimensions to make room for our labels.\n\nggplot(bp_plot) +\n  geom_col(aes(x = GO_term, y = overlap.size),\n           fill = \"royalblue\",\n           color = \"black\") +\n  theme(axis.text.x = element_text(size=rel(1.15)),\n        axis.title = element_text(size=rel(1.15))) +\n  theme(plot.title = element_text(hjust=0.5, \n                                  face = \"bold\")) +\n  labs(title = \"DE genes per GO process\", x = NULL, y =  \"# DE genes\") +\n  theme(axis.text.x = element_text(angle = 45, \n                                   hjust = 1)) + \n  theme(plot.margin = unit(c(1,1,1,3), \"cm\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf we wanted to remove the space between the x-axis and the labels, we could add an additional layer for scale_y_continuous(expand = c(0, 0)), which would not expand the y-axis past the plotting limits.\n\n\n\n\nExporting figures to file\nThere are two ways in which figures and plots can be output to a file (rather than simply displaying on screen). The first (and easiest) is to export directly from the RStudio ‘Plots’ panel, by clicking on Export when the image is plotted. This will give you the option of png or pdf and selecting the directory to which you wish to save it to. It will also give you options to dictate the size and resolution of the output image.\nThe second option is to use R functions and have the write to file hard-coded in to your script. This would allow you to run the script from start to finish and automate the process (not requiring human point-and-click actions to save).\n\n\nConsistent formatting using custom functions\nWhen publishing, it is helpful to ensure all plots have similar formatting. To do this we can create a custom function with our preferences for the theme.\n\n## DO NOT RUN\nname_of_function &lt;- function(arguments) {\n    statements or code that does something\n}\n\nNow, let’s suppose we always wanted our theme to include the following:\n\n## DO NOT RUN\ntheme_bw() +\n    theme(axis.text.x = element_text(size=rel(1.15)),\n        axis.title = element_text(size=rel(1.15)),\n        legend.title = element_text(size=10, \n                                    face=\"bold\"),\n          plot.title=element_text(hjust=0.5, \n                                face = \"bold\"))\n\nIf there is nothing that we want to change when we run this, then we do not need to specify any arguments. Creating the function is simple; we can just put the code inside the {}:\n\npersonal_theme &lt;- function(){\n  theme_bw() +\n    theme(axis.text.x = element_text(size=rel(1.15)),\n        axis.title = element_text(size=rel(1.15)),\n        legend.title = element_text(size=10, \n                                    face=\"bold\"),\n          plot.title=element_text(hjust=0.5, \n                                face = \"bold\"))\n}\n\nNow to run our personal theme with any plot, we can use this function in place of all of the theme() layers:\n\nggplot(bp_plot) +\n  geom_point(aes(x = gene_ratio, y = GO_term, color = p.value), \n             size = 2) +\n  personal_theme() +\n  xlab(\"Gene ratios\") +\n  ylab(\"Top 30 significant GO terms\") +\n  ggtitle(\"Dotplot of top 30 significant GO terms\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\nBased on the number of genes associated with each GO term (“term.size” column) we can categorize them into “small”, “large” or “medium” categories. Once we have done that, we want to determine what the spread of p-values is for each category; we can do this by drawing a boxplot.\n\nUse the following code to create a new column in bp_oe tibble for the new categories.\n\n\n    x &lt;- bp_oe$term.size\n    sizes &lt;- rep(NA, length(x) )\n    \n    sizes[which(x &gt; 3000)] &lt;- \"large\"\n    sizes[which(x &lt;= 3000 & x &gt; 500 )] &lt;- \"medium\"\n    sizes[which(x &lt;= 500)] &lt;- \"small\"\n    bp_oe$term_cat &lt;- factor(sizes, levels = c(\"small\",\"medium\",\"large\"))\n\n\nCreate a boxplot with the new column (term.cat) on the x-axis and the -log10 of the p.value on the y-axis.\nFill color into each boxplot based on that new column\nAdd appropriate labels and theme() layers to your liking."
  },
  {
    "objectID": "lessons/Aside_ggplot2.html#resources",
    "href": "lessons/Aside_ggplot2.html#resources",
    "title": "Plotting and data visualization in R",
    "section": "Resources",
    "text": "Resources\nHelpful packages to add additional functionality to ggplot2:\n\ncowplot\nggpubr\nbbplot\nggrepel\nFundamentals of Data Visualization by Claus 0. Wilke"
  },
  {
    "objectID": "lessons/answer_keys/07_matching_answer_key.html",
    "href": "lessons/answer_keys/07_matching_answer_key.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "lessons/answer_keys/07_matching_answer_key.html#exercise-1-solution",
    "href": "lessons/answer_keys/07_matching_answer_key.html#exercise-1-solution",
    "title": "",
    "section": "Exercise 1 Solution",
    "text": "Exercise 1 Solution\n\nUsing the A and B vectors created above, evaluate each element in B to see if there is a match in A\n\n\nB %in% A\n\n[1] FALSE FALSE FALSE FALSE  TRUE  TRUE\n\n\n\nSubset the B vector to only return those values that are also in A.\n\n\nintersectionBA &lt;- B %in% A\nB[intersectionBA]\n\n[1] 1 5\n\n# or you could do the two above steps in a single line of code:\nB[B %in% A]\n\n[1] 1 5"
  },
  {
    "objectID": "lessons/answer_keys/07_matching_answer_key.html#exercise-2-solution",
    "href": "lessons/answer_keys/07_matching_answer_key.html#exercise-2-solution",
    "title": "",
    "section": "Exercise 2 Solution",
    "text": "Exercise 2 Solution\nWe have a list of 6 marker genes of that we are very interested in. Our goal is to extract count data for these genes, without having to scroll through the data frame of count data, using the %in% operator.\nFirst, lets create a vector called important_genes with the Ensembl IDs of the 6 genes we are interested in:\n\nimportant_genes &lt;- c(\"ENSMUSG00000083700\", \"ENSMUSG00000080990\", \"ENSMUSG00000065619\", \"ENSMUSG00000047945\", \"ENSMUSG00000081010\", \"ENSMUSG00000030970\")\n\n\nUse the %in% operator to determine if all of these genes are in the row names of the rpkm_data data frame.\n\n\nimportant_genes %in% rownames(rpkm_data)\n\n[1] TRUE TRUE TRUE TRUE TRUE TRUE\n\n\n\nExtract the rows from rpkm_data that correspond to these 6 genes using [] and the %in% operator, again. Double check the row names to ensure that you are extracting the correct rows.\n\n\nintersection &lt;- rownames(rpkm_data) %in% important_genes\n\nrpkm_data[intersection, ]\n\n                    sample2  sample5  sample7  sample8  sample9   sample4\nENSMUSG00000030970 2.221180 0.537852 2.243810 2.599400 3.593970 0.1753800\nENSMUSG00000047945 4.745070 0.323620 1.297810 3.896810 3.285470 0.2213430\nENSMUSG00000065619 0.000000 0.000000 0.000000 0.000000 0.000000 0.0000000\nENSMUSG00000080990 0.000000 0.000000 0.000000 0.000000 0.000000 0.0000000\nENSMUSG00000081010 0.222275 0.349415 0.190397 0.167166 0.221353 0.4196660\nENSMUSG00000083700 0.425214 0.337651 0.145973 0.142010 0.508757 0.0660419\n                    sample6 sample12  sample3 sample11 sample10  sample1\nENSMUSG00000030970 0.435484 0.964169 2.151490 0.963523 1.014520 2.971420\nENSMUSG00000047945 0.478836 3.581640 4.501390 1.442970 0.982691 5.199470\nENSMUSG00000065619 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000\nENSMUSG00000080990 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000\nENSMUSG00000081010 0.248244 0.594672 0.214347 0.415823 0.452537 0.235848\nENSMUSG00000083700 0.308669 0.488064 0.136998 0.222865 0.205934 0.124225\n\n\n\nBonus question: Extract the rows from rpkm_data that correspond to these 6 genes using [], but without using the %in% operator.\n\n\nrpkm_data[important_genes, ]\n\n                    sample2  sample5  sample7  sample8  sample9   sample4\nENSMUSG00000083700 0.425214 0.337651 0.145973 0.142010 0.508757 0.0660419\nENSMUSG00000080990 0.000000 0.000000 0.000000 0.000000 0.000000 0.0000000\nENSMUSG00000065619 0.000000 0.000000 0.000000 0.000000 0.000000 0.0000000\nENSMUSG00000047945 4.745070 0.323620 1.297810 3.896810 3.285470 0.2213430\nENSMUSG00000081010 0.222275 0.349415 0.190397 0.167166 0.221353 0.4196660\nENSMUSG00000030970 2.221180 0.537852 2.243810 2.599400 3.593970 0.1753800\n                    sample6 sample12  sample3 sample11 sample10  sample1\nENSMUSG00000083700 0.308669 0.488064 0.136998 0.222865 0.205934 0.124225\nENSMUSG00000080990 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000\nENSMUSG00000065619 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000\nENSMUSG00000047945 0.478836 3.581640 4.501390 1.442970 0.982691 5.199470\nENSMUSG00000081010 0.248244 0.594672 0.214347 0.415823 0.452537 0.235848\nENSMUSG00000030970 0.435484 0.964169 2.151490 0.963523 1.014520 2.971420"
  },
  {
    "objectID": "lessons/answer_keys/07_matching_answer_key.html#exercise-3-solution",
    "href": "lessons/answer_keys/07_matching_answer_key.html#exercise-3-solution",
    "title": "",
    "section": "Exercise 3 Solution",
    "text": "Exercise 3 Solution\nFor a research project, we asked healthy volunteers and cancer patients questions about their diet and exercise. We also collected blood work for each individual, and each person was given a unique ID. Create the following dataframes, behavior and blood by copy/pasting the code below:\n\n# Creating behavior dataframe\nID &lt;- c(546, 983, 042, 952, 853, 061)\ndiet &lt;- c(\"veg\", \"pes\", \"omni\", \"omni\", \"omni\", \"omni\")\nexercise &lt;- c(\"high\", \"low\", \"low\", \"low\", \"med\", \"high\")\nbehavior &lt;- data.frame(ID, diet, exercise)\n\n# Creating blood dataframe\n\nID &lt;- c(983, 952, 704, 555, 853, 061, 042, 237, 145, 581, 249, 467, 841, 546)\nblood_levels &lt;- c(43543, 465, 4634, 94568, 134, 347, 2345, 5439, 850, 6840, 5483, 66452, 54371, 1347)\nblood &lt;- data.frame(ID, blood_levels)\n\n\nWe would like to see if we have diet and exercise information for all of our blood samples. Using the ID information, determine whether all individuals with blood samples have associated behavioral information. Which individuals do not have behavioral information?\n\n\n# One way to subset the FALSE values\nblood$ID[!(blood$ID %in% behavior$ID)]\n\n[1] 704 555 237 145 581 249 467 841\n\n# Equally good way to subset FALSE values\nblood$ID[which(blood$ID %in% behavior$ID == F)]\n\n[1] 704 555 237 145 581 249 467 841\n\n\n\nThe samples lacking behavioral information correspond to individuals who opted out of the study after having their blood drawn. Subset the blood data to keep only samples that have behavioral information and save the dataframe back to the blood variable.\n\n\nblood &lt;- blood[blood$ID %in% behavior$ID, ]\nall(blood$ID %in% behavior$ID)\n\n[1] TRUE\n\n\n\nWe would like to combine the blood and behavior dataframes together, but first we need to make sure the data is in the same order.\n\na. Take a look at each of the dataframes and manually identify the correct order for the blood dataframe such that it matches the order of IDs in the behavior dataframe.\n\nbehavior\n\n   ID diet exercise\n1 546  veg     high\n2 983  pes      low\n3  42 omni      low\n4 952 omni      low\n5 853 omni      med\n6  61 omni     high\n\nblood\n\n    ID blood_levels\n1  983        43543\n2  952          465\n5  853          134\n6   61          347\n7   42         2345\n14 546         1347\n\n# order of `blood` IDs to match `behavior` IDs is: 6, 1, 5, 2, 3, 4\n\nb. Reorder the blood data to match the order of the IDs in the behavior dataframe and save the reordered blood dataframe as blood_reordered. Hint: you will need to have a vector of index values from a. to reorder. Once you have created blood_reordered you can use the all() function as a sanity check to make sure it was done correctly.\n\nblood_reordered &lt;- blood[c(6, 1, 5, 2, 3, 4), ]\nall(blood_reordered$ID == behavior$ID)\n\n[1] TRUE\n\n\nc. Combine the dataframes blood_reordered and behavior using the data.frame() function and save this to a new dataframe called blood_behavior. Note: you will find that there are now two “ID” columns, this will help verify that you have reordered correctly.\n\nblood_behavior &lt;- data.frame(blood_reordered, behavior)\nblood_behavior\n\n    ID blood_levels ID.1 diet exercise\n14 546         1347  546  veg     high\n1  983        43543  983  pes      low\n7   42         2345   42 omni      low\n2  952          465  952 omni      low\n5  853          134  853 omni      med\n6   61          347   61 omni     high"
  },
  {
    "objectID": "lessons/answer_keys/07_matching_answer_key.html#exercise-4-solution",
    "href": "lessons/answer_keys/07_matching_answer_key.html#exercise-4-solution",
    "title": "",
    "section": "Exercise 4 Solution",
    "text": "Exercise 4 Solution\nSimilar to the previous exercise, perform the reordering of the blood data to match the order of the IDs in the behavior dataframe, but this time use the match() function. Save the reordered blood dataframe as blood_reordered_match.\n\nblood_reordered_idx &lt;- match(behavior$ID, blood$ID)\nblood_reordered_idx\n\n[1] 6 1 5 2 3 4\n\nblood_reordered_match &lt;- blood[blood_reordered_idx, ]"
  },
  {
    "objectID": "lessons/answer_keys/Day3_activities_answer_key.html",
    "href": "lessons/answer_keys/Day3_activities_answer_key.html",
    "title": "Day 3 Activities Answer Key",
    "section": "",
    "text": "Download the animals.csv, by right-clicking on the link and “Save Link As…” to place the file into the data directory.\nRead the .csv file into your environment and assign it to a variable called animals. Be sure to check that your row names are the different animals.\n\n\nanimals &lt;- read.csv(\"../data/animals.csv\")\nanimals\n\n          speed color\nElephant   40.0  Gray\nCheetah   120.0   Tan\nTortoise    0.1 Green\nHare       48.0  Grey\nLion       80.0   Tan\nPolarBear  30.0 White\n\n\n\nCheck to make sure that animals is a dataframe.\n\n\nclass(animals)\n\n[1] \"data.frame\"\n\n\n\nHow many rows are in the animals dataframe? How many columns?\n\n\nnrow(animals)\n\n[1] 6\n\nncol(animals)\n\n[1] 2\n\n\n\n\n\n\nExtract the speed value of 40 km/h from the animals dataframe.\n\n\nanimals[1,1]\n\n[1] 40\n\nanimals[which(animals$speed == 40), 1]\n\n[1] 40\n\nanimals[which(animals$speed == 40), \"speed\"]\n\n[1] 40\n\nanimals$speed[which(animals$speed == 40)]\n\n[1] 40\n\n\n\nReturn the rows with animals that are the color Tan.\n\n\nanimals[c(2,5),]\n\n        speed color\nCheetah   120   Tan\nLion       80   Tan\n\nanimals[which(animals$color == \"Tan\"),]\n\n        speed color\nCheetah   120   Tan\nLion       80   Tan\n\n\n\nReturn the rows with animals that have speed greater than 50 km/h and output only the color column. Keep the output as a data frame.\n\n\nanimals[which(animals$speed &gt; 50), \"color\", drop =F]\n\n        color\nCheetah   Tan\nLion      Tan\n\n\n\nChange the color of “Grey” to “Gray”.\n\n\nanimals$color[which(animals$color == \"Grey\")] &lt;- \"Gray\"\nanimals[which(animals$color == \"Grey\"), \"color\"] &lt;- \"Gray\"\n\n\nCreate a list called animals_list in which the first element contains the speed column of the animals dataframe and the second element contains the color column of the animals dataframe.\n\n\nanimals_list &lt;- list(animals$speed, animals$color)\n\n\nGive each element of your list the appropriate name (i.e speed and color).\n\n\nnames(animals_list) &lt;- colnames(animals)\n\n\n\n\n\nIn your environment you should have a dataframe called proj_summary which contains quality metric information for an RNA-seq dataset. We have obtained batch information for the control samples in this dataset. Copy and paste the code below to create a dataframe of control samples with the associated batch information:\n\n\nproj_summary &lt;- read.table(file = \"../data/project-summary.txt\", header = TRUE, row.names = 1)\n\nctrl_samples &lt;- data.frame(row.names = c(\"sample3\", \"sample10\", \"sample8\", \"sample4\", \"sample15\"), \n                            date = c(\"01/13/2018\", \"03/15/2018\", \"01/13/2018\", \"09/20/2018\",\"03/15/2018\"))\n\n\nHow many of the ctrl_samples are also in the proj_summary dataframe? Use the %in% operator to compare sample names.\n\n\nlength(which(rownames(ctrl_samples) %in% rownames(proj_summary)))\n\n[1] 3\n\n\n\nKeep only the rows in proj_summary which correspond to those in ctrl_samples. Do this with the %in% operator. Save it to a variable called proj_summary_ctrl.\n\n\nproj_summary_ctrl &lt;- proj_summary[which(rownames(proj_summary) %in% rownames(ctrl_samples)),]\nproj_summary_ctrl\n\n        percent_GC Exonic_Rate Intronic_Rate Intergenic_Rate Mapping_Rate\nsample3         50      0.8834        0.0663          0.0503    0.9877286\nsample4         50      0.9027        0.0649          0.0325    0.9870764\nsample8         49      0.9022        0.0656          0.0322    0.9877458\n        Quality_format   rRNA_rate treatment\nsample3       standard 0.026944958   control\nsample4       standard 0.005081974   control\nsample8       standard 0.004549047   control\n\n\n\nWe would like to add in the batch information for the samples in proj_summary_ctrl. Find the rows that match in ctrl_samples.\n\n\nm &lt;- match(rownames(proj_summary_ctrl), rownames(ctrl_samples))\nm\n\n[1] 1 4 3\n\n\n\nUse cbind() to add a column called batch to the proj_summary_ctrl dataframe. Assign this new dataframe back to proj_summary_ctrl.\n\n\nproj_summary_ctrl &lt;- cbind(proj_summary_ctrl, batch=ctrl_samples[m,])\nproj_summary_ctrl\n\n        percent_GC Exonic_Rate Intronic_Rate Intergenic_Rate Mapping_Rate\nsample3         50      0.8834        0.0663          0.0503    0.9877286\nsample4         50      0.9027        0.0649          0.0325    0.9870764\nsample8         49      0.9022        0.0656          0.0322    0.9877458\n        Quality_format   rRNA_rate treatment      batch\nsample3       standard 0.026944958   control 01/13/2018\nsample4       standard 0.005081974   control 09/20/2018\nsample8       standard 0.004549047   control 01/13/2018\n\n\n\n\n\n\nSubset proj_summary to keep only the “high” and “low” samples based on the treament column. Save the new dataframe to a variable called proj_summary_noctl.\n\n\nlibrary(purrr)\n\nproj_summary_noctl &lt;- proj_summary[which(proj_summary$treatment != \"control\"),]\nproj_summary_noctl\n\n        percent_GC Exonic_Rate Intronic_Rate Intergenic_Rate Mapping_Rate\nsample1         49      0.8913        0.0709          0.0378    0.9787998\nsample2         49      0.9055        0.0625          0.0321    0.9825069\nsample5         49      0.8923        0.0714          0.0362    0.9781835\nsample6         49      0.8999        0.0667          0.0334    0.9772096\nsample7         49      0.8983        0.0665          0.0352    0.9757997\nsample9         49      0.9111        0.0566          0.0323    0.9814494\n        Quality_format   rRNA_rate treatment\nsample1       standard 0.007264734      high\nsample2       standard 0.005518317       low\nsample5       standard 0.005023175      high\nsample6       standard 0.005345113       low\nsample7       standard 0.005240401      high\nsample9       standard 0.005817519       low\n\n\n\nFurther, subset the dataframe to remove the non-numeric columns “Quality_format”, and “treatment”. Try to do this using the map_lgl() function in addition to is.numeric(). Save the new dataframe back to proj_summary_noctl.\n\n\nkeep &lt;- map_lgl(proj_summary_noctl, is.numeric)\nproj_summary_noctl &lt;- proj_summary_noctl[,keep]\nproj_summary_noctl\n\n        percent_GC Exonic_Rate Intronic_Rate Intergenic_Rate Mapping_Rate\nsample1         49      0.8913        0.0709          0.0378    0.9787998\nsample2         49      0.9055        0.0625          0.0321    0.9825069\nsample5         49      0.8923        0.0714          0.0362    0.9781835\nsample6         49      0.8999        0.0667          0.0334    0.9772096\nsample7         49      0.8983        0.0665          0.0352    0.9757997\nsample9         49      0.9111        0.0566          0.0323    0.9814494\n          rRNA_rate\nsample1 0.007264734\nsample2 0.005518317\nsample5 0.005023175\nsample6 0.005345113\nsample7 0.005240401\nsample9 0.005817519"
  },
  {
    "objectID": "lessons/answer_keys/Day3_activities_answer_key.html#reading-in-and-inspecting-data",
    "href": "lessons/answer_keys/Day3_activities_answer_key.html#reading-in-and-inspecting-data",
    "title": "Day 3 Activities Answer Key",
    "section": "",
    "text": "Download the animals.csv, by right-clicking on the link and “Save Link As…” to place the file into the data directory.\nRead the .csv file into your environment and assign it to a variable called animals. Be sure to check that your row names are the different animals.\n\n\nanimals &lt;- read.csv(\"../data/animals.csv\")\nanimals\n\n          speed color\nElephant   40.0  Gray\nCheetah   120.0   Tan\nTortoise    0.1 Green\nHare       48.0  Grey\nLion       80.0   Tan\nPolarBear  30.0 White\n\n\n\nCheck to make sure that animals is a dataframe.\n\n\nclass(animals)\n\n[1] \"data.frame\"\n\n\n\nHow many rows are in the animals dataframe? How many columns?\n\n\nnrow(animals)\n\n[1] 6\n\nncol(animals)\n\n[1] 2"
  },
  {
    "objectID": "lessons/answer_keys/Day3_activities_answer_key.html#data-wrangling",
    "href": "lessons/answer_keys/Day3_activities_answer_key.html#data-wrangling",
    "title": "Day 3 Activities Answer Key",
    "section": "",
    "text": "Extract the speed value of 40 km/h from the animals dataframe.\n\n\nanimals[1,1]\n\n[1] 40\n\nanimals[which(animals$speed == 40), 1]\n\n[1] 40\n\nanimals[which(animals$speed == 40), \"speed\"]\n\n[1] 40\n\nanimals$speed[which(animals$speed == 40)]\n\n[1] 40\n\n\n\nReturn the rows with animals that are the color Tan.\n\n\nanimals[c(2,5),]\n\n        speed color\nCheetah   120   Tan\nLion       80   Tan\n\nanimals[which(animals$color == \"Tan\"),]\n\n        speed color\nCheetah   120   Tan\nLion       80   Tan\n\n\n\nReturn the rows with animals that have speed greater than 50 km/h and output only the color column. Keep the output as a data frame.\n\n\nanimals[which(animals$speed &gt; 50), \"color\", drop =F]\n\n        color\nCheetah   Tan\nLion      Tan\n\n\n\nChange the color of “Grey” to “Gray”.\n\n\nanimals$color[which(animals$color == \"Grey\")] &lt;- \"Gray\"\nanimals[which(animals$color == \"Grey\"), \"color\"] &lt;- \"Gray\"\n\n\nCreate a list called animals_list in which the first element contains the speed column of the animals dataframe and the second element contains the color column of the animals dataframe.\n\n\nanimals_list &lt;- list(animals$speed, animals$color)\n\n\nGive each element of your list the appropriate name (i.e speed and color).\n\n\nnames(animals_list) &lt;- colnames(animals)"
  },
  {
    "objectID": "lessons/answer_keys/Day3_activities_answer_key.html#the-in-operator-reordering-and-matching",
    "href": "lessons/answer_keys/Day3_activities_answer_key.html#the-in-operator-reordering-and-matching",
    "title": "Day 3 Activities Answer Key",
    "section": "",
    "text": "In your environment you should have a dataframe called proj_summary which contains quality metric information for an RNA-seq dataset. We have obtained batch information for the control samples in this dataset. Copy and paste the code below to create a dataframe of control samples with the associated batch information:\n\n\nproj_summary &lt;- read.table(file = \"../data/project-summary.txt\", header = TRUE, row.names = 1)\n\nctrl_samples &lt;- data.frame(row.names = c(\"sample3\", \"sample10\", \"sample8\", \"sample4\", \"sample15\"), \n                            date = c(\"01/13/2018\", \"03/15/2018\", \"01/13/2018\", \"09/20/2018\",\"03/15/2018\"))\n\n\nHow many of the ctrl_samples are also in the proj_summary dataframe? Use the %in% operator to compare sample names.\n\n\nlength(which(rownames(ctrl_samples) %in% rownames(proj_summary)))\n\n[1] 3\n\n\n\nKeep only the rows in proj_summary which correspond to those in ctrl_samples. Do this with the %in% operator. Save it to a variable called proj_summary_ctrl.\n\n\nproj_summary_ctrl &lt;- proj_summary[which(rownames(proj_summary) %in% rownames(ctrl_samples)),]\nproj_summary_ctrl\n\n        percent_GC Exonic_Rate Intronic_Rate Intergenic_Rate Mapping_Rate\nsample3         50      0.8834        0.0663          0.0503    0.9877286\nsample4         50      0.9027        0.0649          0.0325    0.9870764\nsample8         49      0.9022        0.0656          0.0322    0.9877458\n        Quality_format   rRNA_rate treatment\nsample3       standard 0.026944958   control\nsample4       standard 0.005081974   control\nsample8       standard 0.004549047   control\n\n\n\nWe would like to add in the batch information for the samples in proj_summary_ctrl. Find the rows that match in ctrl_samples.\n\n\nm &lt;- match(rownames(proj_summary_ctrl), rownames(ctrl_samples))\nm\n\n[1] 1 4 3\n\n\n\nUse cbind() to add a column called batch to the proj_summary_ctrl dataframe. Assign this new dataframe back to proj_summary_ctrl.\n\n\nproj_summary_ctrl &lt;- cbind(proj_summary_ctrl, batch=ctrl_samples[m,])\nproj_summary_ctrl\n\n        percent_GC Exonic_Rate Intronic_Rate Intergenic_Rate Mapping_Rate\nsample3         50      0.8834        0.0663          0.0503    0.9877286\nsample4         50      0.9027        0.0649          0.0325    0.9870764\nsample8         49      0.9022        0.0656          0.0322    0.9877458\n        Quality_format   rRNA_rate treatment      batch\nsample3       standard 0.026944958   control 01/13/2018\nsample4       standard 0.005081974   control 09/20/2018\nsample8       standard 0.004549047   control 01/13/2018"
  },
  {
    "objectID": "lessons/answer_keys/Day3_activities_answer_key.html#bonus-using-map_lgl",
    "href": "lessons/answer_keys/Day3_activities_answer_key.html#bonus-using-map_lgl",
    "title": "Day 3 Activities Answer Key",
    "section": "",
    "text": "Subset proj_summary to keep only the “high” and “low” samples based on the treament column. Save the new dataframe to a variable called proj_summary_noctl.\n\n\nlibrary(purrr)\n\nproj_summary_noctl &lt;- proj_summary[which(proj_summary$treatment != \"control\"),]\nproj_summary_noctl\n\n        percent_GC Exonic_Rate Intronic_Rate Intergenic_Rate Mapping_Rate\nsample1         49      0.8913        0.0709          0.0378    0.9787998\nsample2         49      0.9055        0.0625          0.0321    0.9825069\nsample5         49      0.8923        0.0714          0.0362    0.9781835\nsample6         49      0.8999        0.0667          0.0334    0.9772096\nsample7         49      0.8983        0.0665          0.0352    0.9757997\nsample9         49      0.9111        0.0566          0.0323    0.9814494\n        Quality_format   rRNA_rate treatment\nsample1       standard 0.007264734      high\nsample2       standard 0.005518317       low\nsample5       standard 0.005023175      high\nsample6       standard 0.005345113       low\nsample7       standard 0.005240401      high\nsample9       standard 0.005817519       low\n\n\n\nFurther, subset the dataframe to remove the non-numeric columns “Quality_format”, and “treatment”. Try to do this using the map_lgl() function in addition to is.numeric(). Save the new dataframe back to proj_summary_noctl.\n\n\nkeep &lt;- map_lgl(proj_summary_noctl, is.numeric)\nproj_summary_noctl &lt;- proj_summary_noctl[,keep]\nproj_summary_noctl\n\n        percent_GC Exonic_Rate Intronic_Rate Intergenic_Rate Mapping_Rate\nsample1         49      0.8913        0.0709          0.0378    0.9787998\nsample2         49      0.9055        0.0625          0.0321    0.9825069\nsample5         49      0.8923        0.0714          0.0362    0.9781835\nsample6         49      0.8999        0.0667          0.0334    0.9772096\nsample7         49      0.8983        0.0665          0.0352    0.9757997\nsample9         49      0.9111        0.0566          0.0323    0.9814494\n          rRNA_rate\nsample1 0.007264734\nsample2 0.005518317\nsample5 0.005023175\nsample6 0.005345113\nsample7 0.005240401\nsample9 0.005817519"
  },
  {
    "objectID": "lessons/07_introR-data-wrangling2.html",
    "href": "lessons/07_introR-data-wrangling2.html",
    "title": "Data wrangling: dataframes, matrices, and lists",
    "section": "",
    "text": "Approximate time: 60 min",
    "crumbs": [
      "Day 2 Self-learning",
      "Data wrangling: dataframes, matrices, and lists"
    ]
  },
  {
    "objectID": "lessons/07_introR-data-wrangling2.html#learning-objectives",
    "href": "lessons/07_introR-data-wrangling2.html#learning-objectives",
    "title": "Data wrangling: dataframes, matrices, and lists",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDemonstrate how to subset, merge, and create new datasets from existing data structures in R.\n\n\nDataframes\nDataframes (and matrices) have 2 dimensions (rows and columns), so if we want to select some specific data from it we need to specify the “coordinates” we want from it. We use the same square bracket notation but rather than providing a single index, there are two indices required. Within the square bracket, row numbers come first followed by column numbers (and the two are separated by a comma). Let’s explore the metadata dataframe, shown below are the first six samples:\n\nLet’s say we wanted to extract the wild type (Wt) value that is present in the first row and the first column.\n\nTo extract it, just like with vectors, we give the name of the data frame that we want to extract from, followed by the square brackets (metadata[ ]).\nNow inside the square brackets we give the coordinates or indices for the rows in which the value(s) are present, followed by a comma, then the coordinates or indices for the columns in which the value(s) are present (metadata[rows, columns]).\n\nWe know the wild type value is in the first row if we count from the top, so we put a one, then a comma. The wild type value is also in the first column, counting from left to right, so we put a one in the columns space too.\n\n# Extract value 'Wt'\nmetadata[1, 1]\n\n[1] \"Wt\"\n\n\nNow let’s extract the value 1 from the first row and third column.\n\n# Extract value '1'\nmetadata[1, 3] \n\n[1] 1\n\n\nNow if you only wanted to select based on rows, you would provide the index for the rows and leave the columns index blank. The key here is to include the comma, to let R know that you are accessing a 2-dimensional data structure:\n\n# Extract third row\nmetadata[3, ] \n\n        genotype celltype replicate\nsample3       Wt    typeA         3\n\n\nWhat kind of data structure does the output appear to be? We see that it is two-dimensional with row names and column names, so we can surmise that it’s likely a data frame.\nIf you were selecting specific columns from the data frame - the rows are left blank:\n\n# Extract third column\nmetadata[ , 3]   \n\n [1] 1 2 3 1 2 3 1 2 3 1 2 3\n\n\nWhat kind of data structure does this output appear to be?\nIt looks different from the data frame, and we really just see a series of values output, indicating a vector data structure. This happens be default if just selecting a single column from a data frame. R will drop to the simplest data structure possible. Since a single column in a data frame is really just a vector, R will output a vector data structure as the simplest data structure.\nOftentimes we would like to keep our single column as a data frame. To do this, there is an argument we can add when subsetting called drop, meaning do we want to drop down to the simplest data structure. By default it is TRUE, but we can change it’s value to FALSE in order to keep the output as a data frame.\n\n# Extract third column as a data frame\nmetadata[ , 3, drop = FALSE] \n\n         replicate\nsample1          1\nsample2          2\nsample3          3\nsample4          1\nsample5          2\nsample6          3\nsample7          1\nsample8          2\nsample9          3\nsample10         1\nsample11         2\nsample12         3\n\n\nJust like with vectors, you can select multiple rows and columns at a time. Within the square brackets, you need to provide a vector of the desired values.\nWe can extract consecutive rows or columns using the colon (:) to create the vector of indices to extract.\n\n# Dataframe containing first two columns\nmetadata[ , 1:2] \n\n         genotype celltype\nsample1        Wt    typeA\nsample2        Wt    typeA\nsample3        Wt    typeA\nsample4        KO    typeA\nsample5        KO    typeA\nsample6        KO    typeA\nsample7        Wt    typeB\nsample8        Wt    typeB\nsample9        Wt    typeB\nsample10       KO    typeB\nsample11       KO    typeB\nsample12       KO    typeB\n\n\nAlternatively, we can use the combine function (c()) to extract any number of rows or columns. Let’s extract the first, third, and sixth rows.\n\n# Data frame containing first, third and sixth rows\nmetadata[c(1,3,6), ] \n\n        genotype celltype replicate\nsample1       Wt    typeA         1\nsample3       Wt    typeA         3\nsample6       KO    typeA         3\n\n\nFor larger datasets, it can be tricky to remember the column number that corresponds to a particular variable. (Is celltype in column 1 or 2? oh, right… they are in column 1). In some cases, the column/row number for values can change if the script you are using adds or removes columns/rows. It’s, therefore, often better to use column/row names to refer to extract particular values, and it makes your code easier to read and your intentions clearer.\n\n# Extract the celltype column for the first three samples\nmetadata[c(\"sample1\", \"sample2\", \"sample3\") , \"celltype\"] \n\n[1] \"typeA\" \"typeA\" \"typeA\"\n\n\nIt’s important to type the names of the columns/rows in the exact way that they are typed in the data frame; for instance if I had spelled celltype with a capital C, it would not have worked.\nIf you need to remind yourself of the column/row names, the following functions are helpful:\n\n# Check column names of metadata data frame\ncolnames(metadata)\n\n[1] \"genotype\"  \"celltype\"  \"replicate\"\n\n# Check row names of metadata data frame\nrownames(metadata)\n\n [1] \"sample1\"  \"sample2\"  \"sample3\"  \"sample4\"  \"sample5\"  \"sample6\" \n [7] \"sample7\"  \"sample8\"  \"sample9\"  \"sample10\" \"sample11\" \"sample12\"\n\n\nIf only a single column is to be extracted from a data frame, there is a useful shortcut available. If you type the name of the data frame, then the $, you have the option to choose which column to extract. For instance, let’s extract the entire genotype column from our dataset:\n\n# Extract the genotype column\nmetadata$genotype \n\n [1] \"Wt\" \"Wt\" \"Wt\" \"KO\" \"KO\" \"KO\" \"Wt\" \"Wt\" \"Wt\" \"KO\" \"KO\" \"KO\"\n\n\nThe output will always be a vector, and if desired, you can continue to treat it as a vector. For example, if we wanted the genotype information for the first five samples in metadata, we can use the square brackets ([]) with the indices for the values from the vector to extract:\n\n# Extract the first five values/elements of the genotype column\nmetadata$genotype[1:5]\n\n[1] \"Wt\" \"Wt\" \"Wt\" \"KO\" \"KO\"\n\n\nUnfortunately, there is no equivalent $ syntax to select a row by name.\n\n\n\n\n\n\nExercises\n\n\n\n\nReturn a data frame with only the genotype and replicate column values for sample2 and sample8.\nReturn the fourth and ninth values of the replicate column.\nExtract the replicate column as a data frame.\n\n\n\n\nSelecting using indices with logical operators\nWith data frames, similar to vectors, we can use logical expressions to extract the rows or columns in the data frame with specific values. First, we need to determine the indices in a rows or columns where a logical expression is TRUE, then we can extract those rows or columns from the data frame.\nFor example, if we want to return only those rows of the data frame with the celltype column having a value of typeA, we would perform two steps:\n\nIdentify which rows in the celltype column have a value of typeA.\nUse those TRUE values to extract those rows from the data frame.\n\nTo do this we would extract the column of interest as a vector, with the first value corresponding to the first row, the second value corresponding to the second row, so on and so forth. We use that vector in the logical expression. Here we are looking for values to be equal to typeA, so our logical expression would be:\n\nmetadata$celltype == \"typeA\"\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nThis will output TRUE and FALSE values for the values in the vector. The first six values are TRUE, while the last six are FALSE. This means the first six rows of our metadata have a vale of typeA while the last six do not. We can save these values to a variable, which we can call whatever we would like; let’s call it logical_idx.\n\nlogical_idx &lt;- metadata$celltype == \"typeA\"\n\nNow we can use those TRUE and FALSE values to extract the rows that correspond to the TRUE values from the metadata data frame. We will extract as we normally would a data frame with metadata[ , ], and we need to make sure we put the logical_idx in the row’s space, since those TRUE and FALSE values correspond to the ROWS for which the expression is TRUE/FALSE. We will leave the column’s space blank to return all columns.\n\nmetadata[logical_idx, ]\n\n        genotype celltype replicate\nsample1       Wt    typeA         1\nsample2       Wt    typeA         2\nsample3       Wt    typeA         3\nsample4       KO    typeA         1\nsample5       KO    typeA         2\nsample6       KO    typeA         3\n\n\n\nSelecting indices with logical operators using the which() function\nAs you might have guessed, we can also use the which() function to return the indices for which the logical expression is TRUE. For example, we can find the indices where the celltype is typeA within the metadata dataframe:\n\nwhich(metadata$celltype == \"typeA\")\n\n[1] 1 2 3 4 5 6\n\n\nThis returns the values one through six, indicating that the first 6 values or rows are true, or equal to typeA. We can save our indices for which rows the logical expression is true to a variable we’ll call idx, but, again, you could call it anything you want.\n\nidx &lt;- which(metadata$celltype == \"typeA\")\n\nThen, we can use these indices to indicate the rows that we would like to return by extracting that data as we have previously, giving the idx as the rows that we would like to extract, while returning all columns:\n\nmetadata[idx, ]\n\n        genotype celltype replicate\nsample1       Wt    typeA         1\nsample2       Wt    typeA         2\nsample3       Wt    typeA         3\nsample4       KO    typeA         1\nsample5       KO    typeA         2\nsample6       KO    typeA         3\n\n\nLet’s try another subsetting. Extract the rows of the metadata data frame for only the replicates 2 and 3. First, let’s create the logical expression for the column of interest (replicate):\n\nwhich(metadata$replicate &gt; 1)\n\n[1]  2  3  5  6  8  9 11 12\n\n\nThis should return the indices for the rows in the replicate column within metadata that have a value of 2 or 3. Now, we can save those indices to a variable and use that variable to extract those corresponding rows from the metadata table.\n\nidx &lt;- which(metadata$replicate &gt; 1)\n    \nmetadata[idx, ]\n\n         genotype celltype replicate\nsample2        Wt    typeA         2\nsample3        Wt    typeA         3\nsample5        KO    typeA         2\nsample6        KO    typeA         3\nsample8        Wt    typeB         2\nsample9        Wt    typeB         3\nsample11       KO    typeB         2\nsample12       KO    typeB         3\n\n\nAlternatively, instead of doing this in two steps, we could use nesting to perform in a single step:\n\nmetadata[which(metadata$replicate &gt; 1), ]\n\n         genotype celltype replicate\nsample2        Wt    typeA         2\nsample3        Wt    typeA         3\nsample5        KO    typeA         2\nsample6        KO    typeA         3\nsample8        Wt    typeB         2\nsample9        Wt    typeB         3\nsample11       KO    typeB         2\nsample12       KO    typeB         3\n\n\nEither way works, so use the method that is most intuitive for you.\nSo far we haven’t stored as variables any of the extractions/subsettings that we have performed. Let’s save this output to a variable called sub_meta:\n\nsub_meta &lt;- metadata[which(metadata$replicate &gt; 1), ]\n\n\n\n\n\n\n\nExercise\n\n\n\n\nSubset the metadata dataframe to return only the rows of data with a genotype of KO.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere are easier methods for subsetting dataframes using logical expressions, including the filter() and the subset() functions. These functions will return the rows of the dataframe for which the logical expression is TRUE, allowing us to subset the data in a single step. We will explore the filter() function in more detail in a later lesson.\n\n\n\n\n\n\nLists\nSelecting components from a list requires a slightly different notation, even though in theory a list is a vector (that contains multiple data structures). To select a specific component of a list, you need to use double bracket notation [[]]. Let’s use the list1 that we created previously, and index the second component:\n\nlist1[[2]]\n\n  species glengths\n1   ecoli      4.6\n2   human   3000.0\n3    corn  50000.0\n\n\nWhat do you see printed to the console? Using the double bracket notation is useful for accessing the individual components whilst preserving the original data structure. When creating this list we know we had originally stored a dataframe in the second component. With the class function we can check if that is what we retrieve:\n\ncomp2 &lt;- list1[[2]]\nclass(comp2)\n\n[1] \"data.frame\"\n\n\nYou can also reference what is inside the component by adding an additional bracket. For example, in the first component we have a vector stored.\n\nlist1[[1]]\n\n[1] \"ecoli\" \"human\" \"corn\" \n\n\nNow, if we wanted to reference the first element of that vector we would use:\n\nlist1[[1]][1]\n\n[1] \"ecoli\"\n\n\nYou can also do the same for dataframes and matrices, although with larger datasets it is not advisable. Instead, it is better to save the contents of a list component to a variable (as we did above) and further manipulate it. Also, it is important to note that when selecting components we can only access one at a time. To access multiple components of a list, see the note below.\n\n\n\n\n\n\nNote\n\n\n\nUsing the single bracket notation also works wth lists. The difference is the class of the information that is retrieved. Using single bracket notation i.e. list1[1] will return the contents in a list form and not the original data structure. The benefit of this notation is that it allows indexing by vectors so you can access multiple components of the list at once.\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate a list named random with the following components: metadata, age, list1, samplegroup, and number.\nExtract the samplegroup component.\n\n\n\nAssigning names to the components in a list can help identify what each list component contains, as well as, facilitating the extraction of values from list components.\nAdding names to components of a list uses the names() function. Let’s check and see if the list1 has names for the components:\n\nnames(list1) \n\nNULL\n\n\nWhen we created the list we had combined the species vector with a dataframe df and the number variable.\nLet’s assign the original names to the components. To do this we can use the assignment operator in a new context. If we add names(list1) to the left side of the assignment arrow to be assigned to, then anything on the right side of the arrow will be assigned. Since we have three components in list1, we need three names to assign.\nWe can create a vector of names using the combine (c()) function, and inside the combine function we give the names to assign to the components in the order we would like. So the first name is assigned to the first component of the list, and so on.\n\n# Name components of the list\nnames(list1) &lt;- c(\"species\", \"df\", \"number\")\nnames(list1)\n\n[1] \"species\" \"df\"      \"number\" \n\n\nNow that we have named our list components, we can extract components using the $ similar to extracting columns from a data frame. To obtain a component of a list using the component name, use list_name$component_name:\nTo extract the df dataframe from the list1 list:\n\n# Extract 'df' component\nlist1$df\n\n  species glengths\n1   ecoli      4.6\n2   human   3000.0\n3    corn  50000.0\n\n\n\n\n\n\n\n\nExercise\n\n\n\nLet’s practice combining ways to extract data from the data structures we have covered so far:\n\nSet names for the random list you created in the last exercise.\nExtract the age component using the $ notation\n\n\n\n\n\n\n\n\n\nAn R package for data wrangling\n\n\n\nThe methods presented above are using base R functions for data wrangling. Later we will explore the Tidyverse suite of packages, specifically designed to make data wrangling easier.",
    "crumbs": [
      "Day 2 Self-learning",
      "Data wrangling: dataframes, matrices, and lists"
    ]
  },
  {
    "objectID": "lessons/02_introR-syntax-and-data-structures.html",
    "href": "lessons/02_introR-syntax-and-data-structures.html",
    "title": "R Syntax and Data Structures",
    "section": "",
    "text": "Approximate time: 70 min",
    "crumbs": [
      "Day 1 Self-learning:",
      "R Syntax and Data Structures"
    ]
  },
  {
    "objectID": "lessons/02_introR-syntax-and-data-structures.html#learning-objectives",
    "href": "lessons/02_introR-syntax-and-data-structures.html#learning-objectives",
    "title": "R Syntax and Data Structures",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDescribe frequently-used data types in R.\nConstruct data structures to store data.",
    "crumbs": [
      "Day 1 Self-learning:",
      "R Syntax and Data Structures"
    ]
  },
  {
    "objectID": "lessons/02_introR-syntax-and-data-structures.html#data-types",
    "href": "lessons/02_introR-syntax-and-data-structures.html#data-types",
    "title": "R Syntax and Data Structures",
    "section": "Data Types",
    "text": "Data Types\nVariables can contain values of specific types within R. The six data types that R uses include:\n\n\"numeric\" for any numerical value, including whole numbers and decimals. This is the most common data type for performing mathematical operations.\n\"character\" for text values, denoted by using quotes (““) around value. For instance, while 5 is a numeric value, if you were to put quotation marks around it, it would turn into a character value, and you could no longer use it for mathematical operations. Single or double quotes both work, as long as the same type is used at the beginning and end of the character value.\n\"integer\" for whole numbers (e.g., 2L, the L indicates to R that it’s an integer). It behaves similar to the numeric data type for most tasks or functions; however, it takes up less storage space than numeric data, so often tools will output integers if the data is known to be comprised of whole numbers. Just know that integers behave similarly to numeric values. If you wanted to create your own, you could do so by providing the whole number, followed by an upper-case L.\n\"logical\" for TRUE and FALSE (the Boolean data type). The logical data type can be specified using four values, TRUE in all capital letters, FALSE in all capital letters, a single capital T or a single capital F.\n\"complex\" to represent complex numbers with real and imaginary parts (e.g., 1+4i) and that’s all we’re going to say about them\n\"raw\" that we won’t discuss further\n\nThe table below provides examples of each of the commonly used data types:\n\n\n\nData Type\nExamples\n\n\n\n\nNumeric:\n1, 1.5, 20, pi\n\n\nCharacter:\n“anytext”, “5”, “TRUE”\n\n\nInteger:\n2L, 500L, -17L\n\n\nLogical:\nTRUE, FALSE, T, F\n\n\n\nThe type of data will determine what you can do with it. For example, if you want to perform mathematical operations, then your data type cannot be character or logical. Whereas if you want to search for a word or pattern in your data, then you data should be of the character data type. The task or function being performed on the data will determine what type of data can be used.",
    "crumbs": [
      "Day 1 Self-learning:",
      "R Syntax and Data Structures"
    ]
  },
  {
    "objectID": "lessons/02_introR-syntax-and-data-structures.html#data-structures",
    "href": "lessons/02_introR-syntax-and-data-structures.html#data-structures",
    "title": "R Syntax and Data Structures",
    "section": "Data Structures",
    "text": "Data Structures\nWe know that variables are like buckets, and so far we have seen that bucket filled with a single value. Even when number was created, the result of the mathematical operation was a single value. Variables can store more than just a single value, they can store a multitude of different data structures. These include, but are not limited to, vectors (c), factors (factor), matrices (matrix), data frames (data.frame) and lists (list).\n\nVectors\nA vector is the most common and basic data structure in R, and is pretty much the workhorse of R. It’s basically just a collection of values, mainly either numbers,\n\nor characters,\n\nor logical values,\n\nNote that all values in a vector must be of the same data type. If you try to create a vector with more than a single data type, R will try to coerce it into a single data type.\nFor example, if you were to try to create the following vector:\n\nR will coerce it into:\n\n\n\nThe analogy for a vector is that your bucket now has different compartments; these compartments in a vector are called elements.\nEach element contains a single value, and there is no limit to how many elements you can have. A vector is assigned to a single variable, because regardless of how many elements it contains, in the end it is still a single entity (bucket).\nLet’s create a vector of genome lengths and assign it to a variable called glengths.\nEach element of this vector contains a single numeric value, and three values will be combined together into a vector using c() (the combine function). All of the values are put within the parentheses and separated with a comma.\n\n# Create a numeric vector and store the vector as a variable called 'glengths'\nglengths &lt;- c(4.6, 3000, 50000)\nglengths\n\n[1]     4.6  3000.0 50000.0\n\n\nNote your environment shows the glengths variable is numeric (num) and tells you the glengths vector starts at element 1 and ends at element 3 (i.e. your vector contains 3 values) as denoted by the [1:3].\nA vector can also contain characters. Create another vector called species with three elements, where each element corresponds with the genome sizes vector (in Mb).\n\n# Create a character vector and store the vector as a variable called 'species'\nspecies &lt;- c(\"ecoli\", \"human\", \"corn\")\nspecies\n\n[1] \"ecoli\" \"human\" \"corn\" \n\n\nWhat do you think would happen if we forgot to put quotations around one of the values? Let’s test it out with corn.\n\n# Forget to put quotes around corn\nspecies &lt;- c(\"ecoli\", \"human\", corn)\n\n\n\n\n\n\n\nWarning\n\n\n\nError: object ‘corn’ not found\n\n\nNote that RStudio is quite helpful in color-coding the various data types. We can see that our numeric values are blue, the character values are green, and if we forget to surround corn with quotes, it’s black. What does this mean? Let’s try to run this code.\nWhen we try to run this code we get an error specifying that object ‘corn’ is not found. What this means is that R is looking for an object or variable in my Environment called ‘corn’, and when it doesn’t find it, it returns an error. If we had a character vector called ‘corn’ in our Environment, then it would combine the contents of the ‘corn’ vector with the values “ecoli” and “human”.\nSince we only want to add the value “corn” to our vector, we need to re-run the code with the quotation marks surrounding corn. A quick way to add quotes to both ends of a word in RStudio is to highlight the word, then press the quote key.\n\n# Create a character vector and store the vector as a variable called 'species'\nspecies &lt;- c(\"ecoli\", \"human\", \"corn\")\n\n\n\n\n\n\n\nExercises\n\n\n\n\nTry to create a vector of numeric and character values by combining the two vectors that we just created (glengths and species).\nAssign this combined vector to a new variable called combined. Hint: you will need to use the combine c() function to do this.\nPrint the combined vector in the console, what looks different compared to the original vectors?\n\n\n\n\n\nFactors\nA factor is a special type of vector that is used to store categorical data. Each unique category is referred to as a factor level (i.e. category = level). Factors are built on top of integer vectors such that each factor level is assigned an integer value, creating value-label pairs.\nFor instance, if we have four animals and the first animal is female, the second and third are male, and the fourth is female, we could create a factor that appears like a vector, but has integer values stored under-the-hood. The integer value assigned is a one for females and a two for males. The numbers are assigned in alphabetical order, so because the f- in females comes before the m- in males in the alphabet, females get assigned a one and males a two. In later lessons we will show you how you could change these assignments.\n\nLet’s create a factor vector and explore a bit more. We’ll start by creating a character vector describing three different levels of expression. Perhaps the first value represents expression in mouse1, the second value represents expression in mouse2, and so on and so forth:\n\n# Create a character vector and store the vector as a variable called 'expression'\nexpression &lt;- c(\"low\", \"high\", \"medium\", \"high\", \"low\", \"medium\", \"high\")\n\nNow we can convert this character vector into a factor using the factor() function:\n\n# Turn 'expression' vector into a factor\nexpression &lt;- factor(expression)\n\nSo, what exactly happened when we applied the factor() function?\n\nThe expression vector is categorical, in that all the values in the vector belong to a set of categories; in this case, the categories are low, medium, and high. By turning the expression vector into a factor, the categories are assigned integers alphabetically, with high=1, low=2, medium=3. This in effect assigns the different factor levels. You can view the newly created factor variable and the levels in the Environment window.\n\nSo now that we have an idea of what factors are, when would you ever want to use them?\nFactors are extremely valuable for many operations often performed in R. For instance, factors can give order to values with no intrinsic order. In the previous ‘expression’ vector, if I wanted the low category to be less than the medium category, then we could do this using factors. Also, factors are necessary for many statistical methods. For example, descriptive statistics can be obtained for character vectors if you have the categorical information stored as a factor. Also, if you want to denote which category is your base level for a statistical comparison, then you would need to have your category variable stored as a factor with the base level assigned to 1. Anytime that it is helpful to have the categories thought of as groups in an analysis, the factor function makes this possible. For instance, if you want to color your plots by treatment type, then you would need the treatment variable to be a factor.\n\n\n\n\n\n\nExercises\n\n\n\nLet’s say that in our experimental analyses, we are working with three different sets of cells: normal, cells knocked out for geneA (a very exciting gene), and cells overexpressing geneA. We have three replicates for each celltype.\n\nCreate a vector named samplegroup with nine elements: 3 control (“CTL”) values, 3 knock-out (“KO”) values, and 3 over-expressing (“OE”) values.\nTurn samplegroup into a factor data structure.\n\n\n\n\n\nMatrix\nA matrix in R is a collection of vectors of same length and identical datatype. Vectors can be combined as columns in the matrix or by row, to create a 2-dimensional structure.\n\nMatrices are used commonly as part of the mathematical machinery of statistics. They are usually of numeric datatype and used in computational algorithms to serve as a checkpoint. For example, if input data is not of identical data type (numeric, character, etc.), the matrix() function will throw an error and stop any downstream code execution.\n\n\nData Frame\nA data.frame is the de facto data structure for most tabular data and what we use for statistics and plotting. A data.frame is similar to a matrix in that it’s a collection of vectors of the same length and each vector represents a column. However, in a dataframe each vector can be of a different data type (e.g., characters, integers, factors). In the data frame pictured below, the first column is character, the second column is numeric, the third is character, and the fourth is logical.\n\nA data frame is the most common way of storing data in R, and if used systematically makes data analysis easier.\nWe can create a dataframe by bringing vectors together to form the columns. We do this using the data.frame() function, and giving the function the different vectors we would like to bind together. This function will only work for vectors of the same length.\n\n# Create a data frame and store it as a variable called 'df'\ndf &lt;- data.frame(species, glengths)\n\nWe can see that a new variable called df has been created in our Environment within a new section called Data. In the Environment, it specifies that df has 3 observations of 2 variables. What does that mean? In R, rows always come first, so it means that df has 3 rows and 2 columns. We can get additional information if we click on the blue circle with the white triangle in the middle next to df. It will display information about each of the columns in the data frame, giving information about what the data type is of each of the columns and the first few values of those columns.\nAnother handy feature in RStudio is that if we hover the cursor over the variable name in the Environment, df, it will turn into a pointing finger. If you click on df, it will open the data frame as it’s own tab next to the script editor. We can explore the table interactively within this window. To close, just click on the X on the tab.\nAs with any variable, we can print the values stored inside to the console if we type the variable’s name and run.\n\ndf\n\n  species glengths\n1   ecoli      4.6\n2   human   3000.0\n3    corn  50000.0\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate a data frame called favorite_books with the following vectors as columns:\n\n\ntitles &lt;- c(\"Catch-22\", \"Pride and Prejudice\", \"Nineteen Eighty Four\")\npages &lt;- c(453, 432, 328)\n\n\n\n\n\nLists\nLists are a data structure in R that can be perhaps a bit daunting at first, but soon become amazingly useful. A list is a data structure that can hold any number of any types of other data structures.\n\nIf you have variables of different data structures you wish to combine, you can put all of those into one list object by using the list() function and placing all the items you wish to combine within parentheses:\n\nlist1 &lt;- list(species, df, number)\n\nWe see list1 appear within the Data section of our environment as a list of 3 components or variables. If we click on the blue circle with a triangle in the middle, it’s not quite as interpretable as it was for data frames.\nEssentially, each component is preceded by a colon. The first colon give the species vector, the second colon precedes the df data frame, with the dollar signs indicating the different columns, the last colon gives the single value, number.\nIf I click on list1, it opens a tab where you can explore the contents a bit more, but it’s still not super intuitive. The easiest way to view small lists is to print to the console.\nLet’s type list1 and print to the console by running it.\n\nlist1\n\n[[1]]\n[1] \"ecoli\" \"human\" \"corn\" \n\n[[2]]\n  species glengths\n1   ecoli      4.6\n2   human   3000.0\n3    corn  50000.0\n\n[[3]]\n[1] 8\n\n\nThere are three components corresponding to the three different variables we passed in, and what you see is that structure of each is retained. Each component of a list is referenced based on the number position. We will talk more about how to inspect and manipulate components of lists in later lessons.\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate a list called list2 containing species, glengths, and number.\n\n\n\nNow that we know what lists are, why would we ever want to use them? When getting started with R, you will most likely encounter lists with different tools or functions that you use. Oftentimes a tool will need a list as input, so that all the information needed to run the tool is present in a single variable. Sometimes a tool will output a list when working through an analysis. Knowing how to work with them and extract necessary information will be critically important.\nAs you become more comfortable with R, you will find yourself using lists more often. One common use of lists is to make iterative processes more efficient. For example, let’s say you had multiple data frames containing the same weather information from different cities throughout North America. You wanted to perform the same task on each of the data frames, but that would take a long time to do individually. Instead you could create a list where each data frame is a component of the list. Then, you could perform the task on the list instead, which would be applied to each of the components.",
    "crumbs": [
      "Day 1 Self-learning:",
      "R Syntax and Data Structures"
    ]
  },
  {
    "objectID": "lessons/03_introR-functions-and-arguments.html",
    "href": "lessons/03_introR-functions-and-arguments.html",
    "title": "Functions in R",
    "section": "",
    "text": "Approximate time: 30 min",
    "crumbs": [
      "Day 1 Self-learning:",
      "Functions in R"
    ]
  },
  {
    "objectID": "lessons/03_introR-functions-and-arguments.html#learning-objectives",
    "href": "lessons/03_introR-functions-and-arguments.html#learning-objectives",
    "title": "Functions in R",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDescribe and utilize functions in R.\nModify default behavior of a function using arguments.\nIdentify R-specific sources of obtaining more information about functions.\nDemonstrate how to create user-defined functions in R",
    "crumbs": [
      "Day 1 Self-learning:",
      "Functions in R"
    ]
  },
  {
    "objectID": "lessons/03_introR-functions-and-arguments.html#functions-and-their-arguments",
    "href": "lessons/03_introR-functions-and-arguments.html#functions-and-their-arguments",
    "title": "Functions in R",
    "section": "Functions and their arguments",
    "text": "Functions and their arguments\n\nWhat are functions?\nA key feature of R is functions. Functions are “self contained” modules of code that accomplish a specific task. Functions usually take in some sort of data structure (value, vector, dataframe etc.), process it, and return a result.\nThe general usage for a function is the name of the function followed by parentheses:\n\nfunction_name(input)\n\nThe input(s) are called arguments, which can include:\n\nthe physical object (any data structure) on which the function carries out a task\nspecifications that alter the way the function operates (e.g. options)\n\nNot all functions take arguments, for example:\n\ngetwd()\n\nHowever, most functions can take several arguments. If you don’t specify a required argument when calling the function, you will either receive an error or the function will fall back on using a default.\nThe defaults represent standard values that the author of the function specified as being “good enough in standard cases”. An example would be what symbol to use in a plot. However, if you want something specific, simply change the argument yourself with a value of your choice.\n\n\nBasic functions\nWe have already used a few examples of basic functions in the previous lessons i.e getwd(), c(), and factor(). These functions are available as part of R’s built in capabilities, and we will explore a few more of these base functions below.\nLet’s revisit a function that we have used previously to combine data c() into vectors. The arguments it takes is a collection of numbers, characters or strings (separated by a comma). The c() function performs the task of combining the numbers or characters into a single vector. You can also use the function to add elements to an existing vector:\n\nglengths &lt;- c(glengths, 90) # adding at the end \nglengths &lt;- c(30, glengths) # adding at the beginning\nglengths\n\n[1]    30.0     4.6  3000.0 50000.0    90.0\n\n\nWhat happens here is that we take the original vector glengths (containing three elements), and we are adding another item to either end. We can do this over and over again to build a vector or a dataset.\nSince R is used for statistical computing, many of the base functions involve mathematical operations. One example would be the function sqrt(). The input/argument must be a number, and the output is the square root of that number. Let’s try finding the square root of 81:\n\nsqrt(81)\n\n[1] 9\n\n\nNow what would happen if we called the function (e.g. ran the function), on a vector of values instead of a single value?\n\nsqrt(glengths)\n\n[1]   5.477226   2.144761  54.772256 223.606798   9.486833\n\n\nIn this case the task was performed on each individual value of the vector glengths and the respective results were displayed.\nLet’s try another function, this time using one that we can change some of the options (arguments that change the behavior of the function), for example round:\n\nround(3.14159)\n\n[1] 3\n\n\nWe can see that we get 3. That’s because the default is to round to the nearest whole number. What if we want a different number of significant digits? Let’s first learn how to find available arguments for a function.\n\n\nSeeking help on arguments for functions\nThe best way of finding out this information is to use the ? followed by the name of the function. Doing this will open up the help manual in the bottom right panel of RStudio that will provide a description of the function, usage, arguments, details, and examples:\n\n?round\n\nAlternatively, if you are familiar with the function but just need to remind yourself of the names of the arguments, you can use:\n\nargs(round)\n\nEven more useful is the example() function. This will allow you to run the examples section from the Online Help to see exactly how it works when executing the commands. Let’s try that for round():\n\nexample(\"round\")\n\nIn our example, we can change the number of digits returned by adding an argument. We can type digits=2 or however many we may want:\n\nround(3.14159, digits=2)\n\n[1] 3.14\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you provide the arguments in the exact same order as they are defined (in the help manual) you don’t have to name them:\n\nround(3.14159, 2)\n\n[1] 3.14\n\n\nHowever, it’s usually not recommended practice because it involves a lot of memorization. In addition, it makes your code difficult to read for your future self and others, especially if your code includes functions that are not commonly used. (It’s however OK to not include the names of the arguments for basic functions like mean, min, etc…). Another advantage of naming arguments, is that the order doesn’t matter. This is useful when a function has many arguments.\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nLet’s use base R function to calculate mean value of the glengths vector. You might need to search online to find what function can perform this task.\nCreate a new vector test &lt;- c(1, NA, 2, 3, NA, 4). Use the same base R function from exercise 1 (with addition of proper argument), and calculate mean value of the test vector. The output should be 2.5.\nAnother commonly used base function is sort(). Use this function to sort the glengths vector in descending order.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn R, missing values are represented by the symbol NA (not available). It’s a way to make sure that users know they have missing data, and make a conscious decision on how to deal with it. There are ways to ignore NA during statistical calculation, or to remove NA from the vector. If you want more information related to missing data or NA you can go to this page (please note that there are many advanced concepts on that page that have not been covered in class).\n\n\n\n\nUser-defined Functions\nOne of the great strengths of R is the user’s ability to add functions. Sometimes there is a small task (or series of tasks) you need done and you find yourself having to repeat it multiple times. In these types of situations, it can be helpful to create your own custom function. The structure of a function is given below:\n\nname_of_function &lt;- function(argument1, argument2) {\n    statements or code that does something\n    return(something)\n}\n\n\nFirst you give your function a name.\nThen you assign value to it, where the value is the function.\n\nWhen defining the function you will want to provide the list of arguments required (inputs and/or options to modify behaviour of the function), and wrapped between curly brackets place the tasks that are being executed on/using those arguments. The argument(s) can be any type of object (like a scalar, a matrix, a dataframe, a vector, a logical, etc), and it’s not necessary to define what it is in any way.\nFinally, you can “return” the value of the object from the function, meaning pass the value of it into the global environment. The important idea behind functions is that objects that are created within the function are local to the environment of the function – they don’t exist outside of the function.\nLet’s try creating a simple example function. This function will take in a numeric value as input, and return the squared value.\n\nsquare_it &lt;- function(x) {\n    square &lt;- x * x\n    return(square)\n}\n\nOnce you run the code, you should see a function named square_it in the Environment panel (located at the top right of Rstudio interface). Now, we can use this function as any other base R functions. We type out the name of the function, and inside the parentheses we provide a numeric value x:\n\nsquare_it(5)\n\n[1] 25\n\n\nPretty simple, right? In this case, we only had one line of code that was run, but in theory you could have many lines of code to get obtain the final results that you want to “return” to the user.\n\n\n\n\n\n\nNote\n\n\n\nDo I always have to return() something at the end of the function?\nIn the example above, we created a new variable called square inside the function, and then return the value of square. If you don’t use return(), by default R will return the value of the last line of code inside that function. That is to say, the following function will also work.\n\nsquare_it &lt;- function(x) {\n   x * x\n}\n\nHowever, we recommend always using return at the end of a function as the best practice.\n\n\nWe have only scratched the surface here when it comes to creating functions! We will revisit this in later lessons, but if interested you can also find more detailed information on this R-bloggers site, which is where we adapted this example from.\n\n\n\n\n\n\nExercises\n\n\n\n\nWrite a function called multiply_it, which takes two inputs: a numeric value x, and a numeric value y. The function will return the product of these two numeric values, which is x * y. For example, multiply_it(x=4, y=6) will return output 24.",
    "crumbs": [
      "Day 1 Self-learning:",
      "Functions in R"
    ]
  },
  {
    "objectID": "lessons/Day2_activities.html",
    "href": "lessons/Day2_activities.html",
    "title": "Day 2 Activities",
    "section": "",
    "text": "Custom Functions - Let’s create a function temp_conv(), which converts the temperature in Fahrenheit (input) to the temperature in Kelvin (output). Let’s perform a two-step calculation: first convert from Fahrenheit to Celsius, and then convert from Celsius to Kelvin.\n\nThe formula for celsius to farenheight: temp_c = (temp_f - 32) * 5 / 9\nThe formula for celsius to kelvin: temp_k = temp_c + 273.15\nTest your function. If your input is 70, the result of temp_conv(70) should be 294.2611.\n\nNesting Functions - Now we want to round the temperature in Kelvin (output of temp_conv()) to a single decimal place.\n\nUse the round() function with the newly-created temp_conv() function to achieve this in one line of code.\nIf your input is 70, the output should now be 294.3.",
    "crumbs": [
      "Day 2",
      "Day 2 Activities"
    ]
  },
  {
    "objectID": "lessons/Day2_activities.html#exercises",
    "href": "lessons/Day2_activities.html#exercises",
    "title": "Day 2 Activities",
    "section": "",
    "text": "Custom Functions - Let’s create a function temp_conv(), which converts the temperature in Fahrenheit (input) to the temperature in Kelvin (output). Let’s perform a two-step calculation: first convert from Fahrenheit to Celsius, and then convert from Celsius to Kelvin.\n\nThe formula for celsius to farenheight: temp_c = (temp_f - 32) * 5 / 9\nThe formula for celsius to kelvin: temp_k = temp_c + 273.15\nTest your function. If your input is 70, the result of temp_conv(70) should be 294.2611.\n\nNesting Functions - Now we want to round the temperature in Kelvin (output of temp_conv()) to a single decimal place.\n\nUse the round() function with the newly-created temp_conv() function to achieve this in one line of code.\nIf your input is 70, the output should now be 294.3.",
    "crumbs": [
      "Day 2",
      "Day 2 Activities"
    ]
  }
]